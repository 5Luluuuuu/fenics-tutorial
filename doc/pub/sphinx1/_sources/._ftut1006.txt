.. !split

.. _ch:poisson:

Making more flexible PDE solvers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

[**hpl 31**: I don't like this title, but have no other good alternative...]
[**AL 32**: Experimenting with new title]
[**hpl 33**: Additional experiment.]

.. _ch:poisson0:impl2:

Refactored implementation
=========================

Our first programs in this book are all "flat". That is,
they are not organized
into logical, reusable units in terms of Python functions. Such flat
programs are popular for quickly testing out some software, but not
well suited for serious problem solving. We shall therefore at once
*refactor* the program, meaning that we divide it into functions, but
this is just a reordering of the existing statements. During
refactoring, we try make functions as reusable as possible in other
contexts, but statements specific to a certain problem or task are
also encapsulated in (non-reusable) functions.  Being able to
distinguish reusable code from specialized code is a key issue when
refactoring code, and this ability depends on a good mathematical
understanding of the problem at hand ("what is general, what is
special?").  In a flat program, general and specialized code (and
mathematics) is often mixed together.

.. _ch:poisson0:impl2:func:

A more general solver function
------------------------------

We consider the flat program developed in the section :ref:`ch:poisson0:impl`.  Some of the code in this program
is needed to solve any Poisson problem :math:`-\nabla^2 u=f` on :math:`[0,1]\times
[0,1]` with :math:`u=u_{\mathrm{b}}` on the boundary, while other statements arise from
our simple test problem. Let us collect the general, reusable code in
a function ``solver``.  Our special test problem will then just be an
application of ``solver`` with some additional statements.  We limit the
``solver`` function to just *compute the numerical solution*. Plotting
and comparing the solution with the exact solution are considered to
be problem-specific activities to be performed elsewhere.

We parameterize ``solver`` by :math:`f`, :math:`u_{\mathrm{b}}`, and the resolution of the
mesh. Since it is so trivial to use higher-order finite element
functions by changing the third argument to ``FunctionSpace``, we let
also the degree of the polynomials in the finite element basis
functions be an argument to ``solver``.

.. code-block:: python

    from fenics import *
    
    def solver(f, u_b, Nx, Ny, degree=1):
        """
        Solve -Laplace(u)=f on [0,1]x[0,1] with 2*Nx*Ny Lagrange
        elements of specified degree and u=u_b (Expresssion) on
        the boundary.
        """
        # Create mesh and define function space
        mesh = UnitSquareMesh(Nx, Ny)
        V = FunctionSpace(mesh, 'P', degree)
    
        def boundary(x, on_boundary):
            return on_boundary
    
        bc = DirichletBC(V, u_b, boundary)
    
        # Define variational problem
        u = TrialFunction(V)
        v = TestFunction(V)
        a = dot(grad(u), grad(v))*dx
        L = f*v*dx
    
        # Compute solution
        u = Function(V)
        solve(a == L, u, bc)
    
        return u

Plotting for the test problem
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The additional tasks we did in our initial program can be placed in
other functions. For example, plotting the solution in our particular
test problem is placed in an
``application_test`` function:

.. code-block:: python

    def application_test():
        """Plot the solution in the test problem."""
        u_b = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
        f = Constant(-6.0)
        u = solver(f, u_b, 6, 4, 1)
        # Dump solution to file in VTK format
        u.rename('u', 'u')  # name 'u' is used in plot
        vtkfile = File("poisson.pvd")
        vtkfile << u
        # Plot solution and mesh
        plot(u)

Make a module!
~~~~~~~~~~~~~~

The refactored code is put in a file `ft06_poisson_func.py <https://github.com/hplgit/fenics-tutorial/blob/master/src/poisson/ft06_poisson_func.py>`__. We should make
sure that such a file can be imported (and hence reused) in other programs.
Then all statements in the main program should appear with a test
``if __name__ == '__main__':``. This test is true if the file is executed
as a program, but false if the file is imported.
If we want to run this file in the same way as we can
run ``ft06_poisson_func.py``, the main program is simply a call to
``application_test()`` followed by a call ``interactive()`` to hold the plot:

.. code-block:: python

    if __name__ == '__main__':
        application_test()
        # Hold plot
        interactive()

.. index:: unit testing

Verification and unit tests
---------------------------

The remaining part of our first program is to compare the numerical and
the exact solution. Every time we edit the code we must rerun the test
and examine that ``max_error`` is sufficiently small so we know that the
code still works. To this end, we shall adopt *unit testing*, meaning
that we create a mathematical test and corresponding software that
can run all our tests automatically and check that all tests pass.
Python has several tools for unit testing. Two very popular ones are
pytest and nose. These are almost identical and very easy to use.
More classical unit testing with test classes is offered by the built-in
tool ``unittest``, but here we are going to use pytest (or nose) since it demands
shorter and clearer code.

Mathematically, our unit test is that the finite element solution of
our problem when :math:`f=-6` equals the exact solution :math:`u=u_{\mathrm{b}}=1+x^2+2y^2`.
We have already created code that finds the maximum error in the
numerical solution. Because of rounding errors, we cannot demand this
maximum error to be zero, but we have to use a tolerance, which depends
to the number of elements and the degrees of the polynomials in the finite
element basis functions.  If we want
to test that ``solver`` works for meshes up to :math:`2(20\times 20)` elements
and cubic Lagrange elements, :math:`10^{-11}` is
an appropriate tolerance for testing that the maximum error vanishes
(see the section :ref:`ch:poisson0:impl:dissect`).

Only three statements are necessary to carry out the unit test. However,
we shall embed these statements in software that the testing frameworks
pytest and nose can recognize. This means that each unit test
must be placed in a function that

 * has a name starting with ``test_``

 * has no arguments

 * implements the test as ``assert success, msg``

Regarding the last point, ``success`` is a boolean expression that is ``False``
if the test fails, and in that case the string ``msg`` is written to the
screen. When the test fails, ``assert`` raises an ``AssertionError`` exception
in Python, otherwise the statement runs silently. The ``msg`` string is
optional, so ``assert success`` is the minimal test. In our case, we
will do ``assert max_error < tol``, where ``tol`` is the tolerance (:math:`10^{-11}`)
mentioned above.

A proper *test function* for implementing this unit test in the pytest
or nose testing frameworks has the following form. Note that we perform
the test for different mesh resolutions and degrees of finite elements.

.. code-block:: python

    def test_solver():
        """Reproduce u=1+x^2+2y^2 to "machine precision"."""
        tol = 1E-11  # This problem's precision
        u_b = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
        f = Constant(-6.0)
        for Nx, Ny in [(3,3), (3,5), (5,3), (20,20)]:
            for degree in 1, 2, 3:
                print('solving on 2(%dx%d) mesh with P%d elements'
                      % (Nx, Ny, degree))
                u = solver(f, u_b, Nx, Ny, degree)
                # Make a finite element function of the exact u_b
                V = u.function_space()
                u_b_Function = interpolate(u_b, V)  # exact solution
                # Check that dof arrays are equal
                u_b_array = u_b_Function.vector().array()  # dof values
                max_error = (u_b_array - u.vector().array()).max()
                msg = 'max error: %g for 2(%dx%d) mesh and degree=%d' %\ 
                      (max_error, Nx, Ny, degree)
                assert max_error < tol, msg

We can at any time run

.. code-block:: text

    Terminal> py.test -s -v ft06_poisson_func.py

and the pytest tool will run all functions ``test_*()`` in the file and report
how the tests go.

We shall make it a habit in this book to encapsulate numerical test
problems in unit tests as done above, and we strongly encourage the
reader to create similar unit tests whenever a FEniCS solver is
implemented. We dare to assert that this is the only serious way
do reliable computational science with FEniCS.


.. admonition:: Tip: Print messages in test functions

   The ``assert`` statement runs silently when the test passes so users may
   become uncertain if all the statements in a test function are really
   executed. A psychological help is to print out something before ``assert``
   (as we do in the example above) such that it is clear that the
   test really takes place.
   (Note that ``py.test`` needs the ``-s`` option to show printout
   from the test functions.)




.. _ch:poisson0:verify1:

Writing out the discrete solution
---------------------------------

We have seen how to grab the degrees of freedom array from a
finite element function ``u``:

.. code-block:: python

    u_array = u.vector().array()

The elements in ``u_array`` correspond to function values of ``u`` at nodes
in the mesh.  Now, a fundamental question is: What are the
coordinates of node ``i`` whose value is ``u_array[i]``? To answer this
question, we need to understand how to get our hands on the
coordinates, and in particular, the numbering of degrees of freedom
and the numbering of vertices in the mesh. We start with P1 (1st order
Lagrange) elements where all the nodes are vertices in the mesh.

The function ``mesh.coordinates()`` returns the coordinates of the
vertices as a ``numpy`` array with shape :math:`(M,d`), :math:`M` being the number
of vertices in the mesh and :math:`d` being the number of space dimensions:

.. code-block:: python

    >>> from fenics import *
    >>>
    >>> mesh = UnitSquareMesh(2, 2)
    >>> coor = mesh.coordinates()
    >>> coor
    array([[ 0. ,  0. ],
           [ 0.5,  0. ],
           [ 1. ,  0. ],
           [ 0. ,  0.5],
           [ 0.5,  0.5],
           [ 1. ,  0.5],
           [ 0. ,  1. ],
           [ 0.5,  1. ],
           [ 1. ,  1. ]])

We see from this output that vertices are first numbered along :math:`y=0`
with increasing :math:`x` coordinate, then along :math:`y=0.5`, and so on.

Next we compute a function ``u`` on this mesh, e.g., the :math:`u=x+y`:

.. code-block:: python

    >>> V = FunctionSpace(mesh, 'P', 1)
    >>> u = interpolate(Expression('x[0]+x[1]'), V)
    >>> plot(u, interactive=True)
    >>> u_array = u.vector().array()
    >>> u_array
    array([ 1. ,  0.5,  1.5,  0. ,  1. ,  2. ,  0.5,  1.5,  1. ])

We observe that ``u_array[0]`` is *not* the value of :math:`x+y` at vertex number 0,
since this vertex has coordinates :math:`x=y=0`. The numbering of the
degrees of freedom :math:`U_1,\ldots,U_{N}` is obviously not the same as the
numbering of the vertices.

In the plot of ``u``, type ``w`` to turn on wireframe instead of fully colored
surface, ``m`` to show the mesh, and then ``v`` to show the
numbering of the vertices.

| 
| 

.. figure:: vertex_numbering.png
   :width: 500

| 
| 

.. index:: compute vertex values

.. index:: vertex values

Already in the section :ref:`ch:poisson0:impl:dissect` we explained that
the vertex values of a ``Function`` object can be extracted
``u.compute_vertex_values()``, which returns an array where element ``i``
is the value of ``u`` at vertex ``i``:

.. code-block:: python

    >>> u_at_vertices = u.compute_vertex_values()
    >>> for i, x in enumerate(coor):
    ...     print('vertex %d: u_at_vertices[%d]=%g\tu(%s)=%g' %
    ...           (i, i, u_at_vertices[i], x, u(x)))
    vertex 0: u_at_vertices[0]=0	u([ 0.  0.])=8.46545e-16
    vertex 1: u_at_vertices[1]=0.5	u([ 0.5  0. ])=0.5
    vertex 2: u_at_vertices[2]=1	u([ 1.  0.])=1
    vertex 3: u_at_vertices[3]=0.5	u([ 0.   0.5])=0.5
    vertex 4: u_at_vertices[4]=1	u([ 0.5  0.5])=1
    vertex 5: u_at_vertices[5]=1.5	u([ 1.   0.5])=1.5
    vertex 6: u_at_vertices[6]=1	u([ 0.  1.])=1
    vertex 7: u_at_vertices[7]=1.5	u([ 0.5  1. ])=1.5
    vertex 8: u_at_vertices[8]=2	u([ 1.  1.])=2

.. index:: vertex to dof map

.. index:: dof to vertex map

Alternatively, we can ask for the mapping from vertex numbering to degrees
of freedom numbering in the space :math:`V`:

.. code-block:: text

    v2d = vertex_to_dof_map(V)

Now, ``u_array[v2d[i]]`` will give us the value of the
degree of freedom in ``u`` corresponding
to vertex ``i`` (``v2d[i]``). In particular, ``u_array[v2d]`` is an array
with all the elements in the same (vertex numbered) order as ``coor``.
The inverse map, from degrees of freedom
number to vertex number is given by ``dof_to_vertex_map(V)``, so
``coor[dof_to_vertex_map(V)]`` results in an array of all the
coordinates in the same order as the degrees of freedom.

For Lagrange elements of degree larger than 1, there are degrees of
freedom (nodes) that do not correspond to vertices.
[**hpl 34**: Anders, is the following true?] There is no simple way of getting the
coordinates associated with the non-vertex degrees of freedom, so
if we want to write out the values of a finite element solution,
the following code snippet does the task at the vertices, and this
will work for all kinds of Lagrange elements.

.. code-block:: python

    def compare_exact_and_numerical_solution(Nx, Ny, degree=1):
        u_b = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
        f = Constant(-6.0)
        u = solver(f, u_b, Nx, Ny, degree, linear_solver='direct')
        # Grab exact and numerical solution at the vertices and compare
        V = u.function_space()
        u_b_Function = interpolate(u_b, V)
        u_b_at_vertices = u_b_Function.compute_vertex_values()
        u_at_vertices = u.compute_vertex_values()
        coor = V.mesh().coordinates()
        for i, x in enumerate(coor):
            print('vertex %2d (%9g,%9g): error=%g'
                  % (i, x[0], x[1],
                     u_b_at_vertices[i] - u_at_vertices[i]))
            # Could compute u_b(x) - u_at_vertices[i] but this
            # is much more expensive and gives more rounding errors
        center = (0.5, 0.5)
        error = u_b(center) - u(center)
        print('numerical error at %s: %g' % (center, error))

As expected, the error is either identically zero or about :math:`10^{-15}` or
:math:`10^{-16}`.


.. admonition:: Cheap vs expensive function evaluation

   Given a ``Function`` object ``u``, we can evaluate its values in various
   ways:
   
   1. ``u(x)`` for an arbitrary point ``x``
   
   2. ``u.vector().array()[i]`` for degree of freedom number ``i``
   
   3. ``u.compute_vertex_values()[i]`` at vertex number ``i``
   
   The first method, though very flexible, is in general very expensive
   while the other two are very efficient (but limited to certain points).




To demonstrate the use of point evaluations of ``Function`` objects,
we write out the computed ``u`` at the center point
of the domain and compare it with the exact solution:

.. code-block:: python

    center = (0.5, 0.5)
    error = u_b(center) - u(center)
    print('numerical error at %s: %g' % (center, error)

Trying a :math:`2(3\times 3)` mesh, the output from the
previous snippet becomes

.. code-block:: text

    numerical error at (0.5, 0.5): -0.0833333

The discrepancy is due to the fact that the center point is not a node
in this particular mesh, but a point in the interior of a cell,
and ``u`` varies linearly over the cell while
``u_b`` is a quadratic function. When the center point is a node, as in
a :math:`2(t\times 2)` or :math:`2(4\times 4)` mesh, the error is of the order
:math:`10^{-15}`.

We have seen how to extract the nodal values in a ``numpy`` array.
If desired, we can adjust the nodal values too. Say we want to
normalize the solution such that :math:`\max_j U_j = 1`. Then we
must divide all :math:`U_j` values
by :math:`\max_j U_j`. The following function performs the task:

.. code-block:: python

    def normalize_solution(u):
        """Normalize u: return u divided by max(u)."""
        u_array = u.vector().array()
        u_max = u_array.max()
        u_array /= u_max
        u.vector()[:] = u_array
        u.vector().set_local(u_array)  # alternative
        return u

That is, we manipulate ``u_array`` as desired, and then we insert this
array into ``u``'s ``Vector`` object.  The ``/=`` operator implies an
in-place modification of the object on the left-hand side: all
elements of the ``u_array`` are divided by the value ``max_u``.
Alternatively, one could write ``u_array = u_array/max_u``, which
implies creating a new array on the right-hand side and assigning this
array to the name ``u_array``.


.. admonition:: Be careful when manipulating degrees of freedom

   A call like ``u.vector().array()`` returns a *copy* of the data in
   ``u.vector()``. One must therefore never perform assignments like
   ``u.vector.array()[:] = ...``, but instead extract the ``numpy`` array
   (i.e., a copy), manipulate it, and insert it back with ``u.vector()[:]
   = `` or ``u.set_local(...)``.




.. index:: ft07_poisson_iter.py

All the code in this subsection can be found in the file ``ft07_poisson_iter.py``.

.. _ch:poisson0:nD:

Parameterizing the number of space dimensions
---------------------------------------------

.. index:: dimension-independent code

FEniCS makes it is easy to write a unified simulation code that can
operate in 1D, 2D, and 3D. We will conveniently make use of this
feature in forthcoming examples.  As an appetizer, go back to the
introductory programs ``ft01_poisson.py`` or
``ft06_poisson_func.py`` and change the
mesh construction from ``UnitSquareMesh(6, 4)`` to ``UnitCubeMesh(6, 4,
5)``. Now the domain is the unit cube partitioned into :math:`6\times 4\times
5` boxes, and each box is divided into six tetrahedra-shaped
finite elements for computations.  Run the program and observe that we
can solve a 3D problem without any other modifications (!). The
visualization allows you to rotate the cube and observe the function
values as colors on the boundary.

Generating a hypercube
~~~~~~~~~~~~~~~~~~~~~~

The syntax for generating a unit interval, square, or box is different,
so we need to encapsulate this part of the code. Given a list or
tuple with the divisions into cells in the various spatial direction,
the following function returns the mesh in a :math:`d`-dimensional problem:

.. code-block:: python

    def unit_hypercube(divisions, degree):
        mesh_classes = [UnitIntervalMesh, UnitSquareMesh, UnitCubeMesh]
        d = len(divisions)
        mesh = mesh_classes[d-1](*divisions)
        V = FunctionSpace(mesh, 'P', degree)
        return V, mesh

The construction ``mesh_class[d-1]`` will pick the right name of the
object used to define the domain and generate the mesh.
Moreover, the argument ``*divisions``
sends all the component of the list ``divisions`` as separate
arguments. For example, in a 2D problem where ``divisions`` has
two elements, the statement

.. code-block:: python

    mesh = mesh_classes[d-1](*divisions)

is equivalent to

.. code-block:: python

    mesh = UnitSquareMesh(divisions[0], divisions[1])

Replacing the ``Nx`` and ``Ny`` parameters by ``divisions`` and calling
``unit_hypercube`` to create the mesh are the two modifications that
we need in any of the previously shown ``solver`` functions to turn
them into solvers for :math:`d`-dimensional problems!

.. --- begin exercise ---

Exercise 2: Solve a Poisson problem
-----------------------------------

Solve the following problem

.. _Eq:_auto10:

.. math::

    \tag{54}
    \nabla^2 u = 2e^{-2x}\sin(\pi y)((4-5\pi^2)\sin(2\pi x) - 8\pi\cos(2\pi x))
        \hbox{ in }\Omega = [0,1]\times [0,1]
        
        

.. _Eq:_auto11:

.. math::

    \tag{55}
    u = 0\quad\hbox{ on }\partial\Omega
        
        

The exact solution is given by

.. math::
         u(x,y) = 2e^{-2x}\sin(\pi x)\sin(\pi y){\thinspace .}

Compute the maximum numerical approximation error in a mesh with
:math:`2(N_x\times N_y)` elements and in a mesh with double resolution:
:math:`4(N_x\times N_y)` elements. Show that the doubling the resolution
reduces the error by a factor 4 when using Lagrange elements of degree one.
Make an illustrative plot of the solution too.

**a)**
Base your implementation on editing the program
``ft01_poisson.py``.

.. --- begin hint in exercise ---

**Hint 1.**
In the string for an ``Expression`` object, ``pi`` is the value of
:math:`\pi`. Also note that :math:`\pi^2` must be expressed with syntax
``pow(pi,2)`` and not (the common Python syntax) ``pi**2``.

FEniCS will abort with a compilation error if you type the expressions
in a wrong way syntax-wise.  Search for *error:* in the
``/very/long/path/compile.log`` file mentioned in the error message to
see what the C++ compiler reported as error in the expressions.

.. --- end hint in exercise ---

.. --- begin hint in exercise ---

**Hint 2.**
The result that with P1 elements, doubling the resolution reduces the error
with a factor of four, is an
asymptotic result so it requires a sufficiently fine mesh. Here
one may start with :math:`N_x=N_y=20`.

.. --- end hint in exercise ---

Filename: ``poisson_fsin_flat``.

.. --- begin solution of exercise ---

**Solution.**
Looking at the ``ft01_poisson.py`` code, we realize that
the following edits are required:

 * Modify the ``mesh`` computation.

 * Modify ``u_b`` and ``f``.

 * Add expression for the exact solution.

 * Modify the computation of the numerical error.

 * Insert a loop to enable solving the problem twice.

 * Put the error reduction computation and the plot statements after the loop.

Here is the modified code:

.. code-block:: python

    from fenics import *
    
    Nx = Ny = 20
    error = []
    for i in range(2):
        Nx *= (i+1)
        Ny *= (i+1)
    
        # Create mesh and define function space
        mesh = UnitSquareMesh(Nx, Ny)
        V = FunctionSpace(mesh, 'Lagrange', 1)
    
        # Define boundary conditions
        u0 = Constant(0)
    
        def u0_boundary(x, on_boundary):
            return on_boundary
    
        bc = DirichletBC(V, u0, u0_boundary)
    
        # Define variational problem
        u = TrialFunction(V)
        v = TestFunction(V)
        f = Expression('-2*exp(-2*x[0])*sin(pi*x[1])*('
                       '(4-5*pow(pi,2))*sin(2*pi*x[0]) '
                       ' - 8*pi*cos(2*pi*x[0]))')
        # Note: no need for pi=DOLFIN_PI in f, pi is valid variable
        a = inner(nabla_grad(u), nabla_grad(v))*dx
        L = f*v*dx
    
        # Compute solution
        u = Function(V)
        solve(a == L, u, bc)
    
        u_e = Expression(
            '2*exp(-2*x[0])*sin(2*pi*x[0])*sin(pi*x[1])')
    
        u_e_Function = interpolate(u_e, V)         # exact solution
        u_e_array = u_e_Function.vector().array()  # dof values
        max_error = (u_e_array - u.vector().array()).max()
        print('max error:', max_error, '%dx%d mesh' % (Nx, Ny))
        error.append(max_error)
    
    print('Error reduction:', error[1]/error[0])
    
    # Plot solution and mesh
    plot(u)
    
    # Dump solution to file in VTK format
    file = File("poisson.pvd")
    file << u
    
    # Hold plot
    interactive()

The number :math:`\pi` has the symbol ``M_PI`` in C and C++, but in C++
strings in ``Expression`` objects, the symbol ``pi`` can be used directly
(or one can use the less readable ``DOLFIN_PI``).

.. figure:: poisson_fsin.png
   :width: 500

.. --- end solution of exercise ---

**b)**
Base your implementation on a new file that imports functionality
from the module ``ft06_poisson_func.py``. Embed the check of the
reduction of the numerical approximation error in a unit test.
Filename: ``poisson_fsin_func``.

.. --- begin solution of exercise ---

**Solution.**
Solving the two problems is a matter of calling ``solver`` with
different sets of arguments.
To compute the numerical error,
we need code that is close to what we have in ``test_solver``.

.. code-block:: python

    from poisson_func import (
        solver, Expression, Constant, interpolate, File, plot,
        interactive)
    
    def data():
        """Return data for this Poisson problem."""
        u0 = Constant(0)
        u_e = Expression(
            '2*exp(-2*x[0])*sin(2*pi*x[0])*sin(pi*x[1])')
        f = Expression('-2*exp(-2*x[0])*sin(pi*x[1])*('
                       '(4-5*pow(pi,2))*sin(2*pi*x[0]) '
                       ' - 8*pi*cos(2*pi*x[0]))')
        return u0, f, u_e
    
    def test_solver():
        """Check convergence rate of solver."""
        u0, f, u_e = data()
        Nx = 20
        Ny = Nx
        error = []
        # Loop over refined meshes
        for i in range(2):
            Nx *= i+1
            Ny *= i+1
            print('solving on 2(%dx%d) mesh' % (Nx, Ny))
            u = solver(f, u0, Nx, Ny, degree=1)
            # Make a finite element function of the exact u_e
            V = u.function_space()
            u_e_array = interpolate(u_e, V).vector().array()
            max_error = (u_e_array - u.vector().array()).max()  # Linf norm
            error.append(max_error)
            print('max error:', max_error)
        for i in range(1, len(error)):
            error_reduction = error[i]/error[i-1]
            print('error reduction:', error_reduction)
            assert abs(error_reduction - 0.25) < 0.1
    
    def application():
        """Plot the solution."""
        u0, f, u_e = data()
        Nx = 40
        Ny = Nx
        u = solver(f, u0, Nx, Ny, 1)
        # Dump solution to file in VTK format
        file = File("poisson.pvd")
        file << u
        # Plot solution and mesh
        plot(u)
    
    if __name__ == '__main__':
        test_solver()
        application()
        # Hold plot
        interactive()

The unit test is embedded in a proper test function ``test_solver``
for the pytest or
nose testing frameworks. Visualization of the solution is encapsulated
in the ``application`` function. Since we need ``u_e``, ``u_b``, and ``f``
in two functions, we place the definitions in a function ``data`` to
avoid copies of these expressions.

.. --- end solution of exercise ---

.. Closing remarks for this Exercise

Remarks
~~~~~~~

This exercise demonstrates that changing a flat program to solve a new
problem requires careful editing of statements scattered around in the
file, while
the solution in b), based on the ``solver`` function, requires *no modifications*
of the ``ft06_poisson_func.py`` file, just
*minimalistic additional new code* in a separate file. The Poisson solver
remains in one place (``ft06_poisson_func.py``) while in a) we got two
Poisson solvers. If you decide to switch to an iterative solution method
for linear systems, you can do so in one place in b), and all applications
can take advantage of the extension. Hopefully, with this exercise
you realize that embedding
PDE solvers in functions (or classes) makes more reusable software than
flat programs.

.. --- end exercise ---

.. --- begin exercise ---

.. _ch:poisson0:exer:membrane:

Exercise 3: Refactor the code for membrane deflection
-----------------------------------------------------

The ``ft02_membrane.py`` program simulates the deflection of
a membrane. Refactor this code such that we have a ``solver`` function
as in the ``ft06_poisson_func.py`` file. Let the user have the
option to choose a direct or iterative solver for the linear system.
Also implement a unit test where you have :math:`p=4` (constant) and
use P2 and P3 elements. In this case, the exact solution is
quadratic in :math:`x` and :math:`y` and will be "exactly" reproduced by
P2 and higher-order elements.

.. --- begin solution of exercise ---

**Solution.**
We can use the ``solver`` function from ``ft06_poisson_func.py``
right away. The major difference is that
the domain is now a circle and not a square. We change the ``solver``
function by letting the mesh be an argument ``mesh`` (instead of ``Nx``
and ``Ny``):

.. code-block:: python

    def solver(
        f, u_b, mesh, degree=1,
        linear_solver='Krylov', # Alt: 'direct'
        ...):
        V = FunctionSpace(mesh, 'P', degree)
        # code as before

The complete code becomes

.. code-block:: python

    def application(beta, R0, num_elements_radial_dir):
        # Scaled pressure function
        p = Expression(
            '4*exp(-pow(beta,2)*(pow(x[0], 2) + pow(x[1]-R0, 2)))',
            beta=beta, R0=R0)
    
        # Generate mesh over the unit circle
        domain = Circle(Point(0.0, 0.0), 1.0)
        mesh = generate_mesh(domain, num_elements_radial_dir)
    
        w = solver(p, Constant(0), mesh, degree=1,
                   linear_solver='direct')
        w.rename('w', 'deflection')  # set name and label (description)
    
        # Plot scaled solution, mesh and pressure
        plot(mesh, title='Mesh over scaled domain')
        plot(w, title='Scaled ' + w.label())
        V = w.function_space()
        p = interpolate(p, V)
        p.rename('p', 'pressure')
        plot(p, title='Scaled ' + p.label())
    
        # Dump p and w to file in VTK format
        vtkfile1 = File('membrane_deflection.pvd')
        vtkfile1 << w
        vtkfile2 = File('membrane_load.pvd')
        vtkfile2 << p

The key function to simulate membrane deflection is named ``application``.

For :math:`p=4`, we have :math:`w=1-x^2-y^2` as exact solution.
The unit test for P2 and P3 goes as follows:

.. code-block:: python

    def test_membrane():
        """Verification for constant pressure."""
        p = Constant(4)
        # Generate mesh over the unit circle
        domain = Circle(Point(0.0, 0.0), 1.0)
        for degree in 2, 3:
            print('********* P%d elements:' % degree)
            n = 5
            for i in range(4):  # Run some resolutions
                n *= (i+1)
                mesh = generate_mesh(domain, n)
                #info(mesh)
                w = solver(p, Constant(0), mesh, degree=degree,
                           linear_solver='direct')
                print('max w: %g, w(0,0)=%g, h=%.3E, dofs=%d' %
                      (w.vector().array().max(), w((0,0)),
                       1/np.sqrt(mesh.num_vertices()),
                       w.function_space().dim()))
    
                w_exact = Expression('1 - x[0]*x[0] - x[1]*x[1]')
                w_e = interpolate(w_exact, w.function_space())
                error = np.abs(w_e.vector().array() -
                               w.vector().array()).max()
                print('error: %.3E' % error)
                assert error < 9.61E-03
    
    def application2(
        beta, R0, num_elements_radial_dir):
        """Explore more built-in visulization features."""
        # Scaled pressure function
        p = Expression(
            '4*exp(-pow(beta,2)*(pow(x[0], 2) + pow(x[1]-R0, 2)))',
            beta=beta, R0=R0)
    
        # Generate mesh over the unit circle
        domain = Circle(Point(0.0, 0.0), 1.0)
        mesh = generate_mesh(domain, num_elements_radial_dir)
    
        w = solver(p, Constant(0), mesh, degree=1,
                   linear_solver='direct')
        w.rename('w', 'deflection')
    
        # Plot scaled solution, mesh and pressure
        plot(mesh, title='Mesh over scaled domain')
        viz_w = plot(w,
                     wireframe=False,
                     title='Scaled membrane deflection',
                     axes=False,
                     interactive=False,
                     )
        viz_w.elevate(-10) # adjust (lift) camera from default view
        viz_w.plot(w)      # bring new settings into action
        viz_w.write_png('deflection')
        viz_w.write_pdf('deflection')
    
        V = w.function_space()
        p = interpolate(p, V)
        p.rename('p', 'pressure')
        viz_p = plot(p, title='Scaled pressure', interactive=False)
        viz_p.elevate(-10)
        viz_p.plot(p)
        viz_p.write_png('pressure')
        viz_p.write_pdf('pressure')
    
        # Dump w and p to file in VTK format
        vtkfile1 = File('membrane_deflection.pvd')
        vtkfile1 << w
        vtkfile2 = File('membrane_load.pvd')
        vtkfile2 << p

The striking feature is that the solver does not reproduce the solution
to an accuracy more than about 0.01 (!), regardless of the resolution and
type of element.

.. --- end solution of exercise ---

Filename: ``membrane_func``.

.. --- end exercise ---

.. Or Useful extensions and recipies?

Working with linear solvers
===========================

Sparse LU decomposition (Gaussian elimination) is used by default to
solve linear systems of equations in FEniCS programs.  This is a very
robust and recommended method for a few thousand unknowns in the
equation system, and may hence be the method of choice in many 2D and
smaller 3D problems. However, sparse LU decomposition becomes slow and
memory demanding in large problems.  This fact forces the use of
iterative methods, which are faster and require much less memory.
The forthcoming text tells you how to
take advantage of state-of-the-art iterative solution methods in FEniCS.

.. _ch:poisson0:solve:prm:

Controlling the solution process
--------------------------------

Setting linear solver parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Preconditioned Krylov solvers is a type of popular iterative methods
that are easily accessible in FEniCS programs. The Poisson equation
results in a symmetric, positive definite coefficient matrix, for
which the optimal Krylov solver is the Conjugate Gradient (CG)
method. However, the CG method requires boundary conditions to be
implemented in a symmetric way. This is not the case by default, so
then a Krylov solver for non-symmetric system, such as GMRES, is a
better choice.  Incomplete LU factorization (ILU) is a popular and
robust all-round preconditioner, so let us try the GMRES-ILU pair:

.. code-block:: python

    solve(a == L, u, bc)
          solver_parameters={'linear_solver': 'gmres',
                             'preconditioner': 'ilu'})
    # Alternative syntax
    solve(a == L, u, bc,
          solver_parameters=dict(linear_solver='gmres',
                                 preconditioner='ilu'))

the section :ref:`ftut:app:solver:prec` lists the most popular choices of
Krylov solvers and preconditioners available in FEniCS.

.. index:: linear algebra backend

.. index:: PETSc

.. index:: Trilinos

.. index:: MTL4

.. index:: uBLAS

Linear algebra backend
~~~~~~~~~~~~~~~~~~~~~~

The actual GMRES and ILU implementations that are brought into action
depends on the choice of linear algebra package. FEniCS interfaces
several linear algebra packages, called *linear algebra backends* in
FEniCS terminology.  PETSc is the default choice if FEniCS is compiled
with PETSc, otherwise uBLAS.  Epetra (Trilinos), Eigen, MTL4 are other
supported backends. Which backend to apply can be controlled by
setting

.. code-block:: python

    parameters['linear_algebra_backend'] = backendname

where ``backendname`` is a string, either ``'Eigen'``, ``'PETSc'``, ``'uBLAS'``,
``'Epetra'``, or ``'MTL4'``.  All these backends offer high-quality
implementations of both iterative and direct solvers for linear systems
of equations.

.. index:: UMFPACK

A common platform for FEniCS users is Ubuntu Linux.  The FEniCS
distribution for Ubuntu contains PETSc, making this package the
default linear algebra backend.  The default solver is sparse LU
decomposition (``'lu'``), and the actual software that is called is then
the sparse LU solver from UMFPACK (which PETSc has an interface
to). The available linear algebra backends in a FEniCS installation is
listed by

.. code-block:: python

    list_linear_algebra_backends()

.. index:: parameters database

.. index:: info function

The ``parameters`` database
~~~~~~~~~~~~~~~~~~~~~~~~~~~

We will normally like to control the tolerance in the stopping
criterion and the maximum number of iterations when running an
iterative method.  Such parameters can be set by accessing the *global
parameter database*, which is called ``parameters`` and which behaves as
a nested dictionary. Write

.. code-block:: python

    info(parameters, verbose=True)

to list all parameters and their default values in the database.
The nesting of parameter sets is indicated through indentation in the
output from ``info``.
According to this output, the relevant parameter set is
named ``'krylov_solver'``, and the parameters are set like this:

.. code-block:: python

    prm = parameters['krylov_solver']  # short form
    prm['absolute_tolerance'] = 1E-10
    prm['relative_tolerance'] = 1E-6
    prm['maximum_iterations'] = 1000

Stopping criteria for Krylov solvers usually involve the norm of
the residual, which must be smaller than the absolute tolerance
parameter *or* smaller than the relative tolerance parameter times
the initial residual.

To get a printout of the number of actual iterations to reach the
stopping criterion, we can insert

.. code-block:: python

    set_log_level(PROGRESS)
    # or
    set_log_level(DEBUG)

A message with the equation system size, solver type, and number of
iterations arises from specifying the argument ``PROGRESS``, while
``DEBUG`` results in more information, including CPU time spent in
the various parts of the matrix assembly and solve process.

We remark that default values for the global parameter database can be
defined in an XML file. To generate such a file from the current set
of parameters in a program, run

.. code-block:: python

    File('fenics_parameters.xml') << parameters

If a ``fenics_parameters.xml`` file is found in the directory where a
FEniCS program is run, this file is read and used to initialize the
``parameters`` object. Otherwise, the file
``.config/fenics/fenics_parameters.xml`` in the user's home directory is
read, if it exists.  Another alternative is to load the XML (with any
name) manually in the program:

.. code-block:: python

    File('fenics_parameters.xml') >> parameters

The XML file can also be in gzip'ed form with the extension ``.xml.gz``.

.. index:: ft07_poisson_iter.py

An extended solver function
~~~~~~~~~~~~~~~~~~~~~~~~~~~

We may extend the previous solver function from
``ft06_poisson_func.py`` in the section :ref:`ch:poisson0:impl2:func`
such that it also offers the GMRES+ILU
preconditioned Krylov solver:

.. code-block:: python

    def solver(
        f, u_b, Nx, Ny, degree=1,
        linear_solver='Krylov', # Alt: 'direct'
        abs_tol=1E-5,           # Absolute tolerance in Krylov solver
        rel_tol=1E-3,           # Relative tolerance in Krylov solver
        max_iter=1000,          # Max no of iterations in Krylov solver
        log_level=PROGRESS,     # Amount of solver output
        dump_parameters=False,  # Write out parameter database?
        ):
        ...
        # Set up variational problem: a, L, declare u, etc.
    
        if linear_solver == 'Krylov':
            prm = parameters['krylov_solver'] # short form
            prm['absolute_tolerance'] = abs_tol
            prm['relative_tolerance'] = rel_tol
            prm['maximum_iterations'] = max_iter
            print(parameters['linear_algebra_backend'])
            set_log_level(log_level)
            if dump_parameters:
                info(parameters, True)
            solver_parameters = {'linear_solver': 'gmres',
                                 'preconditioner': 'ilu'}
        else:
            solver_parameters = {'linear_solver': 'lu'}
    
        solve(a == L, u, bc, solver_parameters=solver_parameters)
        return u

This new ``solver`` function, found in the file
``ft07_poisson_iter.py``, replaces the one in ``ft06_poisson_func.py``:
it has all the functionality of the previous ``solver`` function,
but can also solve the linear system with
iterative methods and report the progress of such solvers.

Remark regarding unit tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Regarding verification of the new ``solver`` function in terms of unit
tests, it turns out that unit testing in a problem where the
approximation error vanishes is gets more complicated when we use
iterative methods. The problem is to keep the error due to iterative
solution smaller than the tolerance used in the verification
tests. First of all this means that the tolerances used in the Krylov
solvers must be smaller than the tolerance used in the ``assert`` test,
but this is no guarantee to keep the linear solver error this small.
For linear elements and small meshes, a tolerance of :math:`10^{-11}` works
well in the case of Krylov solvers too (using a tolerance :math:`10^{-12}`
in those solvers. However, as soon as we switch to P2 elements, it is
hard to force the linear solver error below :math:`10^{-6}`. Consequently,
tolerances in tests depend on the numerical methods. The interested
reader is referred to the ``test_solver`` function in
``ft07_poisson_iter.py`` for details: this test function tests the
numerical solution for direct and iterative linear solvers, for
different meshes, and different degrees of the polynomials in the
finite element basis functions.

.. _ftut:app:solver:prec:

Linear solvers and preconditioners
----------------------------------

The following solution methods for linear
systems can be accessed in FEniCS programs:

================  ============================================  
      Name                           Method                     
================  ============================================  
``'lu'``          sparse LU factorization (Gaussian elim.)      
``'cholesky'``    sparse Cholesky factorization                 
``'cg'``          Conjugate gradient method                     
``'gmres'``       Generalized minimal residual method           
``'bicgstab'``    Biconjugate gradient stabilized method        
``'minres'``      Minimal residual method                       
``'tfqmr'``       Transpose-free quasi-minimal residual method  
``'richardson'``  Richardson method                             
================  ============================================  

Possible choices of preconditioners include

======================  ==========================================  
         Name                             Method                    
======================  ==========================================  
``'none'``              No preconditioner                           
``'ilu'``               Incomplete LU factorization                 
``'icc'``               Incomplete Cholesky factorization           
``'jacobi'``            Jacobi iteration                            
``'bjacobi'``           Block Jacobi iteration                      
``'sor'``               Successive over-relaxation                  
``'amg'``               Algebraic multigrid (BoomerAMG or ML)       
``'additive_schwarz'``  Additive Schwarz                            
``'hypre_amg'``         Hypre algebraic multigrid (BoomerAMG)       
``'hypre_euclid'``      Hypre parallel incomplete LU factorization  
``'hypre_parasails'``   Hypre parallel sparse approximate inverse   
``'ml_amg'``            ML algebraic multigrid                      
======================  ==========================================  

Many of the choices listed above
are only offered by a specific backend, so setting the backend
appropriately is necessary for being able to choose a desired
linear solver or preconditioner. You can also use constructions like

.. code-block:: python

    prec = 'amg' if has_krylov_solver_preconditioner('amg') \ 
           else 'default'

An up-to-date list of the available solvers and preconditioners
in FEniCS can be produced by

.. code-block:: python

    list_linear_solver_methods()
    list_krylov_solver_preconditioners()

.. _ch:poisson0:solver:problem:

Linear variational problem and solver objects
---------------------------------------------

.. index:: LinearVariationalProblem

.. index:: LinearVariationalSolver

.. index:: ft07_poisson_iter.py

The ``solve(a == L, u, bc)`` call is just a compact syntax alternative to a
slightly more comprehensive specification of the variational equation
and the solution of the associated linear system.  This alternative
syntax is used in a lot of FEniCS applications and will also be
used later in this tutorial, so we show it already now:

.. code-block:: python

    u = Function(V)
    problem = LinearVariationalProblem(a, L, u, bc)
    solver  = LinearVariationalSolver(problem)
    solver.solve()

Many objects have an attribute ``parameters`` corresponding to
a parameter set in the global ``parameters`` database,
but local to the object. Here, ``solver.parameters`` play that
role. Setting the CG method with ILU preconditioning as solution
method and specifying solver-specific parameters can be done
like this:

.. code-block:: python

    solver.parameters['linear_solver'] = 'gmres'
    solver.parameters['preconditioner'] = 'ilu'
    prm = solver.parameters['krylov_solver'] # short form
    prm['absolute_tolerance'] = 1E-7
    prm['relative_tolerance'] = 1E-4
    prm['maximum_iterations'] = 1000

Settings in the global ``parameters`` database are
propagated to parameter sets in individual objects, with the
possibility of being overwritten as done above.

The linear variational problem and solver objects as outlined above
are incorporated in an alternative solver function, named
``solver_objects``, in
``ft07_poisson_iter.py``. Otherwise, this function is parallel to the
previously shown ``solver`` function.

.. _ch:poisson0:linalg:

Creating the linear system explicitly
-------------------------------------

[**hpl 35**: This is already explained for Navier - Stokes now!]

Given :math:`a(u,v)=L(v)`, the discrete solution :math:`u` is computed by
inserting :math:`u=\sum_{j=1}^N U_j \phi_j` into :math:`a(u,v)` and demanding
:math:`a(u,v)=L(v)` to be fulfilled for :math:`N` test functions
:math:`\hat\phi_1,\ldots,\hat\phi_N`. This implies

.. math::
        
        \sum_{j=1}^N a(\phi_j,\hat\phi_i) U_j = L(\hat\phi_i),\quad i=1,\ldots,N,
        

which is nothing but a linear system,

.. math::
        
          AU = b,
        

where the entries in :math:`A` and :math:`b` are given by

.. math::
        
          A_{ij} &= a(\phi_j, \hat{\phi}_i), \\ 
          b_i &= L(\hat\phi_i){\thinspace .}
        

.. index:: assemble

.. index:: linear systems (in FEniCS)

.. index:: assembly of linear systems

The examples so far have specified the left- and right-hand side of
the variational formulation and then asked FEniCS to assemble the
linear system and solve it.  An alternative is to explicitly call
functions for assembling the coefficient matrix :math:`A` and the right-side
vector :math:`b`, and then solve the linear system :math:`AU=b` with respect to
the :math:`U` vector.  Instead of ``solve(a == L, u, b)`` we now write

.. code-block:: python

    A = assemble(a)
    b = assemble(L)
    bc.apply(A, b)
    u = Function(V)
    U = u.vector()
    solve(A, U, b)

The variables ``a`` and ``L`` are as before. That is, ``a`` refers to the
bilinear form involving a ``TrialFunction`` object (e.g., ``u``)
and a ``TestFunction`` object (``v``), and ``L`` involves a
``TestFunction`` object (``v``). From ``a`` and ``L``,
the ``assemble`` function can
compute :math:`A` and :math:`b`.

The matrix :math:`A` and vector :math:`b` are first assembled without incorporating
essential (Dirichlet) boundary conditions. Thereafter, the
call ``bc.apply(A, b)`` performs the necessary modifications of
the linear system such that ``u`` is guaranteed to equal the prescribed
boundary values.
When we have multiple Dirichlet conditions stored in a list ``bcs``,
as explained in the section :ref:`ch:poisson0:multiple:Dirichlet`, we must apply
each condition in ``bcs`` to the system:

.. code-block:: python

    # bcs is a list of DirichletBC objects
    for bc in bcs:
        bc.apply(A, b)

.. index:: assemble_system

There is an alternative function ``assemble_system``, which can
assemble the system and take boundary conditions into account in one call:

.. code-block:: python

    A, b = assemble_system(a, L, bcs)

The ``assemble_system`` function incorporates the boundary conditions
in the element matrices and vectors, prior to assembly.
The conditions are also incorporated in a symmetric way to preserve
eventual symmetry of the coefficient matrix.

.. That is, for each degree of freedom

.. that is known, the corresponding row and column is zero'ed out and 1

.. is placed on the main diagonal, and the right-hand side ``b`` is

.. modified by subtracting the column in ``A`` times the value of the

.. degree of, and then the corresponding entry in ``b`` is replaced by the

.. known value of the degree of freedom.

With ``bc.apply(A, b)`` the
matrix ``A`` is modified in an nonsymmetric way.

.. : The row is zero'ed out

.. and 1 is placed on the main diagonal, and the degree of freedom value

.. is inserted in ``b``.

Note that the solution ``u`` is, as before, a ``Function`` object.
The degrees of freedom, :math:`U=A^{-1}b`, are filled
into ``u``'s ``Vector`` object (``u.vector()``)
by the ``solve`` function.

The object ``A`` is of type ``Matrix``, while ``b`` and
``u.vector()`` are of type ``Vector``. We may convert the
matrix and vector data to ``numpy`` arrays by calling the
``array()`` method as shown before. If you wonder how essential
boundary conditions are incorporated in the linear system, you can
print out ``A`` and ``b`` before and after the
``bc.apply(A, b)`` call:

.. code-block:: python

    A = assemble(a)
    b = assemble(L)
    if mesh.num_cells() < 16:  # print for small meshes only
        print(A.array())
        print(b.array())
    bc.apply(A, b)
    if mesh.num_cells() < 16:
        print(A.array())
        print(b.array())

With access to the elements in ``A`` through a ``numpy`` array we can easily
perform computations on this matrix, such as computing the eigenvalues
(using the ``eig`` function in ``numpy.linalg``). We can alternatively dump
``A.array()`` and ``b.array()`` to file in MATLAB format and invoke
MATLAB or Octave to analyze the linear system.
Dumping the arrays to MATLAB format is done by

.. code-block:: python

    import scipy.io
    scipy.io.savemat('Ab.mat', {'A': A.array(), 'b': b.array()})

Writing ``load Ab.mat`` in MATLAB or Octave will then make
the array variables ``A`` and ``b`` available for computations.

.. index:: SLEPc

Matrix processing in Python or MATLAB/Octave is only feasible for
small PDE problems since the ``numpy`` arrays or matrices in MATLAB
file format are dense matrices. FEniCS also has an interface to the
eigensolver package SLEPc, which is a preferred tool for computing the
eigenvalues of large, sparse matrices of the type encountered in PDE
problems (see ``demo/la/eigenvalue`` in the FEniCS source code tree
for a demo).

By default, ``solve(A, U, b)`` applies sparse LU decomposition
as solver. Specification of an iterative solver and preconditioner
is done through two optional arguments:

.. code-block:: python

    solve(A, U, b, 'cg', 'ilu')

Appropriate names of solvers and preconditioners are found in
the section :ref:`ftut:app:solver:prec`.

.. index:: KrylovSolver

To control tolerances in the stopping criterion and the maximum
number of iterations, one can explicitly form a ``KrylovSolver`` object
and set items in its ``parameters`` attribute
(see also the section :ref:`ch:poisson0:solver:problem`):

.. code-block:: python

    solver = KrylovSolver('cg', 'ilu')
    prm = solver.parameters
    prm['absolute_tolerance'] = 1E-7
    prm['relative_tolerance'] = 1E-4
    prm['maximum_iterations'] = 1000
    u = Function(V)
    U = u.vector()
    set_log_level(DEBUG)
    solver.solve(A, U, b)

The function ``solver_linalg`` in the
program file ``ft08_poisson_vc.py`` implements a solver function where
the user can choose between different types of assembly: the variational
(``solve(a == L, u, bc)``), assembling the matrix and right-hand side separately, and assembling the system such that the coefficient matrix preserves
symmetry.
The function ``application_linalg`` runs a test problem on sequence of
meshes and solves the problem with symmetric and non-symmetric modification
of the coefficient matrix. One can monitor the number of Krylov
method iteration and realize that with a symmetric coefficient matrix,
the Conjugate Gradient method requires slightly fewer iterations than
GMRES in the non-symmetric case. Taking into account that the Conjugate
Gradient method has less work per iteration, there is some efficiency to
be gained by using ``assemble_system``.

[**hpl 36**: Running ``application_linalg``, the results are strange: Why does the ``solve(a==L,...)`` method need many more iterations than ``solve(A, U, b, ...)`` when we use the same Krylov parameter settings? Something wrong with the settings?]

.. index:: random start vector (linear systems)

The choice of start vector for the iterations in a linear solver is often
important. With the ``solver.solve(A, U, b)`` call the default start vector
is the zero vector. A start vector
with random numbers in the interval :math:`[-100,100]` can be computed as

.. code-block:: python

    n = u.vector().array().size
    U = u.vector()
    U[:] = numpy.random.uniform(-100, 100, n)
    solver.parameters['nonzero_initial_guess'] = True
    solver.solve(A, U, b)

Note that we must turn off the default behavior of setting the start
vector ("initial guess") to zero, and then the provided value of ``U``
is used as start vector.

Creating the linear system explicitly in a program can have some
advantages in more advanced problem settings. For example, :math:`A` may
be constant throughout a time-dependent simulation, so we can avoid
recalculating :math:`A` at every time level and save a significant amount
of simulation time.

.. In other problems, we may divide the variational

.. problem and linear system into different terms, say :math:`A=M + {{\Delta t}} K`,

.. where :math:`M` is a matrix arising from a term like :math:`\partial u/\partial t`,

.. :math:`K` is a term corresponding to a Laplace operator, and :math:`{\Delta t}` is

.. a time discretization parameter. When :math:`{\Delta t}` is changed in time,

.. we can efficiently recompute :math:`A = M + {{\Delta t}} K` without

.. reassembling the constant matrices :math:`M` and :math:`K`. This strategy may

.. speed up simulations significantly.

.. _ftut:possion:2D:varcoeff:

A variable-coefficient Poisson problem
======================================

.. index:: Poisson's equation with variable coefficient

.. index:: ft08_poisson_vc.py

Suppose we have a variable coefficient :math:`p(x,y)` in the Laplace operator,
as in the boundary-value problem

.. _Eq:ch:poisson0:2D:varcoeff:

.. math::

    \tag{56}
    - \nabla\cdot \left\lbrack
        p(x,y)\nabla u(x,y)\right\rbrack &= f(x,y) \quad \mbox{in } \Omega,
            \\ 
            u(x,y) &= u_{\mathrm{b}}(x,y) \quad \mbox{on}\  \partial\Omega{\thinspace .}
          
        

We shall quickly demonstrate that this simple extension of our model
problem only requires an equally simple extension of the FEniCS program.

Test problem          (4)
~~~~~~~~~~~~~~~~~~~~~~~~~

Let us continue to use our favorite solution :math:`u(x,y)=1+x^2+2y^2` and
then prescribe :math:`p(x,y)=x+y`. It follows that
:math:`u_{\mathrm{b}}(x,y) = 1 + x^2 + 2y^2` and :math:`f(x,y)=-8x-10y`.

Modifications of the PDE solver
-------------------------------

What are the modifications we need to do in the previously shown codes
to incorporate the variable coefficient :math:`p`?
from the section :ref:`ch:poisson0:verify1`?

  * ``solver`` must take ``p`` as argument,

  * ``f`` in our test problem
    must be an ``Expression`` since it is no longer a constant,

  * a new ``Expression p`` must be defined for the variable coefficient,

  * the formula for :math:`a(u,v)` in the variational problem is slightly changed.

First we address the modified variational problem. Multiplying
the PDE by a test function :math:`v` and
integrating by parts now results
in

.. math::
        
        \int_\Omega p\nabla u\cdot\nabla v {\, \mathrm{d}x} -
        \int_{\partial\Omega} p{\partial u\over
        \partial n}v {\, \mathrm{d}s} = \int_\Omega fv {\, \mathrm{d}x}{\thinspace .}
        

The function spaces for :math:`u` and :math:`v` are the same as in
the problem with :math:`p=1`, implying that the boundary integral
vanishes since :math:`v=0` on :math:`\partial\Omega` where we have Dirichlet conditions.
The weak form :math:`a(u,v)=L(v)` then has

.. _Eq:_auto12:

.. math::

    \tag{57}
    a(u,v) = \int_\Omega p\nabla u\cdot\nabla v {\, \mathrm{d}x},\quad
        L(v) = \int_\Omega fv {\, \mathrm{d}x}{\thinspace .}
        
        

In the code for solving :math:`-\nabla^2u=f` we must replace

.. code-block:: python

    a = dot(grad(u), grad(v))*dx

by

.. code-block:: python

    a = p*dot(grad(u), grad(v))*dx

to solve :math:`-\nabla\cdot(p\nabla u)=f`. Moreover,
the definitions of ``p`` and ``f`` in the test problem read

.. code-block:: python

    p = Expression('x[0] + x[1]')
    f = Expression('-8*x[0] - 10*x[1]')

No additional modifications are necessary. The file
``ft08_poisson_vc.py`` (variable-coefficient Poisson problem in 2D)
is a copy of ``ft07_poisson_iter.py`` with the mentioned changes
incorporated. Observe that :math:`p=1` recovers the original problem in
``ft07_poisson_iter.py``.

You can run it and confirm
that it recovers the exact :math:`u` at the nodes.

.. _ch:poisson0:gradu:

Flux computations
-----------------

.. index:: projection

The flux :math:`-p\nabla u` is often of interest to compute. The formula is simple:
since
:math:`u = \sum_{j=1}^N U_j \phi_j`, we have that

.. math::
        
        -p\nabla u = -p\sum_{j=1}^N U_j \nabla \phi_j{\thinspace .}
        

Given the solution variable ``u`` in the program, its gradient is
obtained by ``grad(u)`` or ``grad(u)``.  However, the gradient of a
piecewise continuous finite element scalar field is a discontinuous
vector field since the :math:`\phi_j` has discontinuous derivatives at the
boundaries of the cells. For example, using Lagrange elements of
degree 1, :math:`u` is linear over each cell, and the numerical :math:`\nabla u`
becomes a piecewise constant vector field. On the contrary, the exact
gradient is continuous.  For visualization and data analysis purposes
we often want the computed gradient to be a continuous vector
field. Typically, we want each component of :math:`\nabla u` to be
represented in the same way as :math:`u` itself. To this end, we can project
the components of :math:`\nabla u` onto the same function space as we used
for :math:`u`.  This means that we solve :math:`w = \nabla u` approximately by a
finite element method, using the same elements for the components of
:math:`w` as we used for :math:`u`. This process is known as *projection*.

.. index:: project

.. index:: projection

Not surprisingly, projection is a so common operation in finite
element programs that FEniCS has a function for doing the task:
``project(q, W)``, which returns the projection of some ``Function`` or
``Expression`` object named ``q`` onto the ``FunctionSpace`` (if ``q`` is
scalar) or ``VectorFunctionSpace`` (if ``q`` is vector-valued) named ``W``.
Specifically, in our case where ``u`` is computed and we want to project
the vector-valued :math:`\nabla u` and :math:`-p\nabla u`
onto the ``VectorFunctionSpace`` where each
component has the same ``Function`` space as ``u``:

.. code-block:: python

    V = u.function_space()
    degree = u.ufl_element().degree()
    W = VectorFunctionSpace(V.mesh(), 'P', degree)
    
    grad_u = project(grad(u), W)
    flux_u = project(-p*grad(u), W)

.. Figure :ref:`ch:poisson0:2D:fig:ex1:gradu` shows

.. example of how such a smoothed ``gradu(u)`` vector field is visualized.

.. FIGURE:[fig/ex1_gradu, width=480] Example of visualizing the vector field :math:`\nabla u` by arrows at the nodes.

An appropriate function for computing the flux based on ``u`` and ``p`` is

.. code-block:: python

    def flux(u, p):
        """Return p*grad(u) projected onto same space as u."""
        V = u.function_space()
        mesh = V.mesh()
        degree = u.ufl_element().degree()
        V_g = VectorFunctionSpace(mesh, 'P', degree)
        flux_u = project(-p*grad(u), V_g)
        flux_u.rename('flux(u)', 'continuous flux field')
        return flux_u

The applications of projection are many, including turning discontinuous
gradient fields into continuous ones, comparing higher- and lower-order
function approximations, and transforming a higher-order finite element
solution down to a piecewise linear field, which is required by many
visualization packages.

Plotting the flux vector field is naturally as easy as plotting
anything else:

.. code-block:: python

    plot(flux, title='flux field')
    
    flux_x, flux_y = flux.split(deepcopy=True)  # extract components
    plot(flux_x, title='x-component of flux (-p*grad(u))')
    plot(flux_y, title='y-component of flux (-p*grad(u))')

The ``deepcopy=True`` argument signifies a *deep copy*, which is
a general term in computer science implying that a copy of the data is
returned. (The opposite, ``deepcopy=False``,
means a *shallow copy*, where
the returned objects are just pointers to the original data.)

.. index:: degrees of freedom array

.. index:: nodal values array

.. index:: degrees of freedom array (vector field)

For data analysis of the nodal values of the flux field we can
grab the underlying ``numpy`` arrays (demands a ``deepcopy=True``
in the split of ``flux``):

.. code-block:: python

    flux_x_array = flux_x.vector().array()
    flux_y_array = flux_y.vector().array()

The degrees of freedom of the ``flux_u`` vector field can also be
reached by

.. code-block:: python

    flux_u_array = flux_u.vector().array()

but this is a flat ``numpy`` array where the degrees of freedom for the
:math:`x` component of the flux is stored in the first part, then the
degrees of freedom of the :math:`y` component, and so on. This is less convenient
to work with.

The function ``application_test_flux`` in the
program ``ft08_poisson_vc.py`` demonstrates the computations described
above.

[**hpl 37**: Not sure if we should use paper space on the box below. Could be in extended material only.]


.. admonition:: Detour: Manual projection

   Although you will always use ``project`` to project a finite element
   function, it can be constructive this point in the tutorial to formulate the
   projection mathematically and implement its steps manually in FEniCS.
   
   Looking at the component :math:`\partial u/\partial x` of the gradient, we
   project the (discrete) derivative :math:`\sum_jU_j{\partial \phi_j/\partial
   x}` onto a function space with basis :math:`\phi_1,\phi_2,\ldots` such that
   the derivative in this space is expressed by the standard sum
   :math:`\sum_j\bar U_j \phi_j`, for suitable (new) coefficients :math:`\bar U_j`.
   
   The variational problem for :math:`w` reads: find  :math:`w\in V^{(\mbox{g})}` such that
   
   .. _Eq:_auto13:

.. math::

    \tag{58}
    a(w, v) = L(v)\quad\forall v\in \hat{V^{(\mbox{g})}},
           
           
   
   where
   
   .. _Eq:_auto14:

.. math::

    \tag{59}
    a(w, v) = \int_\Omega w\cdot v {\, \mathrm{d}x},
           
           
   
   .. _Eq:_auto15:

.. math::

    \tag{60}
    L(v) = \int_\Omega \nabla u\cdot v {\, \mathrm{d}x}{\thinspace .}
           
           
   
   The function spaces :math:`V^{(\mbox{g})}` and :math:`\hat{V^{(\mbox{g})}}` (with the superscript g
   denoting "gradient") are vector versions of the function space for
   :math:`u`, with boundary conditions removed (if :math:`V` is the space we used for
   :math:`u`, with no restrictions on boundary values, :math:`V^{(\mbox{g})} = \hat{V^{(\mbox{g})}} =
   [V]^d`, where :math:`d` is the number of space dimensions).  For example, if
   we used piecewise linear functions on the mesh to approximate :math:`u`, the
   variational problem for :math:`w` corresponds to approximating each
   component field of :math:`w` by piecewise linear functions.
   
   The variational problem for the vector field
   :math:`w`, called ``grad_u`` in the code, is easy to solve in FEniCS:
   
   .. code-block:: python
   
       V_g = VectorFunctionSpace(mesh, 'P', 1)
       w = TrialFunction(V_g)
       v = TestFunction(V_g)
       
       a = dot(w, v)*dx
       L = dot(grad(u), v)*dx
       grad_u = Function(V_g)
       solve(a == L, grad_u)
       
       plot(grad_u, title='grad(u)')
   
   The boundary condition argument to ``solve`` is dropped since there are
   no essential boundary conditions in this problem.
   The new thing is basically that we work with a ``VectorFunctionSpace``,
   since the unknown is now a vector field, instead of the
   ``FunctionSpace`` object for scalar fields.




.. _ftut:structviz:

Taking advantage of structured mesh data
----------------------------------------

.. index:: structured mesh

.. index::
   single: visualization, structured mesh

.. index:: scitools

When finite element computations are done on a structured rectangular
mesh, maybe with uniform partitioning, VTK-based tools for completely
unstructured 2D/3D meshes are not required.  Instead we can use
visualization and data analysis tools for *structured data*.
Such data typically appear in finite difference simulations and
image analysis.  Analysis and visualization of structured data are faster
and easier than doing the same with data on unstructured meshes, and
the collection of tools to choose among is much larger.  We shall
demonstrate the potential of such tools and how they allow for
tailored and flexible visualization and data analysis.

.. index:: BoxField

A necessary first step is to transform our ``mesh`` object to an object
representing a rectangle with equally-shaped *rectangular* cells.  The
second step is to transform the one-dimensional array of nodal values
to a two-dimensional array holding the values at the corners of the
cells in the structured mesh. We want to access a value by its :math:`i` and
:math:`j` indices, :math:`i` counting cells in the :math:`x` direction, and :math:`j` counting
cells in the :math:`y` direction.  This transformation is in principle
straightforward, yet it frequently leads to obscure indexing errors,
so using software tools to ease the work is advantageous.

In the directory ``src/modules``, associated with this booklet, we have
included a Python module ``BoxField`` that can take a finite element
function ``u`` computed by a FEniCS software and represent it on a
structured box-shaped mesh and assign or extract values by
multi-dimensional indexing: ``[i]`` in 1D, ``[i,j]`` in 2D, and ``[i,j,k]``
in 3D. Given a finite element function ``u``, the following function
returns a ``BoxField`` object that represents ``u`` on a structured mesh:

.. code-block:: python

    def structured_mesh(u, divisions):
        """Represent u on a structured mesh."""
        # u must have P1 elements, otherwise interpolate to P1 elements
        u2 = u if u.ufl_element().degree() == 1 else \ 
             interpolate(u, FunctionSpace(mesh, 'P', 1))
        mesh = u.function_space().mesh()
        from BoxField import fenics_function2BoxField
        u_box = fenics_function2BoxField(
            u2, mesh, divisions, uniform_mesh=True)
        return u_box

Note that we can only turn functions on meshes with P1 elements into
``BoxField`` objects, so if ``u`` is based on another element type, we first
interpolate the scalar field onto a mesh with P1 elements. Also note
that to use the
function, we need to know the divisions into cells in the various
spatial directions (``divisions``).

The ``u_box`` object contains several useful data structures:

 * ``u_box.grid``: object for the structured mesh

 * ``u_box.grid.coor[X]``: grid coordinates in ``X=0`` direction

 * ``u_box.grid.coor[Y]``: grid coordinates in ``Y=1`` direction

 * ``u_box.grid.coor[Z]``: grid coordinates in ``Z=2`` direction

 * ``u_box.grid.coorv[X]``: vectorized version of ``u_box.grid.coor[X]``
   (for vectorized computations or surface plotting)

 * ``u_box.grid.coorv[Y]``: vectorized version of ``u_box.grid.coor[Y]``

 * ``u_box.grid.coorv[Z]``: vectorized version of ``u_box.grid.coor[Z]``

 * ``u_box.values``: ``numpy`` array holding the ``u`` values;
   ``u_box.values[i,j]`` holds ``u`` at the mesh point with coordinates 

|    ``(u_box.grid.coor[X], u_box.grid.coor[Y])``

Iterating over points and values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Let us go back to the ``solver`` function in the
``ft08_poisson_vc.py`` code from
the section :ref:`ftut:possion:2D:varcoeff`, compute ``u``, map it onto a
``BoxField`` object for a structured mesh representation, and
write out the coordinates and function values at all mesh points:

.. code-block:: python

    u = solver(p, f, u_b, nx, ny, 1, linear_solver='direct')
    u_box = structured_mesh(u, (nx, ny))
    u_ = u_box.values       # numpy array
    X = 0;  Y = 1           # for indexing in x and y direction
    
    # Iterate over 2D mesh points (i,j)
    print('u_ is defined on a structured mesh with %s points' %
          str(u_.shape))
    for j in range(u_.shape[1]):
        for i in range(u_.shape[0]):
            print('u[%d,%d]=u(%g,%g)=%g' %
                  (i, j,
                   u_box.grid.coor[X][i], u_box.grid.coor[X][j],
                   u_[i,j]))

Finite difference approximations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Note that with ``u_``, we can easily express finite difference approximation
of derivatives:

.. code-block:: python

    x = u_box.grid.coor[X]
    dx = x[1] - x[0]
    u_xx = (u_[i-1,j] - 2*u_[i,j] + u_[i+1,j])/dx**2

.. index:: surface plot (structured mesh)

Surface plot
~~~~~~~~~~~~

The ability to access a finite element field in the way one can access
a finite difference-type of field is handy in many occasions, including
visualization and data analysis.
With Matplotlib we can create a surface plot, see
Figure :ref:`ftut:structviz:fig1` (upper left):

.. code-block:: python

    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    from matplotlib import cm
    fig = plt.figure()
    ax = fig.gca(projection='3d')
    cv = u_box.grid.coorv  # vectorized mesh coordinates
    ax.plot_surface(cv[X], cv[Y], u_, cmap=cm.coolwarm,
                    rstride=1, cstride=1)
    plt.title('Surface plot of solution')

The key issue is to know that the coordinates needed for the surface
plot is in ``u_box.grid.coorv`` and that the values are in ``u_``.

.. _ftut:structviz:fig1:

.. figure:: poisson_vc_structmesh2.png
   :width: 800

   *Various plots of the solution on a structured mesh*

.. index:: contour plot

Contour plot
~~~~~~~~~~~~

A contour plot can also be made by Matplotlib:

.. code-block:: python

    fig = plt.figure()
    ax = fig.gca()
    levels = [1.5, 2.0, 2.5, 3.5]
    cs = ax.contour(cv[X], cv[Y], u_, levels=levels)
    plt.clabel(cs)  # add labels to contour lines
    plt.axis('equal')
    plt.title('Contour plot of solution')

The result appears in Figure :ref:`ftut:structviz:fig1` (upper right).

Curve plot through the mesh
~~~~~~~~~~~~~~~~~~~~~~~~~~~

A handy feature of ``BoxField`` objects is the ability to give a start
point in the grid and a direction, and then extract the field and
corresponding coordinates along the nearest line of mesh points. In 3D fields
one can also extract data in a plane.  Say we want to plot :math:`u` along
the line :math:`y=0.4`. The mesh points, ``x``, and the :math:`u` values
along this line, ``u_val``, are extracted by

.. code-block:: python

    start = (0, 0.4)
    X = 0
    x, u_val, y_fixed, snapped = u_box.gridline(start, direction=X)

The variable ``snapped`` is true if the line had to be snapped onto a
gridline and in that case ``y_fixed`` holds the snapped
(altered) :math:`y` value. To avoid interpolation in the structured mesh,
``snapped`` is in fact *always* true.

A comparison of the numerical and exact solution along the line
:math:`y=0.5` (snapped from :math:`y=0.4`) is made by the following code:

.. code-block:: python

    start = (0, 0.4)
    x, u_val, y_fixed, snapped = u_box.gridline(start, direction=X)
    u_e_val = [u_b((x_, y_fixed)) for x_ in x]
    
    plt.figure()
    plt.plot(x, u_val, 'r-')
    plt.plot(x, u_e_val, 'bo')
    plt.legend(['P1 elements', 'exact'], loc='upper left')
    plt.title('Solution along line y=%g' % y_fixed)
    plt.xlabel('x');  plt.ylabel('u')

See Figure :ref:`ftut:structviz:fig1` (lower left) for the resulting curve plot.

Curve plot of the flux
~~~~~~~~~~~~~~~~~~~~~~

Let us also compare the numerical and
exact flux :math:`-p\partial u/\partial x` along the same line as above:

.. code-block:: python

    flux_u = flux(u, p)
    flux_u_x, flux_u_y = flux_u.split(deepcopy=True)
    
    # Plot the numerical and exact flux along the same line
    flux2_x = flux_u_x if flux_u_x.ufl_element().degree() == 1 \ 
              else interpolate(flux_x,
                   FunctionSpace(u.function_space().mesh(),
                                 'P', 1))
    flux_u_x_box = structured_mesh(flux_u_x, (nx,ny))
    x, flux_u_val, y_fixed, snapped = \ 
       flux_u_x_box.gridline(start, direction=X)
    y = y_fixed
    
    plt.figure()
    plt.plot(x, flux_u_val, 'r-')
    plt.plot(x, flux_u_x_exact(x, y_fixed), 'bo')
    plt.legend(['P1 elements', 'exact'], loc='upper right')
    plt.title('Flux along line y=%g' % y_fixed)
    plt.xlabel('x');  plt.ylabel('u')

The second ``plt.plot`` command
requires a Python function ``flux_u_x_exact(x,y)`` to be
available for the exact flux expression.

Note that Matplotlib is one choice of plotting package. With the unified
interface in the `SciTools package <https://github.com/hplgit/scitools>`__ one
can access Matplotlib, Gnuplot, MATLAB, OpenDX, VisIt, and other plotting
engines through the same API.

.. index:: sympy

Test problem          (5)
~~~~~~~~~~~~~~~~~~~~~~~~~

The graphics referred to in Figure :ref:`ftut:structviz:fig1` correspond to
a test problem with prescribed solution :math:`{u_{\small\mbox{e}}} = H(x)H(y)`, where

.. math::
         H(x) = e^{-16(x-\frac{1}{2})^2}\sin(3\pi x){\thinspace .}

We just fit a function :math:`f(x,y)` in the PDE (can choose :math:`p=1`),
and notice that :math:`u=0` along the
boundary of the unit square. Although it is easy to carry out the
differentiation of :math:`f` by hand and hardcode the resulting expressions
in an ``Expression`` object, a more reliable habit is to use Python's
symbolic computing engine, SymPy, to perform mathematics and
automatically turn formulas into C++ syntax for ``Expression`` objects.
A short introduction was given in
the section :ref:`ftut:nonlinear:Newton:auto`.

We start out with defining the exact solution in ``sympy``:

.. code-block:: python

    from sympy import exp, sin, pi  # for use in math formulas
    import sympy as sym
    H = lambda x: exp(-16*(x-0.5)**2)*sin(3*pi*x)
    x, y = sym.symbols('x[0], x[1]')
    u = H(x)*H(y)

Turning the expression for ``u`` into C or C++ syntax for ``Expression`` objects
needs two steps. First we ask for the C code of the expression,

.. code-block:: python

    u_c = sym.printing.ccode(u)

Printing out ``u_c`` gives (the output is here manually broken into two
lines):

.. code-block:: text

    -exp(-16*pow(x[0] - 0.5, 2) - 16*pow(x[1] - 0.5, 2))*
    sin(3*M_PI*x[0])*sin(3*M_PI*x[1])

The necessary syntax adjustment is replacing
the symbol ``M_PI`` for :math:`\pi` in C/C++ by ``pi`` (or ``DOLFIN_PI``):

.. code-block:: python

    u_c = u_c.replace('M_PI', 'pi')
    u_b = Expression(u_c)

Thereafter, we can progress with the computation of :math:`f = -\nabla\cdot(p\nabla u)`:

.. code-block:: python

    p = 1
    f = sym.diff(-p*sym.diff(u, x), x) + sym.diff(-p*sym.diff(u, y), y)
    f = sym.simplify(f)
    f_c = sym.printing.ccode(f)
    f_c = f_c.replace('M_PI', 'pi')
    f = Expression(f_c)

We also need a Python function for the exact flux :math:`-p\partial u/\partial x`:

.. code-block:: python

    flux_u_x_exact = sym.lambdify([x, y], -p*sym.diff(u, x),
                                  modules='numpy')

It remains to define ``p = Constant(1)`` and set ``nx`` and ``ny`` before calling
``solver`` to compute the finite element solution of this problem.

.. FIGURE: [fig/poisson_vc_structmesh, width=800 frac=1] Various plots of the solution on a structured mesh.

Postprocessing computations
===========================

[**hpl 38**: Need a little intro.]

.. _ch:poisson0:functionals:

Computing functionals
---------------------

.. index:: functionals

After the solution :math:`u` of a PDE is computed, we occasionally want to compute
functionals of :math:`u`, for example,

.. _Eq:ch:poisson0:functionals:energy:

.. math::

    \tag{61}
    {1\over2}||\nabla u||^2 \equiv {1\over2}\int_\Omega \nabla u\cdot \nabla u {\, \mathrm{d}x},
        
        

which often reflects some energy quantity.
Another frequently occurring functional is the error

.. _Eq:ch:poisson0:functionals:error:

.. math::

    \tag{62}
    ||{u_{\small\mbox{e}}}-u|| = \left(\int_\Omega ({u_{\small\mbox{e}}}-u)^2 {\, \mathrm{d}x}\right)^{1/2},
        
        

where :math:`{u_{\small\mbox{e}}}` is the exact solution. The error is of particular
interest when studying convergence properties.  Sometimes the interest
concerns the flux out of a part :math:`\Gamma` of the boundary
:math:`\partial\Omega`,

.. _Eq:ch:poisson0:functionals:flux:

.. math::

    \tag{63}
    F = -\int_\Gamma p\nabla u\cdot\boldsymbol{n} {\, \mathrm{d}s},
        
        

where :math:`\boldsymbol{n}` is an outward unit normal at :math:`\Gamma` and :math:`p` is a
coefficient (see the problem in the section :ref:`ftut:possion:2D:varcoeff`
for a specific example).  All these functionals are easy to compute
with FEniCS, and this section describes how it can be done.

.. index:: energy functional

Energy functional
~~~~~~~~~~~~~~~~~

The integrand of the energy functional
:ref:`(61) <Eq:ch:poisson0:functionals:energy>` is described in the UFL
language in the same manner as we describe weak forms:

.. code-block:: python

    energy = 0.5*dot(grad(u), grad(u))*dx
    E = assemble(energy)

The ``assemble`` call performs the integration.  It is possible to
restrict the integration to subdomains, or parts of the boundary, by
using a mesh function to mark the subdomains as explained in the section :ref:`ch:poisson0:multi:bc`.

.. index:: error functional

Error functional
~~~~~~~~~~~~~~~~

Computation of :ref:`(62) <Eq:ch:poisson0:functionals:error>` is typically done
by

.. code-block:: python

    error = (u - u_exact)**2*dx
    E = sqrt(abs(assemble(error)))

The exact solution :math:`{u_{\small\mbox{e}}}` is here in a ``Function`` or ``Expression``
object ``u_exact``, while ``u`` is the finite element approximation.
(Sometimes, for very small error values, the result of
``assemble(error)`` can be a (very small) negative number, so we have
used ``abs`` in the expression for ``E`` above to ensure a positive value
for the ``sqrt`` function.)

As will be explained and demonstrate in the section :ref:`ch:poisson0:convrates`, the integration of ``(u - u_exact)**2*dx``
can result in too optimistic convergence rates unless one is careful
how ``u_exact`` is transferred onto a mesh. The general recommendation
for reliable error computation is to use the ``errornorm`` function (see
``pydoc fenics.errornorm`` and the section :ref:`ch:poisson0:convrates` for
more information):

.. code-block:: python

    E = errornorm(u_exact, u)

.. index:: flux functional

Flux Functionals
~~~~~~~~~~~~~~~~

To compute flux integrals like :math:`F = -\int_\Gamma p\nabla
u\cdot\boldsymbol{n} {\, \mathrm{d}s}` we need to define the :math:`\boldsymbol{n}` vector,
referred to as *facet normal* in FEniCS. If the surface domain
:math:`\Gamma` in the flux integral is the complete boundary we can perform
the flux computation by

.. code-block:: python

    n = FacetNormal(mesh)
    flux = -p*dot(grad(u), n)*ds
    total_flux = assemble(flux)

Although ``grad(u)`` and ``grad(u)`` are interchangeable in the above
expression when ``u`` is a scalar function, we have chosen to write
``grad(u)`` because this is the right expression if we generalize the
underlying equation to a vector Laplace/Poisson PDE. With ``grad(u)`` we
must in that case write ``dot(n, grad(u))``.

It is possible to restrict the integration to a part of the boundary
using a mesh function to mark the relevant part, as explained in
the section :ref:`ch:poisson0:multi:bc`. Assuming that the part corresponds
to subdomain number ``i``, the relevant syntax for the variational
formulation of the flux is ``-p*dot(grad(u), n)*ds(i)``.

.. _ch:poisson0:convrates:

Computing convergence rates
---------------------------

[**hpl 39**: Newer FEniCS examples have ``dx(degree)``. Should explain that syntax. Also ``Expression(string, degree)``.]

To illustrate error computations and convergence of finite element
solutions, we have included a function ``convergence_rate`` in the
``ft08_poisson_vc.py`` program. This is a tool that is very handy
when verifying finite element codes and will therefore be explained in
detail here.

The :math:`L^2` norm of the error in a finite element approximation :math:`u`,
:math:`{u_{\small\mbox{e}}}` being the exact solution, is given by

Various ways of computing the error
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. math::
         E = \left(\int_\Omega (u_e-u)^2 {\, \mathrm{d}x}\right)^{1/2},

and implemented in FEniCS by

.. code-block:: python

    error = (u - u_e)**2*dx
    E = sqrt(abs(assemble(error)))

Sometimes, for very small error values, the result of
``assemble(error)`` can be a (very small) negative number, so we have
used ``abs`` in the expression for ``E`` above to ensure a positive value
for the ``sqrt`` function.

We remark that ``u_e`` will, in the expression above, be interpolated
onto the function space ``V`` before ``assemble`` can perform the
integration over the domain. This implies that the exact solution used
in the integral will vary linearly over the cells, and not as a sine
function, if ``V`` corresponds to linear Lagrange elements.  This
situation may yield a smaller error ``u - u_e`` than what is actually
true.  More accurate representation of the exact solution is easily
achieved by interpolating the formula onto a space defined by
higher-order elements, say of third degree:

.. code-block:: python

    Ve = FunctionSpace(mesh, 'P', degree=3)
    u_e_Ve = interpolate(u_e, Ve)
    error = (u - u_e_Ve)**2*dx
    E = sqrt(assemble(error))

To achieve complete mathematical control of which function space the
computations are carried out in, we can explicitly interpolate ``u`` to
the same space:

.. code-block:: python

    u_Ve = interpolate(u, Ve)
    error = (u_Ve - u_e_Ve)**2*dx

The square in the expression for ``error`` will be expanded and lead to
a lot of terms that almost cancel when the error is small, with the
potential of introducing significant rounding errors.  The function
``errornorm`` is available for avoiding this effect by first
interpolating ``u`` and ``u_exact`` to a space with higher-order elements,
then subtracting the degrees of freedom, and then performing the
integration of the error field. The usage is simple:

.. code-block:: python

    E = errornorm(u_exact, u, normtype='L2', degree=3)

It is illustrative to look at the short implementation of ``errornorm``:

.. code-block:: python

    def errornorm(u_exact, u, Ve):
        u_Ve = interpolate(u, Ve)
        u_e_Ve = interpolate(u_exact, Ve)
        e_Ve = Function(Ve)
        # Subtract degrees of freedom for the error field
        e_Ve.vector()[:] = u_e_Ve.vector().array() - \ 
                           u_Ve.vector().array()
        error = e_Ve**2*dx
        return sqrt(assemble(error))

The ``errornorm`` procedure turns out to be identical to computing
the expression ``(u_e - u)**2*dx`` directly in
the present test case.

Sometimes it is of interest to compute the error of the
gradient field: :math:`||\nabla (u-{u_{\small\mbox{e}}})||`
(often referred to as the :math:`H^1` seminorm of the error).
Given the error field ``e_Ve`` above, we simply write

.. code-block:: python

    H1seminorm = sqrt(assemble(dot(grad(e_Ve), grad(e_Ve))*dx))

All the various types of error computations here are placed in a
function ``compute_errors`` in ``ft08_poisson_vc.py``:
[**hpl 40**: Necessary to repeat code? New info is essentiall the return dict.]
[**hpl 41**: Anders, I (in 2010...) ran into problems with ``fenics.errornorm``, see comments in the code below, and made the version below. We should check out these problems again and adjust ``fenics.errornorm`` if necessary.]

.. code-block:: python

    def compute_errors(u, u_exact):
        """Compute various measures of the error u - u_exact, where
        u is a finite element Function and u_exact is an Expression."""
    
        # Compute error norm (for very small errors, the value can be
        # negative so we run abs(assemble(error)) to avoid failure in sqrt
    
        V = u.function_space()
    
        # Function - Expression
        error = (u - u_exact)**2*dx
        E1 = sqrt(abs(assemble(error)))
    
        # Explicit interpolation of u_e onto the same space as u:
        u_e = interpolate(u_exact, V)
        error = (u - u_e)**2*dx
        E2 = sqrt(abs(assemble(error)))
    
        # Explicit interpolation of u_exact to higher-order elements,
        # u will also be interpolated to the space Ve before integration
        Ve = FunctionSpace(V.mesh(), 'P', 5)
        u_e = interpolate(u_exact, Ve)
        error = (u - u_e)**2*dx
        E3 = sqrt(abs(assemble(error)))
    
        # fenics.errornorm interpolates u and u_e to a space with
        # given degree, and creates the error field by subtracting
        # the degrees of freedom, then the error field is integrated
        # TEMPORARY BUG - doesn't accept Expression for u_e
        #E4 = errornorm(u_e, u, normtype='l2', degree=3)
        # Manual implementation errornorm to get around the bug:
        def errornorm(u_exact, u, Ve):
            u_Ve = interpolate(u, Ve)
            u_e_Ve = interpolate(u_exact, Ve)
            e_Ve = Function(Ve)
            # Subtract degrees of freedom for the error field
            e_Ve.vector()[:] = u_e_Ve.vector().array() - u_Ve.vector().array()
            # More efficient computation (avoids the rhs array result above)
            #e_Ve.assign(u_e_Ve)                      # e_Ve = u_e_Ve
            #e_Ve.vector().axpy(-1.0, u_Ve.vector())  # e_Ve += -1.0*u_Ve
            error = e_Ve**2*dx(Ve.mesh())
            return sqrt(abs(assemble(error))), e_Ve
        E4, e_Ve = errornorm(u_exact, u, Ve)
    
        # Infinity norm based on nodal values
        u_e = interpolate(u_exact, V)
        E5 = abs(u_e.vector().array() - u.vector().array()).max()
    
        # H1 seminorm
        error = dot(grad(e_Ve), grad(e_Ve))*dx
        E6 = sqrt(abs(assemble(error)))
    
        # Collect error measures in a dictionary with self-explanatory keys
        errors = {'u - u_exact': E1,
                  'u - interpolate(u_exact,V)': E2,
                  'interpolate(u,Ve) - interpolate(u_exact,Ve)': E3,
                  'errornorm': E4,
                  'infinity norm (of dofs)': E5,
                  'grad(error) H1 seminorm': E6}
    
        return errors

Computing convergence rates empirically
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Calling the ``solver`` function for finer and finer meshes enables us to
study the convergence rate. Define the element size :math:`h=1/n`, where :math:`n`
is the number of cell divisions in :math:`x` and :math:`y` direction (``n=Nx=Ny`` in
the code). We perform experiments with :math:`h_0>h_1>h_2\cdots` and compute
the corresponding errors :math:`E_0, E_1, E_3` and so forth.  Assuming
:math:`E_i=Ch_i^r` for unknown constants :math:`C` and :math:`r`, we can compare two
consecutive experiments, :math:`E_i=Ch_i^r` and :math:`E_{i-1}=Ch_{i-1}^r`, and
solve for :math:`r`:

.. math::
        
        r = {\ln(E_i/E_{i-1})\over\ln (h_i/h_{i-1})}{\thinspace .}
        

The :math:`r` values should approach the expected convergence
rate ``degree+1`` as :math:`i` increases.

The procedure above can easily be turned into Python code. Here
we run through a different types of elements (P1, P2, P3, and P4),
perform experiments over a series of refined meshes, and for
each experiment report the six error types as returned by ``compute_errors``:

.. code-block:: python

    def convergence_rate(u_exact, f, u_b, p, degrees,
                         n=[2**(k+3) for k in range(5)]):
        """
        Compute convergence rates for various error norms for a
        sequence of meshes with Nx=Ny=b and P1, P2, ...,
        Pdegrees elements. Return rates for two consecutive meshes:
        rates[degree][error_type] = r0, r1, r2, ...
        """
    
        h = {}  # Discretization parameter, h[degree][experiment]
        E = {}  # Error measure(s), E[degree][experiment][error_type]
        P_degrees = 1,2,3,4
        num_meshes = 5
    
        # Perform experiments with meshes and element types
        for degree in P_degrees:
            n = 4   # Coarsest mesh division
            h[degree] = []
            E[degree] = []
            for i in range(num_meshes):
                n *= 2
                h[degree].append(1.0/n)
                u = solver(p, f, u_b, n, n, degree,
                           linear_solver='direct')
                errors = compute_errors(u, u_exact)
                E[degree].append(errors)
                print('2*(%dx%d) P%d mesh, %d unknowns, E1=%g' %
                      (n, n, degree, u.function_space().dim(),
                       errors['u - u_exact']))
        # Convergence rates
        from math import log as ln  # log is a fenics name too
        error_types = list(E[1][0].keys())
        rates = {}
        for degree in P_degrees:
            rates[degree] = {}
            for error_type in sorted(error_types):
                rates[degree][error_type] = []
                for i in range(num_meshes):
                    Ei   = E[degree][i][error_type]
                    Eim1 = E[degree][i-1][error_type]
                    r = ln(Ei/Eim1)/ln(h[degree][i]/h[degree][i-1])
                    rates[degree][error_type].append(round(r,2))
        return rates

Test problem          (6)
~~~~~~~~~~~~~~~~~~~~~~~~~

The section :ref:`ch:poisson0:gradu` specifies a more complicated solution,

.. math::
        
        u(x,y) = \sin(\omega\pi x)\sin(\omega\pi y)
        

on the unit square. This choice implies :math:`f(x,y)=2\omega^2\pi^2 u(x,y)`.
With :math:`\omega` restricted to an integer
it follows that :math:`u_{\mathrm{b}}=0`.

We need to define the appropriate boundary conditions, the exact
solution, and the :math:`f` function in the code:

.. code-block:: python

    def boundary(x, on_boundary):
        return on_boundary
    
    bc = DirichletBC(V, Constant(0.0), boundary)
    
    omega = 1.0
    u_e = Expression('sin(omega*pi*x[0])*sin(omega*pi*x[1])',
                     omega=omega)
    
    f = 2*pi**2*omega**2*u_e

Experiments
~~~~~~~~~~~

The function ``convergence_rate_sin()`` in ``ft08_poisson_vc.py``
implements the test problem
above and applies the ``convergence_rate`` function to estimate
convergence rates.
We achieve some interesting results.
Using the error measure ``E5`` based on the infinity norm of the
difference of the degrees of freedom, we have

=======  ===========  ============  ============  ============  =============  
element  :math:`n=8`  :math:`n=16`  :math:`n=32`  :math:`n=64`  :math:`n=128`  
=======  ===========  ============  ============  ============  =============  
P1              1.99          1.97          1.99           2.0            2.0  
P2              3.99          3.96          3.99           4.0           3.99  
P3              3.96          3.89          3.96          3.99            4.0  
P4              3.75          4.99           5.0           5.0                 
=======  ===========  ============  ============  ============  =============  

The computations with P4 elements on a :math:`2(128\times 128)` mesh with a
direct solver (UMFPACK) on a small laptop broke down.
Otherwise we achieve expected results: the error goes like
:math:`h^{d+1}` for elements of degree :math:`d`. Also :math:`L^2` norms based
on the ``errornorm`` gives the expected :math:`h^{d+1}` rate for
:math:`u` and :math:`h^d` for :math:`\nabla u`.

However, using ``(u - u_exact)**2`` for the error computation, which implies
interpolating ``u_exact`` onto the same space as ``u``, results in :math:`h^4`
convergence for P2 elements.

=======  ===========  ============  ============  ============  =============  
element  :math:`n=8`  :math:`n=16`  :math:`n=32`  :math:`n=64`  :math:`n=128`  
=======  ===========  ============  ============  ============  =============  
P1              1.98          1.94          1.98           2.0            2.0  
P2              3.98          3.95          3.99          3.99           3.99  
P3              3.69          4.03          4.01          3.95           2.77  
=======  ===========  ============  ============  ============  =============  

This is an example where it is important to interpolate ``u_exact`` to a
higher-order space (polynomials of degree 3 are sufficient here) to
avoid computing a too optimistic convergence rate.

.. Problems with interpolate(u,Ve) - interpolate(u_exact,Ve) for

.. high degree and large meshes. Rounding errors? errornorm is the

.. remedy?

.. interpolate(u,Ve) - interpolate(u_exact,Ve)

.. P1: 1.98, 1.96, 1.99, 2.0, 2.0

.. P2: 3.01, 3.03, 3.01, 3.0, 3.02

.. P3: 2.7, 4.02, 4.0, 2.63, 0.17

.. P4: 1.54, 5.11, 0.91, 0.15, -0.01

Checking convergence rates is the next best method for verifying PDE codes
(the best being a numerical solution without approximation errors
as in the section :ref:`ch:poisson0:verify1` and many other places in this tutorial).

Multiple domains and boundaries
===============================

[**hpl 38**: Need a little intro.]

.. _ch:poisson0:DN:

Combining Dirichlet and Neumann conditions
------------------------------------------

Let us make a slight extension of our two-dimensional Poisson problem
with Dirichlet conditions on the entire boundary and add a Neumann boundary
condition. The domain is still the unit square, but now we set the
Dirichlet condition :math:`u=u_{\mathrm{b}}` at the left and right sides, :math:`x=0` and
:math:`x=1`, while the Neumann condition

.. math::
        
        -{\partial u\over\partial n}=g
        

is applied to the remaining
sides :math:`y=0` and :math:`y=1`.
The Neumann condition is also known as a *natural boundary condition*
(in contrast to an essential boundary condition).

.. index:: Neumann boundary conditions

PDE problem          (5)
~~~~~~~~~~~~~~~~~~~~~~~~

Let :math:`\Gamma_D` and :math:`\Gamma_N` denote the parts of :math:`\partial\Omega`
where the Dirichlet and Neumann conditions apply, respectively.  The
complete boundary-value problem can be written as

.. _Eq:_auto16:

.. math::

    \tag{64}
    - \nabla^2 u = f \mbox{ in } \Omega,  
        
        

.. _Eq:_auto17:

.. math::

    \tag{65}
    u = u_{\mathrm{b}} \mbox{ on } \Gamma_D,       
        
        

.. _Eq:_auto18:

.. math::

    \tag{66}
    - {\partial u\over\partial n} = g \mbox{ on } \Gamma_N  {\thinspace .}
        
        

Again we choose :math:`u=1+x^2 + 2y^2` as the exact solution and adjust :math:`f`, :math:`g`, and
:math:`u_{\mathrm{b}}` accordingly:

.. math::
        
        f &= -6,\\ 
        g &= \left\lbrace\begin{array}{ll}
        -4, & y=1\\ 
        0,  & y=0
        \end{array}\right.\\ 
        u_{\mathrm{b}} &= 1 + x^2 + 2y^2{\thinspace .}
        

For ease of programming we may introduce a :math:`g` function defined over the whole
of :math:`\Omega` such that :math:`g` takes on the right values at :math:`y=0` and
:math:`y=1`. One possible extension is

.. math::
        
        g(x,y) = -4y{\thinspace .}
        

Variational formulation          (5)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The first task is to derive the variational problem. This time we cannot
omit the boundary term arising from the integration by parts, because
:math:`v` is only zero on :math:`\Gamma_D`. We have

.. math::
        
         -\int_\Omega (\nabla^2 u)v {\, \mathrm{d}x}
        = \int_\Omega\nabla u\cdot\nabla v {\, \mathrm{d}x} - \int_{\partial\Omega}{\partial u\over
        \partial n}v {\, \mathrm{d}s},
        

and since :math:`v=0` on :math:`\Gamma_D`,

.. math::
        
        - \int_{\partial\Omega}{\partial u\over
        \partial n}v {\, \mathrm{d}s}
        =
        - \int_{\Gamma_N}{\partial u\over
        \partial n}v {\, \mathrm{d}s}
        = \int_{\Gamma_N}gv {\, \mathrm{d}s},
        

by applying the boundary condition on :math:`\Gamma_N`.
The resulting weak form reads

.. _Eq:ch:poisson0:2D:DN:weak:

.. math::

    \tag{67}
    \int_{\Omega} \nabla u \cdot \nabla v {\, \mathrm{d}x} +
        \int_{\Gamma_N} gv {\, \mathrm{d}s}
        = \int_{\Omega} fv {\, \mathrm{d}x}{\thinspace .}
        
        

Expressing this equation
in the standard notation :math:`a(u,v)=L(v)` is straightforward with

.. _Eq:ftut:poisson2:vard:a:

.. math::

    \tag{68}
    a(u, v) = \int_{\Omega} \nabla u \cdot \nabla v {\, \mathrm{d}x},
        
        

.. _Eq:ftut:poisson2:vard:L:

.. math::

    \tag{69}
    L(v) = \int_{\Omega} fv {\, \mathrm{d}x} -
        \int_{\Gamma_N} gv {\, \mathrm{d}s}{\thinspace .}  
        

FEniCS implementation          (7)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

How does the Neumann condition impact the implementation?
Let us go back to the very simplest file,
``ft01_poisson.py``, from
the section :ref:`ch:poisson0:impl:code`,
we realize that the statements remain almost the same.
Only two adjustments are necessary:

  * The function describing the boundary where Dirichlet conditions
    apply must be modified.

  * The new boundary term must be added to the expression in ``L``.

The first adjustment can be coded as

.. code-block:: python

    def Dirichlet_boundary(x, on_boundary):
        if on_boundary:
            if x[0] == 0 or x[0] == 1:
                return True
            else:
                return False
        else:
            return False

A more compact implementation reads

.. code-block:: python

    def Dirichlet_boundary(x, on_boundary):
        return on_boundary and (x[0] == 0 or x[0] == 1)


.. admonition:: Never use ``==`` for comparing real numbers

   A list like ``x[0] == 1`` should never be used if ``x[0]`` is a real number,
   because rounding errors in ``x[0]`` may make the test fail even when it is
   mathematically correct. Consider
   
   .. code-block:: python
   
       >>> 0.1 + 0.2 == 0.3
       False
       >>> 0.1 + 0.2
       0.30000000000000004
   
   Comparison of real numbers need to use tolerances! The values of the
   tolerances depend on the size of the numbers involved in arithmetic
   operations:
   
   .. code-block:: python
   
       >>> abs(0.1+0.2 - 0.3)
       5.551115123125783e-17
       >>> abs(1.1+1.2 - 2.3)
       0.0
       >>> abs(10.1+10.2 - 20.3)
       3.552713678800501e-15
       >>> abs(100.1+100.2 - 200.3)
       0.0
       >>> abs(1000.1+1000.2 - 2000.3)
       2.2737367544323206e-13
       >>> abs(10000.1+10000.2 - 20000.3)
       3.637978807091713e-12
   
   For numbers around unity, tolerances as low as :math:`3\cdot 10^{-16}` can be used
   (in fact, this tolerance is known as the constant ``DOLFIN_EPS`` in FEniCS),
   otherwise an appropriate tolerance must be found.
   
   Testing for ``x[0] == 1`` should therefore be implemented as
   
   .. code-block:: python
   
       tol = 1E-14
       if abs(x[0] - 1) < tol:
           ...




.. index:: near

Here is a new boundary function using tolerances in the test:

.. code-block:: python

    def Dirichlet_boundary(x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and \ 
               (abs(x[0]) < tol or abs(x[0] - 1) < tol)

This function can be written a bit more elegantly using the ``near``
function in FEniCS:

.. code-block:: python

    def Dirichlet_boundary(x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and \ 
               (near(x[0], 0, tol) or near(x[1], 1, tol))

The second adjustment of our program concerns the definition of ``L``,
where we have to add a boundary integral and a definition of the :math:`g`
function to be integrated:

.. code-block:: python

    g = Expression('-4*x[1]')
    L = f*v*dx - g*v*ds

The ``ds`` variable implies a boundary integral, while ``dx``
implies an integral over the domain :math:`\Omega`.
No more modifications are necessary.

.. _ch:poisson0:multiple:Dirichlet:

Multiple Dirichlet conditions
-----------------------------

The PDE problem from the previous section applies a function :math:`u_{\mathrm{b}}(x,y)`
for setting Dirichlet conditions at two parts of the boundary.
Having a single function to set multiple Dirichlet conditions is
seldom possible. The more general case is to have :math:`m` functions for
setting Dirichlet conditions on :math:`m` parts of the boundary.
The purpose of this section is to explain how such multiple conditions
are treated in FEniCS programs.

Let us return to the case from the section :ref:`ch:poisson0:DN` and define
two separate functions for the two Dirichlet conditions:

.. math::
        
            - \nabla^2 u &= -6 \mbox{ in } \Omega, \\ 
            u &= u_L \mbox{ on } \Gamma_{D,0}, \\ 
            u &= u_R \mbox{ on } \Gamma_{D,1}, \\ 
            - {\partial u\over\partial n} &= g \mbox{ on } \Gamma_N {\thinspace .}
        

Here, :math:`\Gamma_{D,0}` is the boundary :math:`x=0`, while :math:`\Gamma_{D,1}` corresponds
to the boundary :math:`x=1`.  We have that :math:`u_L = 1 + 2y^2`, :math:`u_R = 2 +
2y^2`, and :math:`g=-4y`.

For the left boundary :math:`\Gamma_0` we define the
usual triple of a function for the boundary value, a function for
defining the boundary of interest, and a ``DirichletBC`` object:

.. code-block:: python

    u_L = Expression('1 + 2*x[1]*x[1]')
    
    def left_boundary(x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[0]) < tol
    
    Gamma_0 = DirichletBC(V, u_L, left_boundary)

For the boundary :math:`x=1` we write a similar code snippet:

.. code-block:: python

    u_R = Expression('2 + 2*x[1]*x[1]')
    
    def right_boundary(x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[0] - 1) < tol
    
    Gamma_1 = DirichletBC(V, u_R, right_boundary)

The various essential conditions are then collected in a list
and used in the solution process:

.. code-block:: python

    bcs = [Gamma_0, Gamma_1]
    ...
    solve(a == L, u, bcs)
    # or
    problem = LinearVariationalProblem(a, L, u, bcs)
    solver  = LinearVariationalSolver(problem)
    solver.solve()

In other problems, where the :math:`u` values are constant at a part of the
boundary, we may use a simple ``Constant`` object instead of an
``Expression`` object.

.. _ftut:possion:2D:2mat:impl:

Working with subdomains
-----------------------

.. index:: heterogeneous media

.. index:: multi-material domain

Solving PDEs in domains made up of different materials is a frequently
encountered task. In FEniCS, these kind of problems are handled by
defining subdomains inside the domain. The subdomains may represent
the various materials. We can thereafter define material properties
through functions, known in FEniCS as *mesh functions*, that are
piecewise constant in each subdomain.  A simple example with two
materials (subdomains) in 2D will demonstrate the basic steps in the
process.

.. _ftut:possion:2D:2mat:fig1:

.. figure:: layered_medium_2.png
   :width: 400

   *Medium with discontinuous material properties*

Suppose we want to solve

.. _Eq:ch:poisson0:2D:2mat:varcoeff2:

.. math::

    \tag{70}
    \nabla\cdot \left\lbrack k(x,y)\nabla u(x,y)\right\rbrack = 0,
        

in a domain :math:`\Omega` consisting of two subdomains where :math:`k` takes on
a different value in each subdomain.
For simplicity, yet without loss of generality, we choose for the current
implementation
the domain :math:`\Omega = [0,1]\times [0,1]` and divide it into two equal
subdomains,
as depicted in Figure :ref:`ftut:possion:2D:2mat:fig1`,

.. math::
        
        \Omega_0 = [0, 1]\times [0,1/2],\quad
        \Omega_1 = [0, 1]\times (1/2,1]{\thinspace .}
        

We define :math:`k(x,y)=k_0` in :math:`\Omega_0` and :math:`k(x,y)=k_1` in :math:`\Omega_1`,
where :math:`k_0>0` and :math:`k_1>0` are given constants.

Physically, the present problem may correspond to heat conduction, where
the heat conduction in :math:`\Omega_1` is more efficient than
in :math:`\Omega_0`. An alternative interpretation is flow in porous media
with two geological layers, where the layers' ability to transport
the fluid differ.

Expression objects with if test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The simplest way of implementing a variable :math:`k` is to define an
``Expression`` object where we return the appropriate :math:`k` value
depending on the position in space.  Since we need some testing on the
coordinates, the most straightforward approach is to define a subclass
of ``Expression``, where we can use a full Python method instead of just
a C++ string formula for specifying a function.  The method that
defines the function is called ``eval``:

.. code-block:: python

    class K(Expression):
        def set_k_values(self, k0, k1):
            self.k0, self.k1 = k0, k1
    
        def eval(self, value, x):
            """x: spatial point, value[0]: function value."""
    	# Fill in-place value[0] for scalar function,
    	# value[:] for vector function (no return)
    
    	tol = 1E-14  # Tolerance for coordinate comparisons
            if x[1] <= 0.5+tol:
    	    value[0] = self.k0
    	else:
    	    value[0] = self.k1
    
    # Initialize
    k = K()
    k.set_k_values(1, 0.01)

The ``eval`` method gives great flexibility in defining functions, but a
downside is that C++ calls up ``eval`` in Python for each point ``x``,
which is a slow process, and the number of calls is proportional to
the number of numerical integration points in the mesh (about the
number of degrees of freedom).  Function expressions in terms of
strings are compiled to efficient C++ functions, being called from
C++, so we should try to express functions as string expressions if
possible. (The ``eval`` method can also be defined through C++ code, but
this is much more complicated and not covered here.)  The idea is to
use inline if tests in C++:

.. code-block:: python

    tol = 1E-14
    k0 = 1.0
    k1 = 0.01
    k = Expression('x[1] <= 0.5+tol? k0 : k1',
                   tol=tol, k0=k0, k1=k1)

The method with if tests on the location is feasible when the
subdomains have very simple shapes. A completely general method,
utilizing *mesh functions*, is described next.

.. index:: boundary specification (class)

Mesh functions
~~~~~~~~~~~~~~

We now address how to specify the subdomains :math:`\Omega_0` and :math:`\Omega_1`
so that the method also works for subdomains of any shape. For this
purpose we need to use subclasses of class ``SubDomain``, not only plain
functions as we have used so far for specifying boundaries. Consider
the boundary function

.. code-block:: python

    def boundary(x, on_boundary):
        tol = 1E-14
        return on_boundary and abs(x[0]) < tol

for defining the boundary :math:`x=0`. Instead of using such a stand-alone
function, we can create an instance (or object)
of a subclass of ``SubDomain``,
which implements the ``inside`` method as an alternative to the
``boundary`` function:

.. code-block:: python

    class Boundary(SubDomain):
        def inside(self, x, on_boundary):
            tol = 1E-14
            return on_boundary and abs(x[0]) < tol
    
    boundary = Boundary()
    bc = DirichletBC(V, Constant(0), boundary)

A word about computer science terminology may be used here: The term
*instance* means a Python object of a particular type (such as
``SubDomain``, ``Function``, ``FunctionSpace``, etc.).  Many use *instance*
and *object* as interchangeable terms. In other computer programming
languages one may also use the term *variable* for the same thing.  We
mostly use the well-known term *object* in this text.

A subclass of ``SubDomain`` with an ``inside`` method offers functionality
for marking parts of the domain or the boundary. Now we need to define
one class for the subdomain :math:`\Omega_0` where :math:`y\leq 1/2` and another
for the subdomain :math:`\Omega_1` where :math:`y\geq 1/2`:

.. code-block:: python

    tol = 1E-14  # Tolerance for coordinate comparisons
    
    class Omega0(SubDomain):
        def inside(self, x, on_boundary):
            return x[1] <= 0.5+tol
    
    class Omega1(SubDomain):
        def inside(self, x, on_boundary):
            return x[1] >= 0.5-tol

Notice the use of ``<=`` and ``>=`` in both tests. For a cell to belong
to, e.g., :math:`\Omega_1`, the ``inside`` method must return ``True`` for all
the vertices ``x`` of the cell. So to make the cells at the internal
boundary :math:`y=1/2` belong to :math:`\Omega_1`, we need the test ``x[1] >=
0.5``. However, because of potential rounding errors in the coordinates
``x[1]``, we use a tolerance in the comparisons: ``x[1] >= 0.5-tol``.

The next task is to use a *mesh function* to mark all cells in
:math:`\Omega_0` with the subdomain number 0 and all cells in :math:`\Omega_1`
with the subdomain number 1.  Our convention is to number subdomains
as :math:`0,1,2,\ldots`.

A ``MeshFunction`` object is a discrete function that can be evaluated
at a set of so-called *mesh entities*. Examples of mesh entities are
cells, facets, and vertices. A ``MeshFunction`` over cells is suitable
to represent subdomains (materials), while a ``MeshFunction`` over
facets is used to represent pieces of external or internal boundaries.
Mesh functions over vertices can be used to describe continuous
fields.  The specialized classes ``CellFunction`` and ``FacetFunction``
are used to construct mesh functions of cells and facets,
respectively.

Since we need to define subdomains of :math:`\Omega` in the present example,
we make use of a ``CellFunction``. The constructor
is fed with two arguments: 1) the type of value: ``'int'`` for integers,
``'uint'`` for positive (unsigned) integers, ``'double'`` for real
numbers, and ``'bool'`` for logical values; 2) a ``Mesh`` object.
Alternatively, the constructor can take just a filename and initialize
the ``CellFunction`` from data in a file.

We start with creating a ``CellFunction`` whose values are non-negative
integers (``'uint'``) for numbering the subdomains.
The appropriate code for two subdomains then reads

.. code-block:: python

    materials = CellFunction('size_t', mesh)
    # Mark subdomains with numbers 0 and 1
    subdomain0 = Omega0()
    subdomain0.mark(materials, 0)
    subdomain1 = Omega1()
    subdomain1.mark(materials, 1)
    
    # Alternative
    materials.set_all(0)
    subdomain1.mark(materials, 1)

Calling ``materials.array()`` returns a ``numpy`` array of the
subdomain values. That is, ``materials.array()[i]`` is
the subdomain value of cell number ``i``. This array is used to
look up the subdomain or material number of a specific element.

We need a function ``k`` that is constant in each subdomain :math:`\Omega_0`
and :math:`\Omega_1`. Since we want ``k`` to be a finite element function, it
is natural to choose a space of functions that is constant over each
element.  The family of discontinuous Galerkin methods, in FEniCS
denoted by ``'DG'``, is suitable for this purpose. Since we want
functions that are piecewise constant, the value of the degree
parameter is zero:

.. code-block:: python

    V0 = FunctionSpace(mesh, 'DG', 0)
    k  = Function(V0)

To fill ``k`` with the right values in each element, we loop over
all cells (i.e., indices in ``materials.array()``),
extract the corresponding subdomain number of a cell,
and assign the corresponding :math:`k` value to the ``k.vector()`` array:

.. code-block:: python

    k_values = [1.5, 50]  # values of k in the two subdomains
    for cell_no in range(len(materials.array())):
        material_no = materials.array()[cell_no]
        k.vector()[cell_no] = k_values[material_no]

Long loops in Python are known to be slow, so for large meshes
it is preferable to avoid such loops and instead use *vectorized code*.
Normally this implies that the loop must be replaced by
calls to functions from the ``numpy`` library that operate on complete
arrays (in efficient C code). The functionality we want in the present
case is to compute an array of the same size as
``materials.array()``, but where the value ``i`` of an entry
in ``materials.array()`` is replaced by ``k_values[i]``.
Such an operation is carried out by the ``numpy`` function ``choose``:

.. code-block:: python

    help = numpy.asarray(materials.array(), dtype=numpy.int32)
    k.vector()[:] = numpy.choose(help, k_values)

The ``help`` array is required since ``choose`` cannot work with
``materials.array()`` because this array has elements of
type ``uint32``. We must therefore transform this array to an array
``help`` with standard ``int32`` integers.

The next section exemplifies a complete solver with a piecewise
constant coefficient, like :math:`k`, defined through ``SubDomain`` objects,
combined with different types of boundary conditions.

.. index:: CompiledSubDomain

C++ strings for subdomain definitions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The ``SubDomain`` class in Python is convenient, but leads to lots of
function calls from C++ to Python, which are slow. In large problems,
the subdomains should be defined through C++ code. This is easy to achieve
using the ``CompiledSubDomain`` object. Consider the definition of
classes ``Omega0`` and ``Omega1`` above in Python.
The key strings that define these subdomain can be expressed in
C++ syntax and fed to ``CompiledSubDomain`` as follows:

.. code-block:: python

    tol = 1E-14  # Tolerance for coordinate comparisons
    
    subdomain0 = CompiledSubDomain(
                    'x[1] <= boundary+tol', tol=1E-14, boundary=0.5)
    subdomain1 = CompiledSubDomain(
                    'x[1] >= boundary-tol', tol=1E-14, boundary=0.5)

As seen, one can have parameters in the strings and specify their
values by keyword arguments.
The resulting objects, ``subdomain0`` and ``subdomain1``, can be used
as ordinary ``SubDomain`` objects.

Compiled subdomain strings can be applied for specifying boundaries as
well, e.g.,

.. code-block:: python

    y_R = CompiledSubDomain('on_boundary && near(x[1], R, eps=tol)',
                            tol=1E-14, R=2)   # y=2

It is possible to feed the C++ string (without parameters) directly as
the third argument to ``DirichletBC`` without explicitly constructing a
``CompiledSubDomain`` object:

.. code-block:: python

    bc1 = DirichletBC(V, value, 'on_boundary && near(x[1], 2, 1E-14)')

.. index:: near

.. --- begin exercise ---

.. _ch:poisson0:exer:eff:expression:

Exercise 4: Efficiency of Python vs C++ expressions
---------------------------------------------------

Consider a cube mesh with :math:`N` cells in each spatial direction.
We want to define a ``Function`` on this mesh where the
values are given by the mathematical function :math:`f(x,y,z)=a\sin(bxyz)`,
where :math:`a` and :math:`b` are two parameters. Write a ``class SineXYZ``:

.. code-block:: python

    class SineXYZ(Expression):
        def __init__(self, a, b):
            self.a, self.b = a, b
    
        def eval(self, value, x):
            value[0] = self.a*sin(self.b*x[0]*x[1]*x[2])

Create an alternative ``Expression`` based on giving the formula for :math:`f(x,y,z)`
as a C++ code string. Compare the computational efficiency of the
two implementations (e.g., using ``time.clock()`` to measure the CPU time).

The ``sin`` function used in class ``SineXYZ.eval`` can mean many things.
This is an advanced FEniCS function if imported from ``fenics``.
Much more efficient versions for sin of numbers are found in ``math.sin``
and ``numpy.sin``. Compare the use ``sin`` from ``fenics``, ``math``, ``numpy``, and
``sympy`` (note that ``sin`` from ``sympy`` is very slow).

.. --- begin solution of exercise ---

**Solution.**
Here is an appropriate program:

.. code-block:: python

    from __future__ import print_function
    from fenics import *
    import time
    
    def make_sine_Function(N, method):
        """Fill a Function with sin(x*y*z) values."""
        mesh = UnitCubeMesh(N, N, N)
        V = FunctionSpace(mesh, 'Lagrange', 2)
    
        if method.startswith('Python'):
            if method.endswith('fenics.sin'):
                # Need sin as local variable in this function
                from fenics import sin
            elif method.endswith('math.sin'):
                from math import sin
            elif method.endswith('numpy.sin'):
                from numpy import sin
            elif method.endswith('sympy.sin'):
                from sympy import sin
            else:
                raise NotImplementedError('method=%s' % method)
            print('sin:', sin, type(sin))
    
            class SineXYZ(Expression):
                def __init__(self, a, b):
                    self.a, self.b = a, b
    
                def eval(self, value, x):
                    value[0] = self.a*sin(self.b*x[0]*x[1]*x[2])
    
            expr = SineXYZ(a=1, b=2)
    
        elif method == 'C++':
            expr = Expression('a*sin(b*x[0]*x[1]*x[2])', a=1, b=2)
    
        t0 = time.clock()
        u = interpolate(expr, V)
        t1 = time.clock()
        return u, t1-t0
    
    def main(N):
        u, cpu_py_fenics  = make_sine_Function(N, 'Python-fenics.sin')
        u, cpu_py_math    = make_sine_Function(N, 'Python-math.sin')
        u, cpu_py_numpy   = make_sine_Function(N, 'Python-numpy.sin')
        u, cpu_py_sympy   = make_sine_Function(N, 'Python-sympy.sin')
        u, cpu_cpp = make_sine_Function(N, 'C++')
        print("""DOFs: %d
    Python:
    fenics.sin: %.2f
    math.sin:   %.2f
    numpy.sin:  %.2f
    sympy.sin:  %.2f
    C++:        %.2f
    Speed-up:   math: %.2f  sympy: %.2f""" %
              (u.function_space().dim(),
               cpu_py_fenics, cpu_py_math,
               cpu_py_numpy, cpu_py_sympy,
               cpu_cpp,
               cpu_py_math/float(cpu_cpp),
               cpu_py_sympy/float(cpu_cpp)))
    
    def profile():
        import cProfile
        prof = cProfile.Profile()
        prof.runcall(main)
        prof.dump_stats("tmp.profile")
        # http://docs.python.org/2/library/profile.html
    
    main(20)
    #profile()

Running the program shows that ``sin`` from ``math`` is the most efficient choice,
but a string C++ runs 40 times faster. Note that ``fenics.sin``, which is a
sine function in the UFL language that can work with symbolic expressions
in finite element forms, is (naturally) less efficient than the ``sin``
functions for numbers in ``math`` and ``numpy``.

.. --- end solution of exercise ---

Filename: ``Expression_efficiency``.

.. --- end exercise ---

.. _ch:poisson0:multi:bc:

Multiple Neumann, Robin, and Dirichlet conditions
-------------------------------------------------

.. index:: Dirichlet boundary conditions

.. index:: Neumann boundary conditions

.. index:: Robin boundary conditions

.. index:: boundary conditions

Consider the model problem from the section :ref:`ch:poisson0:multiple:Dirichlet` where we had both Dirichlet and
Neumann conditions.  The term ``v*g*ds`` in the expression for ``L``
implies a boundary integral over the complete boundary, or in FEniCS
terms, an integral over all exterior facets.  However, the
contributions from the parts of the boundary where we have Dirichlet
conditions are erased when the linear system is modified by the
Dirichlet conditions.  We would like, from an efficiency point of
view, to integrate ``v*g*ds`` only over the parts of the boundary where
we actually have Neumann conditions.  And more importantly, in other
problems one may have different Neumann conditions or other conditions
like the Robin type condition.  With the mesh function concept we can
mark different parts of the boundary and integrate over specific
parts.  The same concept can also be used to treat multiple Dirichlet
conditions.  The forthcoming text illustrates how this is done.

Three types of boundary conditions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We extend our repertoire of boundary conditions to three types:
Dirichlet, Neumann, and Robin.  Dirichlet conditions apply to some
parts :math:`\Gamma_{D,0}`, :math:`\Gamma_{D,1}`, :math:`...`, of the boundary:

.. math::
         u_{0,0}\hbox{ on }\Gamma_{D,0},\quad
        u_{0,1}\hbox{ on }\Gamma_{D,1}, \ldots

where :math:`u_{0,i}` are prescribed functions, :math:`i=0,1,\ldots`
On other parts, :math:`\Gamma_{N,0}`, :math:`\Gamma_{N,1}`, and so on, we have
Neumann conditions

.. math::
         -p{\partial u\over\partial n} = g_{0}\hbox{ on }\Gamma_{N,0},\quad
        -p{\partial u\over\partial n} = g_{1}\hbox{ on }\Gamma_{N,1},\quad \ldots
        

Finally, we have *Robin conditions*

.. _Eq:ch:poisson0:multi:bc:Robin:

.. math::

    \tag{71}
    -p{\partial u\over\partial n} = r(u-s),
        
        

where :math:`r` and :math:`s` are specified functions.  The Robin condition is
most often used to model heat transfer to the surroundings and arise
naturally from Newton's cooling law. In that case, :math:`r` is a heat
transfer coefficient, and :math:`s` is the temperature of the
surroundings. Both can be space and time-dependent.
The Robin conditions apply
at some parts :math:`\Gamma_{R,0}`, :math:`\Gamma_{R,1}`, and so forth:

.. math::
         -p{\partial u\over\partial n} = r_0(u-s_0)\hbox{ on }\Gamma_{R,0},\quad
        -p{\partial u\over\partial n} = r_1(u-s_1)\hbox{ on }\Gamma_{R,1},\quad \ldots
        

.. index:: Robin condition

A general model problem
~~~~~~~~~~~~~~~~~~~~~~~

With the notation above,
the model problem to be solved with multiple Dirichlet, Neumann, and
Robin conditions can formally be defined as

.. _Eq:ch:poisson0:2D:DN3:

.. math::

    \tag{72}
    -\nabla\cdot(p\nabla u) = -f, \mbox{ in } \Omega, 
        

.. _Eq:ch:poisson0:2D:DN3:bcD:

.. math::

    \tag{73}
    u = u_{0,i} \mbox{ on } \Gamma_{D,i},\quad i=0,1,\ldots
        
        

.. _Eq:ch:poisson0:2D:DN3:bcN:

.. math::

    \tag{74}
    -p{\partial u\over\partial n} = g_i \mbox{ on } \Gamma_{N,i},\quad
        i=0,1,\ldots
        
        

.. _Eq:ch:poisson0:2D:DN3:bcR:

.. math::

    \tag{75}
    -p{\partial u\over\partial n} = r_i(u-s_i) \mbox{ on } \Gamma_{R,i},\quad
        i=0,1,\ldots
        
        

Variational formulation          (6)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Integration by parts of :math:`-\int_\Omega v\nabla\cdot(p\nabla u) {\, \mathrm{d}x}` becomes
as usual

.. math::
        
         -\int_\Omega v\nabla\cdot(p\nabla u) {\, \mathrm{d}x}
        = \int_\Omega p\nabla u\cdot \nabla v {\, \mathrm{d}x} -
        \int_{\partial\Omega}p\frac{\partial u}{\partial n}v {\, \mathrm{d}s}{\thinspace .}
        

The boundary integral does not apply to the parts of
the boundary where we have Dirichlet conditions (:math:`\Gamma_{D,i}`).
Moreover, on the remaining parts, we must split the boundary integral
into the parts where we have Neumann and Robin conditions such that we
insert the right conditions as integrands.
Specifically, we have

.. math::
        
        -\int_{\partial\Omega}p\frac{\partial u}{\partial n}v {\, \mathrm{d}s}
        &=
        -\sum_i\int_{\Gamma_{N,i}}p\frac{\partial u}{\partial n} {\, \mathrm{d}s}
        -\sum_i\int_{\Gamma_{R,i}}p\frac{\partial u}{\partial n} {\, \mathrm{d}s}\\ 
        &=
        \sum_i\int_{\Gamma_{N,i}}g_i {\, \mathrm{d}s} +
        \sum_i\int_{\Gamma_{R,i}}r_i(u-s_i) {\, \mathrm{d}s}{\thinspace .}
        

The variational formulation then becomes

.. _Eq:ch:poisson0:multi:bc:varform:

.. math::

    \tag{76}
    F = \int_{\Omega} p\nabla u\cdot \nabla v {\, \mathrm{d}x} +
        \sum_i\int_{\Gamma_{N,i}} g_iv {\, \mathrm{d}s} +
        \sum_i\int_{\Gamma_{R,i}}r_i(u-s_i)v {\, \mathrm{d}s}
        - \int_{\Omega} fv {\, \mathrm{d}x} =0{\thinspace .}
        
        

We have been used to writing
this variational formulation in the standard notation
:math:`a(u,v)=L(v)`, which requires that we identify all integrals with
*both* :math:`u` and :math:`v`, and collect these in :math:`a(u,v)`, while the remaining
integrals with :math:`v` and not :math:`u` go into :math:`L(v)`.  The integral from the
Robin condition must of this reason be split in two parts:

.. math::
        
        \int_{\Gamma_{R,i}}r_i(u-s_i)v {\, \mathrm{d}s}
        = \int_{\Gamma_{R,i}} r_iuv {\, \mathrm{d}s} - \int_{\Gamma_{R,i}}r_is_iv {\, \mathrm{d}s}{\thinspace .}
        

We then have

.. _Eq:ch:poisson0:2D:DN3:var:a:

.. math::

    \tag{77}
    a(u, v) = \int_{\Omega} p\nabla u\cdot \nabla v {\, \mathrm{d}x}
        + \sum_i\int_{\Gamma_{R,i}}r_iuv {\, \mathrm{d}s},
        
        

.. _Eq:ch:poisson0:2D:DN3:var:L:

.. math::

    \tag{78}
    L(v) = \int_{\Omega} fv {\, \mathrm{d}x} -
        \sum_i\int_{\Gamma_{N,i}} g_i v {\, \mathrm{d}s} + \sum_i\int_{\Gamma_{R,i}}r_is_iv {\, \mathrm{d}s}{\thinspace .}
        
        

FEniCS implementation of boundary conditions
--------------------------------------------

Looking at our previous ``solver`` functions for solving the 2D Poisson equation,
the following new aspects must be taken care of:

 1. definition of a mesh function over the boundary,

 2. marking each side as a subdomain, using the mesh function,

 3. splitting a boundary integral into parts.

A general approach to the first task is to mark each of the desired
boundaries with markers 0, 1, 2, and so forth. Here we aim at
the four sides of the unit square, marked with
0 (:math:`x=0`), 1 (:math:`x=1`), 2 (:math:`y=0`), and 3 (:math:`y=1`).
The marking of boundaries makes use of a mesh function object, but contrary to
the section :ref:`ftut:possion:2D:2mat:impl`, this is not a function over
cells, but a function over cell facets. We apply the ``FacetFunction``
for this purpose:

.. code-block:: python

    boundary_parts = FacetFunction('size_t', mesh)

As in the section :ref:`ftut:possion:2D:2mat:impl` we use a subclass of
``SubDomain`` to identify the various parts of the mesh
function. Problems with domains of more complicated geometries may set
the mesh function for marking boundaries as part of the mesh
generation.  In our case, the :math:`x=0` boundary can be marked by

.. code-block:: python

    class BoundaryX0(SubDomain):
        def inside(self, x, on_boundary):
            return on_boundary and abs(x[0]) < tol
    
    bx0 = BoundaryX0()
    bx0.mark(boundary_parts, 0)

Similarly, we make the classes ``BoundaryX1`` for the :math:`x=1` boundary,
``BoundaryY0`` for the :math:`y=0` boundary, and ``BoundaryY1`` for the :math:`y=1`
boundary, and mark these as subdomains 1, 2, and 3, respectively.

For generality of the implementation, we let the user specify
what kind of boundary condition that applies to each of the four
boundaries. We set up a Python dictionary for this purpose, with
the key as subdomain number and the value as a dictionary specifying
the kind of condition as key and a function as its value.
For example,

.. code-block:: text

    boundary_conditions = {
      0: {'Dirichlet': u_b},
      1: {'Robin': (r, s)},
      2: {'Neumann: g}},
      3: {'Neumann', 0}}

specifies

 * a Dirichlet condition, with values implemented by an ``Expression``
   or ``Constant`` object
   ``u_b``, on subdomain 0, i.e., the :math:`x=1` boundary;

 * a Robin condition :ref:`(71) <Eq:ch:poisson0:multi:bc:Robin>`
   on subdomain 1, :math:`x=1`, with ``Expression`` or ``Constant`` objects
   ``r`` and ``s`` specifying :math:`r` and :math:`s`;

 * a Neumann condition :math:`\partial u/\partial n=g` on subdomain 2, :math:`y=0`,
   where an ``Expression`` or ``Constant`` object ``g`` implements the value :math:`g`;

 * a homogeneous Neumann condition :math:`\partial u/\partial n=0` on
   subdomain 3, :math:`y=1`.

As explained in the section :ref:`ch:poisson0:multiple:Dirichlet`,
multiple Dirichlet conditions must be collected in a list of
``DirichletBC`` objects. Based on the ``boundary_conditions`` data
structure above, we can construct this list by the following snippet:

.. code-block:: python

    bcs = []  # List of Dirichlet conditions
    for n in boundary_conditions:
        if 'Dirichlet' in boundary_conditions[n]:
            bcs.append(
                DirichletBC(V, boundary_conditions[n]['Dirichlet'],
                            boundary_parts, n))

The new aspect of the variational problem is the two distinct
boundary integrals over :math:`\Gamma_{N,i}` and :math:`\Gamma_{R,i}`.
Having a mesh function over exterior cell facets (our
``boundary_parts`` object), where subdomains (boundary parts) are
numbered as :math:`0,1,2,\ldots`, the special symbol ``ds(0)``
implies integration over subdomain (part) 0, ``ds(1)`` denotes
integration over subdomain (part) 1, and so on.
The idea of multiple ``ds``-type objects generalizes to volume
integrals too: ``dx(0)``, ``dx(1)``, etc., are used to
integrate over subdomain 0, 1, etc.,  inside :math:`\Omega`.

Before we have ``ds(n)`` for integers ``n`` defined, we must do

.. code-block:: python

    ds = Measure('ds', domain=mesh, subdomain_data=boundaries_parts)

Similarly, if we want integration of different parts of the domain,
we redefine ``dx`` as

.. code-block:: python

    dx = Measure('dx', domain=mesh, subdomain_data=domains)

where ``domains`` is a ``CellFunction`` defining subdomains in :math:`\Omega`.

Suppose we have a Robin condition with values ``r`` and ``s`` on subdomain
``R``, a Neumann condition with value ``g`` on subdomain ``N``, the
variational form can be written

.. code-block:: python

    a = dot(grad(u), grad(v))*dx + r*u*v*ds(R)
    L = f*v*dx - g*v*ds(N) + r*s*v*ds(R)

In our case things get a bit more complicated since the
information about integrals in Neumann and Robin conditions
are in the ``boundary_conditions`` data structure. We can collect
all Neumann conditions by the code

.. code-block:: python

    u = TrialFunction(V)
    v = TestFunction(V)
    Neumann_integrals = []
    for n in boundary_conditions:
        if 'Neumann' in boundary_conditions[n]:
            if boundary_conditions[n]['Neumann'] != 0:
                g = boundary_conditions[n]['Neumann']
                Neumann_integrals.append(g*v*ds(n))

Applying ``sum(Nemann_integrals)`` will apply the ``+`` operator to
the variational forms in the ``Numeann_integrals`` list and result
in the integrals we need for the right-hand side ``L`` of the
variational form.

The integrals in the Robin condition can similarly be collected
in lists:

.. code-block:: python

    Robin_a_integrals = []
    Robin_L_integrals = []
    for n in boundary_conditions:
        if 'Robin' in boundary_conditions[n]:
            r, s = boundary_conditions[n]['Robin']
            Robin_a_integrals.append(r*u*v*ds(n))
            Robin_L_integrals.append(r*s*v*ds(n))

We are now in a position to define the ``a`` and ``L`` expressions
in the variational formulation:

.. code-block:: python

    a = dot(p*grad(u), grad(v))*dx + \ 
        sum(Robin_a_integrals)
    L = f*v*dx - sum(Neumann_integrals) + sum(Robin_L_integrals)

.. index:: lhs

.. index:: rhs

Simplified handling of the variational formulation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We carefully ordered the terms in the variational formulation above
into the :math:`a` and :math:`L` parts. This requires a splitting of the Robin
condition and makes the ``a`` and ``L`` expressions less readable (still we
think understanding this splitting is key for any finite element programmer!).
Fortunately, UFL allows us to specify the complete variational form
:ref:`(76) <Eq:ch:poisson0:multi:bc:varform>` as one expression and offer tools to
extract what goes into the bilinear form :math:`a(u,v)` and the linear form
:math:`L(v)`:

.. code-block:: python

    F = dot(p*grad(u), grad(v))*dx + \ 
        sum(Robin_integrals) - f*v*dx + sum(Neumann_integrals)
    a, L = lhs(F), rhs(F)

This time we can more naturally define the integrals from the
Robin condition as ``r*(u-s)*v*ds(n)``:

.. code-block:: python

    Robin_integrals = []
    for n in boundary_conditions:
        if 'Robin' in boundary_conditions[n]:
            r, s = boundary_conditions[n]['Robin']
            Robin_integrals.append(r*(u-s)*v*ds(n))

The complete code is in the ``solver_bc`` function in the
``ft08_poisson_vc.py`` file.

Test problem          (7)
~~~~~~~~~~~~~~~~~~~~~~~~~

Let us continue to use :math:`{u_{\small\mbox{e}}}=1+x^2+2y^2` as the exact solution, and
set :math:`p=1` and :math:`f=-6` in the PDE.  Our domain is the unit square, and
we assign Dirichlet conditions at :math:`x=0` and :math:`x=1`, a Neumann condition
at :math:`y=1`, and a Robin condition at :math:`y=0`. With the given :math:`{u_{\small\mbox{e}}}`, we
realize that the Neumann condition is :math:`-4y` (which means :math:`-4` at
:math:`y=1`), while the Robin
condition can be selected in many ways. Since :math:`\partial u/\partial
n=-\partial u/\partial y=0` at :math:`y=0`, we can select :math:`s=u` and have :math:`r`
arbitrary in the Robin condition.

The boundary parts are :math:`\Gamma_{D,0}`: :math:`x=0`, :math:`\Gamma_{D,1}`: :math:`x=1`,
:math:`\Gamma_{R,0}`: :math:`y=0`, and :math:`\Gamma_{N,0}`: :math:`y=1`.

When implementing this test problem (and especially other test
problems with more complicated expressions), it is advantageous to use
symbolic computing. Below we define the exact solution as a ``sympy``
expression and derive other functions from their mathematical
definitions.  Then we turn these expressions into C/C++ code, which
can be fed into ``Expression`` objects.

.. code-block:: python

    def application_bc_test():
        # Define manufactured solution in sympy and derive f, g, etc.
        import sympy as sym
        x, y = sym.symbols('x[0] x[1]')  # UFL needs x[0] for x etc.
        u = 1 + x**2 + 2*y**2
        f = -sym.diff(u, x, 2) - sym.diff(u, y, 2)  # -Laplace(u)
        f = sym.simplify(f)
        u_00 = u.subs(x, 0)  # x=0 boundary
        u_01 = u.subs(x, 1)  # x=1 boundary
        g = -sym.diff(u, y).subs(y, 1)  # x=1 boundary, du/dn=-du/dy
        r = 1000 # any function can go here
        s = u
    
        # Turn to C/C++ code for UFL expressions
        f = sym.printing.ccode(f)
        u_00 = sym.printing.ccode(u_00)
        u_01 = sym.printing.ccode(u_01)
        g = sym.printing.ccode(g)
        r = sym.printing.ccode(r)
        s = sym.printing.ccode(s)
        print('Test problem (C/C++):\nu = %s\nf = %s' % (u, f))
        print('u_00: %s\nu_01: %s\ng = %s\nr = %s\ns = %s' %
              (u_00, u_01, g, r, s))
    
        # Turn into FEniCS objects
        u_00 = Expression(u_00)
        u_01 = Expression(u_01)
        f = Expression(f)
        g = Expression(g)
        r = Expression(r)
        s = Expression(s)
        u_exact = Expression(sym.printing.ccode(u))
    
        boundary_conditions = {
            0: {'Dirichlet': u_00},   # x=0
            1: {'Dirichlet': u_01},   # x=1
            2: {'Robin': (r, s)},     # y=0
            3: {'Neumann': g}}        # y=1
    
        p = Constant(1)
        Nx = Ny = 2
        u, p = solver_bc(
            p, f, boundary_conditions, Nx, Ny, degree=1,
            linear_solver='direct',
            debug=2*Nx*Ny < 50,  # for small problems only
            )

This simple test problem is turned into a real unit test for different
function spaces in the function ``test_solver_bc``.

Debugging the setting of boundary conditions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

It is easy to make mistakes when implementing a problem with many
different types of boundary conditions, as in the present case. Some
helpful debugging output is to run through all vertex coordinates and
check if the ``SubDomain.inside`` method marks the vertex as on the
boundary. Another useful printout is to list which degrees of freedom
that are subject to Dirichlet conditions, and for first-order Lagrange
elements, add the corresponding vertex coordinate to the output.

.. code-block:: python

    if debug:
        # Print the vertices that are on the boundaries
        coor = mesh.coordinates()
        for x in coor:
            if bx0.inside(x, True): print('%s is on x=0' % x)
            if bx1.inside(x, True): print('%s is on x=1' % x)
            if by0.inside(x, True): print('%s is on y=0' % x)
            if by1.inside(x, True): print('%s is on y=1' % x)
        # Print the Dirichlet conditions
        print('No of Dirichlet conditions:', len(bcs))
        d2v = dof_to_vertex_map(V)
        for bc in bcs:
            bc_dict = bc.get_boundary_values()
            for dof in bc_dict:
                print('dof %2d: u=%g' % (dof, bc_dict[dof]))
                if V.ufl_element().degree() == 1:
                    print('   at point %s' %
                          (str(tuple(coor[d2v[dof]].tolist()))))

In addition, it is helpful to print the exact and the numerical solution
at all the vertices as shown in the section :ref:`ch:poisson0:verify1`.

FEniCS implementation of multiple subdomains
--------------------------------------------

The section :ref:`ftut:possion:2D:2mat:impl` explains how to deal with
multiple subdomains of :math:`\Omega` and a piecewise constant coefficient
function :math:`p` that takes on different constant values in the different
subdomains. We can easily add this type of :math:`p` coefficient to the
``solver_bc`` function. The signature of the function is

.. code-block:: python

    def solver_bc(
        p, f,                   # Coefficients in the PDE
        boundary_conditions,    # Dict of boundary conditions
        Nx, Ny,                 # Cell division of the domain
        degree=1,               # Polynomial degree
        subdomains=[],          # List of SubDomain objects in domain
        linear_solver='Krylov', # Alt: 'direct'
        abs_tol=1E-5,           # Absolute tolerance in Krylov solver
        rel_tol=1E-3,           # Relative tolerance in Krylov solver
        max_iter=1000,          # Max no of iterations in Krylov solver
        log_level=PROGRESS,     # Amount of solver output
        dump_parameters=False,  # Write out parameter database?
        debug=False,
        ):
    ...
        return u, p   # p may be modified

If ``subdomain`` is an empty list, we assume there are no subdomains, and
:math:`p` is an ``Expression`` or ``Constant`` object specifying a formula for
:math:`p`. If not, ``subdomain`` is a list of ``SubDomain`` objects, defining
different parts of the domain. The first element is a dummy object,
defining "the rest" of the domain. The next elements define specific
geometries in the ``inside`` methods. We start by marking all elements
with subdomain number 0, this will then be "the rest" after marking
subdomains 1, 2, and so on. The next step is to define ``p`` as a
piecewise constant function over cells and fill it with values.
We assume that the user-argument ``p`` is an array (or list) holding
the values of :math:`p` in the different parts corresponding to ``subdomains``.
The returned ``p`` is needed for flux computations. If there are no
subdomains, the returned ``p`` is just the original ``p`` argument.

The appropriate code for computing ``p`` becomes

.. code-block:: python

    import numpy as np
    if subdomains:
        # subdomains is list of SubDomain objects,
        # p is array of corresponding constant values of p
        # in each subdomain
        materials = CellFunction('size_t', mesh)
        materials.set_all(0)  # "the rest"
        for m, subdomain in enumerate(subdomains[1:], 1):
            subdomain.mark(materials, m)
    
        p_values = p
        V0 = FunctionSpace(mesh, 'DG', 0)
        p  = Function(V0)
        help = np.asarray(materials.array(), dtype=np.int32)
        p.vector()[:] = np.choose(help, p_values)

We define :math:`p(x,y)=p_0` in :math:`\Omega_0` and :math:`k(x,y)=p_1` in :math:`\Omega_1`,
where :math:`p_0>0` and :math:`p_1>0` are given constants.
As boundary conditions, we choose :math:`u=0` at :math:`y=0`, :math:`u=1` at :math:`y=1`,
and :math:`\partial u/\partial n=0` at :math:`x=0` and :math:`x=1`.
One can show that the exact solution is now given by

.. _Eq:_auto19:

.. math::

    \tag{79}
    u(x, y) = \left\lbrace\begin{array}{ll}
        {2yp_1\over p_0+p_1}, & y \leq 1/2\\ 
        {(2y-1)p_0 + p_1\over p_0+p_1}, & y \geq 1/2
        \end{array}\right.
        
        

As long as the element boundaries coincide with the internal boundary
:math:`y=1/2`, this piecewise linear solution should be exactly recovered
by Lagrange elements of any degree. We can use this property to verify
the implementation and make a unit test for a series of function
spaces:

.. code-block:: python

    def test_solvers_bc_2mat():
        tol = 2E-13  # Tolerance for comparisons
    
        class Omega0(SubDomain):
            def inside(self, x, on_boundary):
                return x[1] <= 0.5+tol
    
        class Omega1(SubDomain):
            def inside(self, x, on_boundary):
                return x[1] >= 0.5-tol
    
        subdomains = [Omega0(), Omega1()]
        p_values = [2.0, 13.0]
        boundary_conditions = {
            0: {'Neumann': 0},
            1: {'Neumann': 0},
            2: {'Dirichlet': Constant(0)}, # y=0
            3: {'Dirichlet': Constant(1)}, # y=1
            }
    
        f = Constant(0)
        u_exact = Expression(
            'x[1] <= 0.5? 2*x[1]*p_1/(p_0+p_1) : '
            '((2*x[1]-1)*p_0 + p_1)/(p_0+p_1)',
            p_0=p_values[0], p_1=p_values[1])
    
        for Nx, Ny in [(2,2), (2,4), (8,4)]:
            for degree in 1, 2, 3:
                u, p = solver_bc(
                    p_values, f, boundary_conditions, Nx, Ny, degree,
                    linear_solver='direct', subdomains=subdomains,
                    debug=False)
    
                # Compute max error in infinity norm
                u_e = interpolate(u_exact, u.function_space())
                import numpy as np
                max_error = np.abs(u_e.vector().array() -
                               u.vector().array()).max()
                assert max_error < tol, 'max error: %g' % max_error

Bibliography
============

.. [Ref01]
   **A. Logg, K.-A. Mardal and G. N. Wells**. Automated Solution of Partial Differential Equations by the Finite Element Method,
   Springer,
   2012.

.. [Ref02]
   **P. S. Foundation**. The Python Tutorial.

.. [Ref03]
   **H. P. Langtangen and L. R. Hellevik**. Brief Tutorials on Scientific Python,
   `http://hplgit.github.io/bumpy/doc/web/index.html <http://hplgit.github.io/bumpy/doc/web/index.html>`_.

.. [Ref04]
   **M. Pilgrim**. *Dive into Python*,
   Apress,
   2004,
   `http://www.diveintopython.net <http://www.diveintopython.net>`_.

.. [Ref05]
   **H. P. Langtangen**. *Python Scripting for Computational Science*,
   third edition,
   Springer,
   2009.

.. [Ref06]
   **H. P. Langtangen**. *A Primer on Scientific Programming With Python*,
   fifth edition,
   *Texts in Computational Science and Engineering*,
   Springer,
   2016.

.. [Ref07]
   **J. M. Kinder and P. Nelson**. *A Student's Guide to Python for Physical Modeling*,
   Princeton University Press,
   2015.

.. [Ref08]
   **J. Kiusalaas**. *Numerical Methods in Engineering With Python*,
   Cambridge University Press,
   2005.

.. [Ref09]
   **R. H. Landau, M. J. Paez and C. C. Bordeianu**. *Computational Physics: Problem Solving with Python*,
   third edition,
   Wiley,
   2015.

.. [Ref10]
   **M. G. Larson and F. Bengzon**. *The Finite Element Method: Theory, Implementation, and Applications*,
   *Texts in Computational Science and Engineering*,
   Springer,
   2013.

.. [Ref11]
   **M. Gockenbach**. *Understanding and Implementing the Finite Element Method*,
   SIAM,
   2006.

.. [Ref12]
   **J. Donea and A. Huerta**. *Finite Element Methods for Flow Problems*,
   Wiley Press,
   2003.

.. [Ref13]
   **T. J. R. Hughes**. *The Finite Element Method: Linear Static and Dynamic Finite Element 	Analysis*,
   Prentice-Hall,
   1987.

.. [Ref14]
   **W. B. Bickford**. *A First Course in the Finite Element Method*,
   2nd edition,
   Irwin,
   1994.

.. [Ref15]
   **K. Eriksson, D. Estep, P. Hansbo and C. Johnson**. *Computational Differential Equations*,
   Cambridge University Press,
   1996.

.. [Ref16]
   **S. C. Brenner and L. R. Scott**. *The Mathematical Theory of Finite Element Methods*,
   third edition,
   *Texts in Applied Mathematics*,
   Springer,
   2008.

.. [Ref17]
   **D. Braess**. *Finite Elements*,
   third edition,
   Cambridge University Press,
   2007.

.. [Ref18]
   **A. Ern and J.-L. Guermond**. *Theory and Practice of Finite Elements*,
   Springer,
   2004.

.. [Ref19]
   **A. Quarteroni and A. Valli**. *Numerical Approximation of Partial Differential Equations*,
   *Springer Series in Computational Mathematics*,
   Springer,
   1994.

.. [Ref20]
   **P. G. Ciarlet**. *The Finite Element Method for Elliptic Problems*,
   *Classics in Applied Mathematics*,
   SIAM,
   2002.

.. [Ref21]
   **D. N. Arnold and A. Logg**. Periodic Table of the Finite Elements,
   *SIAM News*,
   2014.

.. [Ref22]
   **M. S. Alnæs, A. Logg, K. B. Ølgaard, M. E. Rognes and G. N. Wells**. Unified Form Language: A domain-specific language for weak formulations of partial differential equations,
   *ACM Transactions on Mathematical Software*,
   40(2),
   2014.

.. [Ref23]
   **A. H. Squillacote**. The Paraview Guide,
   Kitware,
   2007,
   `http://www.paraview.org/paraview-guide/ <http://www.paraview.org/paraview-guide/>`_.

.. [Ref24]
   **H. P. Langtangen and A. Logg**. *The Advanced FEniCS Tutorial - Writing State-of-the-art Finite Element Solvers in Hours*,
   Springer,
   2016.

.. [Ref25]
   **A. J. Chorin**. Numerical solution of the Navier-Stokes equations,
   *Math. Comp.*,
   22,
   pp. 745-762,
   1968.

.. [Ref26]
   **R. Temam**. Sur l'approximation de la solution des \'equations de Navier-Stokes,
   *Arc. Ration. Mech. Anal.*,
   32,
   pp. 377-385,
   1969.

.. [Ref27]
   **K. Goda**. A multistep technique with implicit difference schemes for calculating two- or three-dimensional cavity flows,
   *Journal of Computational Physics*,
   30(1),
   pp. 76-95,
   1979.

