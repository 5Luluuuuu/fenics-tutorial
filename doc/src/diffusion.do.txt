========= The diffusion solver revisited =========
label{ch:diffusion}

# Pointers backward...what is needed to be recaptured?

======= Optimization of algorithms and implementations =======

===== Avoiding some assembly =====

We realize that $a$ does not depend on time, which means that its
associated matrix also will be time independent. Therefore, it is wise
to explicitly create matrices and vectors as demonstrated in Section
ref{ftut:poisson1:linalg}.  The matrix $A$ arising from $a$ can be
computed prior to the time stepping, so that we only need to compute
the right-hand side $b$, corresponding to $L$, in each pass in the
time loop. Let us express the solution procedure in algorithmic form,
writing $u$ for the unknown spatial function at the new time level
($u^k$) and $u_1$ for the spatial solution at one earlier time level
($u^{k-1}$):

 * define Dirichlet boundary condition ($u_0$, Dirichlet boundary, etc.)
 * let $u_1$ interpolate $I$ or be the projection of $I$
 * define $a$ and $L$
 * assemble matrix $A$ from $a$
 * set some stopping time $T$
 * $t={\dt}$
 * while $t\leq T$
   * assemble vector $b$ from $L$
   * apply essential boundary conditions
   * solve $AU=b$ for $U$ and store in $u$
   * $t\leftarrow t + {\dt}$
   * $u_1 \leftarrow u$ (be ready for next step)

The code features the following changes from the `${prog["diffusion_flat1"]}.py`
program. We may define $a$ and $L$ from $F$ as before, or do it explicitly:

!bc pycod
a = u*v*dx + dt*dot(grad(u), grad(v))*dx
L = (u_1 + dt*f)*v*dx
!ec
Prior to the time loop we assemble the coefficient matrix $A$ once and
for all:

idx{`assemble`}

!bc pycod
A = assemble(a)   # assemble only once, before the time stepping
!ec
At each time level we can do a similar `b = assemble(L)`. With this
construction, a new vector for `b` is allocated in memory in every
pass of the time loop.  It would be much more memory friendly to reuse
the storage of the `b` we already have.  This is easily accomplished
by

!bc pycod
b = assemble(L, tensor=b)
!ec
That is, we send in our previous `b`, which is then filled with new values
and returned from `assemble`. Now there will be only a single
memory allocation of the right-hand side vector. Before the time loop
we set `b = None` such that `b` is defined in the first call to
`assemble`.

The necessary changes inside the time loop go as follows:

!bc pycod
while t <= T:
    b = assemble(L, tensor=b)
    u0.t = t
    bc.apply(A, b)
    solve(A, u.vector(), b)
!ec
The update `u0.t = t` is of key importance as `bc.apply(A, b)` will
look up the `u0` object to find the proper values in the Dirichlet condition,
and these change with time in our test problem!

The complete program is found in the file
"`${prog['diffusion_flat2']}.py`": "${src_url}/${prog['diffusion_flat2']}.py".


===== Avoiding all assembly =====
label{ftut:timedep:diffusion1:noassemble}
idx{assembly, increasing efficiency}

The purpose of this section is to present a technique for speeding up
FEniCS simulators for time-dependent problems where it is possible to
perform all assembly operations prior to the time loop.  There are two
costly operations in the time loop: assembly of the right-hand side
$b$ and solution of the linear system via the `solve` call. The
assembly process involves work proportional to the number of degrees
of freedom $N$, while the solve operation has a work estimate of
$\mathcal{O}( N^{\alpha})$, for some $\alpha\geq 1$.  Typically,
$\alpha\in [1,2]$.  As $N\rightarrow\infty$, the solve operation will
dominate for $\alpha>1$, but for the values of $N$ typically used on
smaller computers, the assembly step may still represent a
considerable part of the total work at each time level. Avoiding
repeated assembly can therefore contribute to a significant speed-up
of a finite element code in time-dependent problems.

=== Deriving recursive linear systems ===

To see how repeated assembly can be avoided, we look at the $L(v)$
form in  (ref{ftut:diffusion:pde1:L}),
which in general varies with
time through $u^{k-1}$, $f^k$, and possibly also with $\dt$
if the time step is adjusted during the simulation.
The technique for avoiding repeated assembly consists in
expanding the finite element functions in sums over the basis functions
$\phi_i$, as explained
in Section ref{ftut:poisson1:linalg}, to identify matrix-vector
products that build up the complete system. We have
$u^{k-1}=\sum_{j=1}^NU^{k-1}_j\phi_j$, and we can expand $f^k$ as
$f^{k}=\sum_{j=1}^NF^{k}_j\phi_j$. Inserting these expressions in $L(v)$
and using
$v=\hat\phi_i$ result in

!bt
\begin{align*}
\int_\Omega \left(u^{k-1} + {\dt}f^k\right)v \dx &=
\int_\Omega \left(\sum_{j=1}^N U^{k-1}_j\phi_j + {\dt}\sum_{j=1}^N F^{k}_j\phi_j\right)\hat\phi_i \dx,\\
&=\sum_{j=1}^N\left(\int_\Omega \hat\phi_i\phi_j \dx\right)U^{k-1}_j
 + {\dt}\sum_{j=1}^N\left(\int_\Omega \hat\phi_i\phi_j \dx\right)F^{k}_j\tp
\end{align*}
!et
Introducing $M_{ij} = \int_\Omega \hat\phi_i\phi_j \dx$, we see that
the last expression can be written

!bt
\begin{equation*}
\sum_{j=1}^NM_{ij}U^{k-1}_j + {\dt} \sum_{j=1}^NM_{ij}F^{k}_j,
\end{equation*}
!et
which is nothing but two matrix-vector products,

!bt
\begin{equation*}
MU^{k-1} + {\dt} MF^k,
\end{equation*}
!et
if $M$ is the matrix with entries $M_{ij}$,

!bt
\begin{equation*}
U^{k-1}=(U^{k-1}_1,\ldots,U^{k-1}_N)^T,
\end{equation*}
!et
and

!bt
\begin{equation*}
F^k=(F^{k}_1,\ldots,F^{k}_N)^T\tp
\end{equation*}
!et

We have immediate access to $U^{k-1}$ in the program since that is the
vector in the `u_1` function. The $F^k$ vector can easily be computed
by interpolating the prescribed $f$ function (at each time level if
$f$ varies with time). Given $M$, $U^{k-1}$, and $F^k$, the right-hand
side $b$ can be calculated as

!bt
\begin{equation*}
b = MU^{k-1} + {\dt} MF^k \tp
\end{equation*}
!et
That is, no assembly is necessary to compute $b$.

The coefficient matrix $A$ can also be split into two terms.  We
insert $v=\hat\phi_i$ and $u^k = \sum_{j=1}^N U^k_j\phi_j$ in the
expression (ref{ftut:diffusion:pde1:a}) to get

!bt
\begin{equation*}
\sum_{j=1}^N \left(\int_\Omega \hat\phi_i\phi_j \dx\right)U^k_j + {\dt}
\sum_{j=1}^N \left(\int_\Omega \nabla\hat\phi_i\cdot\nabla\phi_j \dx\right)U^k_j,
\end{equation*}
!et
which can be written as a sum of matrix-vector products,

!bt
\begin{equation*}
MU^k + {\dt} KU^k = (M + {\dt} K)U^k,
\end{equation*}
!et
if we identify the matrix $M$ with entries $M_{ij}$ as above and
the matrix $K$ with entries

!bt
\begin{equation} K_{ij} = \int_\Omega \nabla\hat\phi_i\cdot\nabla\phi_j \dx\tp
\end{equation}
!et
The matrix $M$ is often called the ``mass matrix'' while ``stiffness
matrix'' is a common nickname for $K$. The associated bilinear forms
for these matrices, as we need them for the assembly process in a
FEniCS program, become

!bt
\begin{align}
a_K(u,v) &= \int_\Omega\nabla u\cdot\nabla v \dx,
label{ftut:diffusion:pde1:aK}\\
a_M(u,v) &= \int_\Omega uv \dx label{ftut:diffusion:pde1:aM}\tp
\end{align}
!et

The linear system at each time level, written as $AU^k=b$,
can now be computed by first computing $M$ and $K$, and then forming
$A=M+{\dt} K$ at $t=0$, while $b$ is computed as
$b=MU^{k-1} + {\dt}MF^k$ at each time level.

=== Implementation ===

The following modifications are needed in the `${prog["diffusion_func"]}.py`
program from the previous section in order to implement the new
strategy of avoiding assembly at each time level:

  o Define separate forms $a_M$ and $a_K$
  o Assemble $a_M$ to $M$ and $a_K$ to $K$
  o Compute $A=M+{\dt}$, $K$
  o Define $f$ as an `Expression`
  o Interpolate the formula for $f$ to a finite element function $F^k$
  o Compute $b=MU^{k-1} + {\dt}MF^k$

The relevant code segments become

!bc pycod
# 1.
a_K = dot(grad(u), grad(v))*dx
a_M = u*v*dx
# No need for L

# 2. and 3.
M = assemble(a_M)
K = assemble(a_K)
A = M + dt*K

# 4.
f = Expression('beta - 2 - 2*alpha', beta=beta, alpha=alpha)

# 5. and 6.
while t <= T:
    f_k = interpolate(f, V)
    F_k = f_k.vector()
    b = M*u_1.vector() + dt*M*F_k
!ec

[hpl: I wonder if the refactoring should have a function first and then
a class or if we jump right to the class. From now on we could use
classes as the packaging of FEniCS programs.]

We implement these modification in a refactored version of the
program `${prog["diffusion_flat2"]}.py`, where the solver is a function
as explained in Section ref{ftut:poisson1:impl2} rather than a
flat program. The new `solver_minimize_assembly` function resides in
"`${prog['diffusion_func']}.py`": "${prog['diffusion_func']}.py".

@@@CODE src/diffusion_func.py fromto: def solver_minimize_assembly@def solver_bc

A special feature in this program is the `user_action` callback function:
at every time level, the solution is sent to `user_action`, which is
some function provided by the user where the solution can be processed, e.g.,
stored, analyzed, or visualized. In a unit test for the test example without
numerical approximation errors, we can write a call to the solver function,

!bc pycod
def test_solver():
    import numpy as np
    alpha = 3; beta = 1.2
    u0 = Expression('1 + x[0]*x[0] + alpha*x[1]*x[1] + beta*t',
                    alpha=alpha, beta=beta, t=0)
    f = Constant(beta - 2 - 2*alpha)
    dt = 0.3; T = 1.9
    u0.t = 0

    # Define assert_error callback function
    ...

    solver_minimize_assembly(
        f, u0, u0, dt, T, Nx, Ny, degree,
        user_action=assert_error, I_project=False)
!ec
The `user_action` function `assert_error` asserts equality of the
exact and numerical solution at every time level:

!bc pycod
def assert_error(t, u, timestep):
    u_e = interpolate(u0, u.function_space())
    error= np.abs(u_e.vector().array() -
    	          u.vector().array()).max()
    tol = 2E-12
    assert error < tol, 'error: %g' % error
!ec

One can also use the user action callback function to visualize
the solution:

!bc pycod
def assert_error(t, u, timestep):
    global p
    if t == 0:
        p = plot(u, title='u',
	         # Fix the color scale
                 range_min=float(u_range[0]),  # must be float
                 range_max=float(u_range[1]))  # must be float
    else:
        p.plot(u)
    print('t=%g' % t)
    time.sleep(0.5)
!ec
It is key to fix the color scale to get a meaningful animation.

A complete function calling up `solver_minimize_assembly` for
animating the solution in two test problems is found in the
function `application_animate` in
"`${prog['diffusion_func']}.py`": "${prog['diffusion_func']}.py".

Note that `p`, which must survive between subsequent calls to the
callback function, has to be declared as a global variable. This is
necessary when the user action function is a *closure* (function
inside function, ``remembering'' variables in the parent function) and
`p` is changed inside the closure.  Some programmers find it more
convenient to let the user action be class instead, where `p` can be
an attribute. Later examples employ the class design.

[hpl: The function `solver_vs_solver_minimize_assembly` measures the
impact of this optimization. It is not big: a factor of 1-2 for
P1 elements but hardly anything for P2 elements. Tested up to
$10^5$ unknowns. However, the technique is important and it gave
a significant speed-up when used in the Oasis CFD code by Mikael and
co-workers (that code is on par wit OpenFOAM).]

[hpl: I AM HERE!]

======= A welding example with post processing and animation =======
label{ch:diffusion:welding}

The focus so far in this tutorial has been on producing the solution
of PDE problems. For scientific investigations, the primary work is
often with post processing results: computing quantities derived from
the solution and inspecting these with visualization or data analysis tools.
To ease this process, we shall make use of a convenient tool, `cbcpost`,
for post processing, saving data to file(s), and animating solutions.
We recommend to use
`cbcpost` in all time-dependent FEniCS solvers, but it also has a lot
to offer in stationary problems too.

To explain the usage of `cbcpost` for storage and plotting,
we address a real physical application:
welding of a plate, where a moving heat source gives rise to a moving
temperature field.

===== Post processing data and saving to file =====
label{ch:diffusion:welding:cbcpost}

=== Installation ===

The `cbcpost` package is not a part of the `fenics` package so you
will need to install it.
The simplest installation method is to use `pip`. We recommend to
install a companion package `fenicstools` as well. Just run

!bc
sudo pip install git+https://bitbucket.org/simula_cbc/cbcpost.git
sudo pip install git+https://github.com/mikaem/fenicstools.git
!ec
in a terminal window (skip `sudo` on Windows machines).
Alternatively, you can grab the source code and run `setup.py` the usual
way Python packages are installed from source:

!bc sys
Terminal> git clone https://bitbucket.org/simula_cbc/cbcpost.git
Terminal> cd cbcpost
Terminal> python setup.py install
Terminal> cd ..
Terminal> git clone https://github.com/mikaem/fenicstools.git
Terminal> cd fenicstools
Terminal> python setup.py install
!ec

=== Basic commands ===

We must create a *post processor* and then specify what kind of
results we want to be stored on file and (optionally) get visualized.
Suppose we have a field with logical name `Temperature` that we want
to save in XDMF/HDF5 format in files in a fresh subdirectory `Results`:

!bc pycod
import cbcpost as post
# Create post processor
pp = post.PostProcessor(dict(casedir='Results', clean_casedir=True))
# Specify storage of a "Temperature" field
pp.add_field(post.SolutionField(
    'Temperature',
    dict(save=True,
         save_as=['hdf5', 'xdmf'],
         plot=True,
	 plot_args=dict(range_min=0.0, range_max=1.2))))
!ec
The `plot=True` automatically launches `fenics.plot` commands of
this scalar field during the simulation. The ranges of the color
scale must be given (as `float` variables) so that the color scale
stays fixed during the animation on the screen.

Inside the time loop, we have to feed a new solution to the post processor
to get it saved:

!bc pycod
pp.update_all({'Temperature': lambda: T}, t, timestep)
!ec
Here, `T` is the `Function` object that we have solved for, `t` is
current time, and `timestep` is the corresponding time step number.

One can specify many fields to be saved (and plotted), but even more
important: `cbcpost` can calculate a lot of derived quantities from
the solution, such as

 * time derivatives and integrals of vector/scalar fields
 * extraction of fields over subdomains
 * slicing of fields in 3D geometries
 * averaging of fields in space or time
 * norms and point values of fields as function of time
 * user-defined post processing of fields

!bnotice Tip: Use `cbcpost` to visualize time-dependent data
Instead of issuing your own `plot` commands in time-dependent
problems, it is safer and more convenient to specify `plot=True`
and fix the range of the color scale, when you add fields
to the post processor. Multiple fields will be synchronized during
the animation.
!enotice

===== Heat transfer due to a moving welding source =====
label{ch:diffusion:welding:problem}

Let us solve a real diffusion problem taken from welding.
A moving welding equipment acts as a moving heat source.
The question is how the heat from the equipment spreads out
in the material that is being welded. We use the standard
heat equation and do not take phase transitions into account.
The governing PDE is then

!bt
\[ \varrho c \frac{\partial u}{\partial t} = k\nabla^2 u + f,\]
!et
where $u$ is temperature, $\varrho$ is the density of the material,
$c$ is the heat capacity at constant volume, $k$ is the heat
conduction coefficient, and $f$ models the heat source from the
welding equipment. The domain is $\Omega = [0,L]\times [0,L]$.

A welding source rotating with angular velocity $\omega$ about a
point $(x_0,y_0)$ can be modelled as a Gaussian function with
``standard deviation'' $\sigma$:

!bt
\[ f(x,y,t) = A\exp{\left(-\frac{1}{2}
\left(\frac{x-(x_0 + R\cos\omega t)}{\sigma}\right)^2 -\frac{1}{2}
\left(\frac{y-(y_0 + R\sin\omega t)}{\sigma}\right)^2\right)}\tp\]
!et
The parameter $A$ is the strength of the heat source.

The initial condition is that the material has constant room temperature.

===== Scaling of the welding problem =====
label{ch:diffusion:welding:scaling}

There are 10 physical parameters in the problem:
$L$, $\varrho$, $c$, $k$, $A$, $x_0$, $y_0$, $R$, $\omega$, $\sigma$.
Scaling can dramatically reduce the number of parameters and also
introduce new parameters that are much easier to assign numerical
values. We therefore scale the problem. As length scale, we choose
$L$ so the scaled domain becomes the unit square. As time scale
and characteristic size of $u$, we just introduce $t_c$ ad $u_c$.
This means that we introduce scaled variables

!bt
\[
\bar x = \frac{x}{L},\ \bar y = \frac{y}{L},\ \bar t =\frac{t}{t_c},
\ \bar u = \frac{u-U_s}{u_c}\tp
\]
!et
The parameter $U_s$ is the temperature of the surroundings (the initial
conditions) such that we can have $u=0$ at $t=0$.

The scaled form of $f$ is naturally $\bar f = f/A$, since this makes
$\bar f\in (0,1]$. The arguments in the exponential function in $f$ can
also be scaled:

!bt
\begin{align*}
\bar f &= \exp{\left(-\frac{1}{2}
\left(\frac{\bar xL -(L \bar x_0 + L\bar R\cos\omega t_c t)}{\sigma}\right)^2 -\frac{1}{2}
\left(\frac{L \bar y-(L\bar y0 + L\bar R\sin\omega t_c t)}{\sigma}\right)^2\right)}\\
&= \exp{\left(-\frac{1}{2}\frac{L^2}{\sigma^2}
\left(x -(\bar x_0 + \bar R\cos\omega t_c \bar t)\right)^2 -\frac{1}{2}
\left(\bar y-(\bar y0 + \bar R\sin\omega t_c \bar t)\right)^2\right)}\\
&= \exp{\left(-\frac{1}{2}\beta
\left(x -(\frac{1}{2} + \bar R\cos\bar t)\right)^2 -\frac{1}{2}
\left(\bar y-(\frac{1}{2} + \bar R\sin\bar t)\right)^2\right)},
\end{align*}
!et
where $\beta$ is a dimensionless parameter,

!bt
\[ \beta = \frac{L}{\sigma},\]
!et
reflecting the ratio of the domain size and the width of the heat source.
Moreover, we have restricted the rotation point to be the center point
of the domain:

!bt
\[ (\bar x_0,\bar y_0) = (\frac{1}{2},\frac{1}{2})\tp\]
!et
The time scale
in diffusion problems is usually related to the ``speed of the
diffusion'', but in this problem it is more natural to base the time
scale on the movement of the heat source, which suggests setting
$t_c = 1/\omega$.

Inserting the new scaled variables in the PDE leads to

!bt
\[ \frac{\partial \bar u}{\partial\bar t} =
\frac{k}{\omega\varrho c L^2}\bar\nabla^2\bar u +
\frac{A}{\omega u_c\varrho c}\bar f(\bar x,\bar y,\bar t)\tp\]
!et
The first coefficient is a dimensionless number,

!bt
\[ \gamma = \frac{k}{\omega\varrho c L^2},\]
!et
while the second coefficient can be used to determine $u_c$ by demanding
the source term to balance the time derivative term,

!bt
\[ u_c = \frac{A}{\omega\varrho c}\tp\]
!et
Our aim is to have $\bar u \in [0,1]$, but this $u_c$ do not capture
the precise magnitude of $u$. However, we believe that the characteristic
size of $u$ is

!bt
\[ u_c = \delta^{-1}\frac{A}{\omega\varrho c},\]
!et
for a scaling factor $\delta$. Using this $u_c$ gives the PDE

!bt
\[ \frac{\partial \bar u}{\partial\bar t} =
\gamma\bar\nabla^2\bar u +
\delta\bar f(\bar x,\bar y,\bar t),\]
!et
with two dimensionless variables, but $\delta$ is tuned from experiments
to give $\bar u$ a typically size of unity.

Looking at $\gamma$, we see that it can be written

!bt
\[ \gamma = \frac{1/\omega}{\varrho c L^2/k},\]
!et
which is the ratio of the time scale for the heat source and the
time scale for diffusion.

To summarize, the physics of our problem depends now on
$\beta$, $\bar R$, and $\gamma$, just three parameters.
Of these, $\bar R = 0.2$ is an appropriate choice. For a quite
localized heat source in space, $\beta=10$ is a suitable parameter.
Then we are actually left with only one parameter to adjust: $\gamma$.
It is much easier to assign this parameter a value than to set
$\varrho$, $c$, and $k$ for some chosen material, and then
determine $A$, $L$, etc.

===== A function-based solver =====
label{ch:diffusion:welding:funcsolver}

We can use the `solver_minimize_assembly` function to solve the
welding problem. The application code just declares the problem-dependent
parameters and calls the solver function. From a trial run we find
that $\delta = 700$ gives $\bar u$ of unit size for moderate $\gamma$
values.

!bc pycod
def application_welding(gamma=1, delta=1):
    from math import pi, sin, cos
    u0 = Constant(0)
    I = Constant(0)
    beta = 10
    R = 0.2
    f = Expression(
        'delta*exp(-0.5*pow(beta,2)*(pow(x[0]-(0.5+R*cos(t)),2) + '
                                    'pow(x[1]-(0.5+R*sin(t)),2)))',
        delta=delta, beta=beta, R=R, t=0)
    # Simulate to rotations with the equipment
    omega = 1.0      # Scaled angular velocity
    P = 2*pi/omega   # One period of rotation
    T = 2*P          # Total simulation time
    dt = P/40        # 40 steps per rotation
    Nx = Ny = 60
    solver_minimize_assembly(
        gamma, f, u0, I, dt, T, Nx, Ny, degree=1,
        user_action=ProcessResults(), I_project=False)
!ec

The remaining task is to write the user action callback function to
process the solution at teach time step. We want to make use of
`cbcpost` for storage and plotting.  Since we need the post processor
variable, called `pp` in Section ref{ch:diffusion:welding:cbcpost},
needs to survive between calls to the user action function, we find it
most convenient to implement this function in terms of a class with
`pp` as attribute and `__call__` as the user action function.  We want
to make comparisons between the heat source and the temperature
response, so we register both fields for storage and plotting:

@@@CODE-4 src/diffusion_func.py fromto: import cbcpost as post@# Leave plotting to cbcpost
We took the opportunity in the callback function (`__call__`) to also
store the `u` and `f` functions to VTK files, although this is really
not necessary since ParaView or VisIt can read XDMF files.

Note that the use of `cbcpost` is usually very dependent on the
problem at hand, so it does not make sense to include `cbcpost` code
in a general PDE solver, only in problem-specific code such as the
user action function.

Getting an animation on the screen with the built-in plotting tool is
a matter of running the welding example:

!bc pyshell
>>> from diffusion_func import application_welding as a
>>> a(gamma=10, delta=700)
!ec
(We introduced the synonym `a` to save some typing.)
Or you can run this as a command in the terminal:

!bc sys
Terminal> python -c '\
from diffusion_func import application_welding as a;
a(gamma=10, delta=700)'
!ec

Since we have fixed the color scale of the temperature to have values
in $[0,1.1]$, we must adjust $\delta$ appropriately to $\gamma$.  For
example, running $\gamma=40$ reveals, from the output in the terminal,
that the maximum temperature is about 0.25, and consequently we do not
see much. For any given $\gamma$, run the problem with $\delta=1$ (and
say `num_rotations=0.2` to make a quick simulation), and rerun with
$\delta$ as one over the maximum temperature.  Here we get an
approximate $\delta = 66.7\gamma$ for $\gamma \leq 0.1$. Try running
$\gamma=0.01$ and $\delta=1$ to observe some more significant heat
transfer away from the welding equipment. With $\gamma =0.001$ there
is significant heat build-up, but for so small $\gamma$ we should
re-scale the problem and use the diffusion time scale as time scale.

In ParaView, load `Results/Temperature/Temperature.xdmf` as file,
click _Apply_, then the play button for animation. If the animation is
not correct, repeat the procedure. Thereafter, split the layout in
two, choose _3D View_, load `Results/Heat source/Heat_source.xmdf`,
click _Apply_, and run the animation. The two plots are synchronized.

# This is only in brief now in development
#MOVIE: [https://github.com/hplgit/fenics-tutorial/tree/master/doc/pub/mov/welding_gamma1.ogg] Welding example with $\gamma=1$.
#MOVIE: [https://github.com/hplgit/fenics-tutorial/tree/brief/doc/pub/mov/welding_gamma1.ogg] Welding example with $\gamma=1$.


======= Refactored implementation =======
label{ch:diffusion:refactor}

The flat program for the diffusion solver in
`${prog["diffusion_flat1"]}.py` and `${prog["diffusion_flat2"]}.py`
was refactored in `${prog["diffusion_func"]}.py` in
terms of a `solver` function with the general code
for solving the PDE problem, a callback function for processing
the solution at each time step, and an application function using
the solver and defining the callback function to solve a specific
problem. However, for time-dependent problems a solver function that
gets all its input through a set of arguments is less flexible
than a solver *class*, which can demand its input both through
arguments and through functions (in subclasses) provided by the user.




===== A class-based solver for a general diffusion problem =====
label{ch:diffusion:refactor:class_solver}

When you want to apply some software tool for solving a PDE problem,
you usually want to explore a family of related problems. To this end,
you need to formulate some general form of the PDE problem and then


% if EXV:
===== Exercise: Implement second-order schemes in time =====

A backward difference of accuracy $\mathcal{O}(\Delta t^2)$ involves
three time levels:

!bt
\[ \frac{\partial}{\partial t}u(x, y, t_{n+1}) \approx
\frac{u^{n+1} - 4u^n + u^{n-1}}{2\Delta t}\tp\]
!et
Make a solver based on this scheme. For the first time step, use the
two-level
Backward Euler method. The implementation should also offer the Backward Euler
method. In addition, implement the Crank-Nicolson method where you solve

!bt
\[ \frac{\partial u}{\partial t} = G(u)\]
!et
by

!bt
\[ \frac{u^{n+1}-u^n}{\Delta t} = \frac{1}{2}(G(u^{n+1}) + G(u^n))\tp\]
!et
This method also has a truncation error of order $\Delta t^2$.
[hpl: Find some good test problems for comparing the performance of the schemes.]
% endif

===== A physical example =====
label{ftut:timedep:diffusion2:sin}

idx{`${prog["sin_daD"]}.py`}

With the basic programming techniques for time-dependent problems from
Sections ref{ftut:timedep:diffusion1:noassemble} and
ref{ftut:timedep:diffusion1:impl} we are ready to attack more
physically realistic examples.  The next example concerns the
question: How is the temperature in the ground affected by day and
night variations at the earth's surface?  We consider some box-shaped
domain $\Omega$ in $d$ dimensions with coordinates
$x_0,\ldots,x_{d-1}$ (the problem is meaningful in 1D, 2D, and 3D).
At the top of the domain, $x_{0}=0$, we have an oscillating
temperature

!bt
\begin{equation*}
T_0(t) = T_R + T_A\sin (\omega t),
\end{equation*}
!et
where $T_R$ is some reference temperature, $T_A$ is the amplitude of
the temperature variations at the surface, and $\omega$ is the
frequency of the temperature oscillations.  At all other boundaries we
assume that the temperature does not change anymore when we move away
from the boundary, i.e., the normal derivative is zero.  Initially,
the temperature can be taken as $T_R$ everywhere.  The heat
conductivity properties of the soil in the ground may vary with space
so we introduce a variable coefficient $\kappa$ reflecting this
property.  Figure ref{ftut:timedep:diffusion2:sin:fig1} shows a sketch
of the problem, with a small region where the heat conductivity is
much lower.  [hpl: All parameters $\varrho$, $c$, and $\kappa$ are
different!]

FIGURE:[fig/daynight, width=480] Sketch of a (2D) problem involving heating and cooling of the ground due to an oscillating surface temperature. label{ftut:timedep:diffusion2:sin:fig1}

The initial-boundary value problem for this problem reads

!bt
\begin{align}
\varrho c{\partial T\over\partial t} &= \nabla\cdot\left( \kappa\nabla T\right)\hbox{ in }\Omega\times (0,t_{\hbox{stop}}],\\
T &= T_0(t)\hbox{ on }\Gamma_0,\\
{\partial T\over\partial n} &= 0\hbox{ on }\partial\Omega\backslash\Gamma_0,\\
T &= T_R\hbox{ at }t =0\tp
\end{align}
!et
Here, $\varrho$ is the density of the soil, $c$ is the
heat capacity, $\kappa$ is the thermal conductivity
(heat conduction coefficient)
in the soil, and $\Gamma_0$ is the surface boundary $x_{0}=0$.

We use a $\theta$-scheme in time, i.e., the evolution equation
$\partial P/\partial t=Q(t)$ is discretized as

!bt
\begin{equation*}
{P^k - P^{k-1}\over{\dt}} = \theta Q^k + (1-\theta )Q^{k-1},
\end{equation*}
!et
where $\theta\in[0,1]$ is a weighting factor: $\theta =1$ corresponds
to the backward difference scheme, $\theta =1/2$ to the Crank-Nicolson
scheme, and $\theta =0$ to a forward difference scheme.
The $\theta$-scheme applied to our PDE results in

!bt
\begin{equation*}
\varrho c{T^k-T^{k-1}\over{\dt}} =
\theta \nabla\cdot\left( \kappa\nabla T^k\right)
+ (1-\theta) \nabla\cdot\left( k\nabla T^{k-1}\right)\tp
\end{equation*}
!et
Bringing this time-discrete PDE into weak form follows the technique shown
many times earlier in this tutorial. In the standard notation
$a(T,v)=L(v)$ the weak form has

!bt
\begin{align}
a(T,v) &= \int_\Omega
\left( \varrho c Tv + \theta{\dt} \kappa\nabla T\cdot \nabla v\right) \dx,\\
L(v) &= \int_\Omega \left( \varrho c T^{k-1}v - (1-\theta){\dt}
\kappa\nabla T^{k-1}\cdot \nabla v\right) \dx\tp
\end{align}
!et

Observe that boundary integrals vanish because of the Neumann boundary
conditions.

idx{heterogeneous medium}
idx{multi-material domain}

The size of a 3D box is taken as $W\times W\times D$, where $D$ is
the depth and $W=D/2$ is the width.
We give the degree of the basis functions at the command line, then $D$,
and then the divisions of the domain in the various directions.
To make a box, rectangle, or interval of arbitrary (not unit) size,
we have the classes `BoxMesh`, `RectangleMesh`, and
`IntervalMesh` at our disposal. The mesh and the function space
can be created by the following code:

!bc pycod
degree = int(sys.argv[1])
D = float(sys.argv[2])
W = D/2.0
divisions = [int(arg) for arg in sys.argv[3:]]
d = len(divisions)  # no of space dimensions
if d == 1:
    mesh = IntervalMesh(divisions[0], -D, 0)
elif d == 2:
    mesh = RectangleMesh(-W/2, -D, W/2, 0, divisions[0], divisions[1])
elif d == 3:
    mesh = BoxMesh(-W/2, -W/2, -D, W/2, W/2, 0,
               divisions[0], divisions[1], divisions[2])
V = FunctionSpace(mesh, 'P', degree)
!ec
The `RectangleMesh` and `BoxMesh` objects are defined by the coordinates
of the "minimum" and "maximum" corners.

Setting Dirichlet conditions at the upper boundary can be done by

!bc pycod
T_R = 0; T_A = 1.0; omega = 2*pi

T_0 = Expression('T_R + T_A*sin(omega*t)',
                 T_R=T_R, T_A=T_A, omega=omega, t=0.0)

def surface(x, on_boundary):
    return on_boundary and abs(x[d-1]) < 1E-14

bc = DirichletBC(V, T_0, surface)
!ec

The $\kappa$ function can be defined as a constant $\kappa_1$ inside
the particular rectangular area with a special soil composition, as
indicated in Figure ref{ftut:timedep:diffusion2:sin:fig1}. Outside
this area $\kappa$ is a constant $\kappa_0$.
The domain of the rectangular area is taken as

!bt
\begin{equation*}
[-W/4, W/4]\times [-W/4, W/4]\times [-D/2, -D/2 + D/4]
\end{equation*}
!et
in 3D, with $[-W/4, W/4]\times [-D/2, -D/2 + D/4]$ in 2D and
$[-D/2, -D/2 + D/4]$ in 1D.
Since we need some testing in the definition of the $\kappa(\x)$
function, the most straightforward approach is to define a subclass
of `Expression`, where we can use a full Python method instead of
just a C++ string formula for specifying a function.
The method that defines the function is called `eval`:

!bc pycod
class Kappa(Expression):
    def eval(self, value, x):
        """x: spatial point, value[0]: function value."""
        d = len(x)  # no of space dimensions
        material = 0  # 0: outside, 1: inside
        if d == 1:
            if -D/2. < x[d-1] < -D/2. + D/4.:
                material = 1
        elif d == 2:
            if -D/2. < x[d-1] < -D/2. + D/4. and \
               -W/4. < x[0] < W/4.:
                material = 1
        elif d == 3:
            if -D/2. < x[d-1] < -D/2. + D/4. and \
               -W/4. < x[0] < W/4. and -W/4. < x[1] < W/4.:
                material = 1
        value[0] = kappa_0 if material == 0 else kappa_1
!ec
The `eval` method gives great flexibility in defining functions,
but a downside is that C++ calls up `eval` in Python for
each point `x`, which is a slow process, and the number of calls
is proportional to the number of numerical
integration points in the mesh (about
the number of degrees of freedom).
Function expressions in terms of strings are compiled to efficient
C++ functions, being called from C++, so we should try to express functions
as string expressions if possible. (The `eval` method can also be
defined through C++ code, but this is much
more complicated and not covered here.)
Using inline if-tests in C++, we can make string expressions for
$\kappa$, here stored in a Python dictionary so that `kappa_str[d-1]`
is the proper test in a $d$ dimensional problem:

!bc pycod
kappa_str = {}
kappa_str[1] = 'x[0] > -D/2 && x[0] < -D/2 + D/4 ? kappa_1 : kappa_0'
kappa_str[2] = 'x[0] > -W/4 && x[0] < W/4 '\
               '&& x[1] > -D/2 && x[1] < -D/2 + D/4 ? '\
               'kappa_1 : kappa_0'
kappa_str[3] = 'x[0] > -W/4 && x[0] < W/4 '\
               'x[1] > -W/4 && x[1] < W/4 '\
               '&& x[2] > -D/2 && x[2] < -D/2 + D/4 ?'\
               'kappa_1 : kappa_0'

kappa = Expression(kappa_str[d],
                   D=D, W=W, kappa_0=kappa_0, kappa_1=kappa_1)
!ec

Let `T` denote the unknown spatial temperature function at the
current time level, and let `T_1` be the corresponding function
at one earlier time level.
We are now ready to define the initial condition and the
`a` and `L` forms of our problem:

!bc pycod
T_prev = interpolate(Constant(T_R), V)

rho = 1
c = 1
period = 2*pi/omega
t_stop = 5*period
dt = period/20  # 20 time steps per period
theta = 1

T = TrialFunction(V)
v = TestFunction(V)
f = Constant(0)
a = rho*c*T*v*dx + theta*dt*kappa*\
    dot(grad(T), grad(v))*dx
L = (rho*c*T_prev*v + dt*f*v -
     (1-theta)*dt*kappa*dot(grad(T_1), grad(v)))*dx

A = assemble(a)
b = None  # variable used for memory savings in assemble calls
T = Function(V)   # unknown at the current time level
!ec
We could, alternatively, break `a` and `L` up in subexpressions
and assemble a mass matrix and stiffness matrix, as exemplified in
Section ref{ftut:timedep:diffusion1:noassemble}, to avoid
assembly of `b` at every time level. This modification is
straightforward and left as an exercise. The speed-up can be significant
in 3D problems.

The time loop is very similar to what we have displayed in
Section ref{ftut:timedep:diffusion1:impl}:

!bc pycod
T = Function(V)   # unknown at the current time level
t = dt
while t <= t_stop:
    b = assemble(L, tensor=b)
    T_0.t = t
    bc.apply(A, b)
    solve(A, T.vector(), b)
    # visualization statements
    t += dt
    T_prev.assign(T)
!ec
The complete code in `${prog["sin_daD"]}.py` contains several
statements related to visualization and animation of the solution, both as a
finite element field (`plot` calls) and as a curve in the
vertical direction. The code also plots the exact analytical solution,

!bt
\[
T(x,t) = T_R + T_Ae^{ax}\sin (\omega t + ax),\quad a =\sqrt{\omega\varrho c\over 2\kappa},
\]
!et
which is valid when $\kappa = \kappa_0=\kappa_1$.

Implementing this analytical solution as a Python function
taking scalars and numpy arrays as arguments requires a word of caution.
A straightforward function like

!bc pycod
def T_exact(x):
    a = sqrt(omega*rho*c/(2*kappa_0))
    return T_R + T_A*exp(a*x)*sin(omega*t + a*x)
!ec
will not work and result in an error message from UFL. The reason is that
the names `exp` and `sin` are those imported
by the `from fenics import *` statement, and these names
come from UFL and are aimed at being used in variational forms.
In the `T_exact` function where `x` may be a scalar or a
`numpy` array, we therefore need to explicitly specify
`np.exp` and `np.sin` (if `numpy` is imported under the common name `np`):

!bc pycod
def T_exact(x):
    a = sqrt(omega*rho*c/(2*kappa_0))
    return T_R + T_A*np.exp(a*x)*np.sin(omega*t + a*x)
!ec

The complete code is found in the file The reader is encouraged to
play around with the code and test out various parameter sets:

  o $T_R=0$, $T_A=1$, $\kappa_0 = \kappa_1=0.2$, $\varrho = c = 1$, $\omega = 2\pi$
  o $T_R=0$, $T_A=1$, $\kappa_0=0.2$, $\kappa_1=0.01$, $\varrho = c = 1$, $\omega = 2\pi$
  o $T_R=0$, $T_A=1$, $\kappa_0=0.2$, $\kappa_1=0.001$, $\varrho = c = 1$, $\omega = 2\pi$
  o $T_R=10$ C, $T_A=10$ C, $\kappa_0= 2.3 \hbox{ K}^{-1}\hbox{Ns}^{-1}$,
    $\kappa_1= 100 \hbox{ K}^{-1}\hbox{Ns}^{-1}$,
    $\varrho = 1500\hbox{ kg/m}^3$,
    $c = 1480\hbox{ Nm}\cdot\hbox{kg}^{-1}\hbox{K}^{-1}$,
    $\omega = 2\pi/24$ 1/h  $= 7.27\cdot 10^{-5}$ 1/s, $D=1.5$ m
  o As above, but $\kappa_0= 12.3 \hbox{ K}^{-1}\hbox{Ns}^{-1}$ and
    $\kappa_1= 10^4 \hbox{ K}^{-1}\hbox{Ns}^{-1}$

Data set number 4 is relevant for real temperature variations in
the ground (not necessarily the large value of $\kappa_1$),
while data set number 5
exaggerates the effect of a large heat conduction contrast so that
it becomes clearly visible in an animation.

#  kappa_1 = 1.1, varrho_1 = 1200, c_1 = 1000 => 9.17E-7
#  kappa_0 = 2.3, varrho_0 = 1800, c_0 = 1500 => 8.52E-7
