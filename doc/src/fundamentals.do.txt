!split
========= Fundamentals =========
label{ch:fundamentals}

!bquote
The goal of this chapter is to show how a range of important PDEs
from science and engineering can be quickly solved with a few lines
of FEniCS code. We introduce the most
fundamental FEniCS objects such as `Mesh`, `Function`,
`FunctionSpace`, `TrialFunction`,
and `TestFunction`, and learn how to set up the variational formulation
of the PDE problem in a way that closely resembles the mathematics.

The code is made as simple as possible, we solve all linear systems
by (sparse) Gaussian elimination, we don't use any problem-dependent
optimizations of algorithms and code, and we only treat examples taking
place in homogeneous media. Subsequent chapters will extend the
examples here with more general, efficient, and sophisticated
implementations.
!equote

======= The Poisson equation =======

===== Mathematical problem formulation =====

label{tut:poisson1:bvp}
idx{Poisson's equation}

Let us start by writing a ``Hello, World!'' program. In the world of
PDEs, thus must be a program that solves the Poisson equation:

!bt
\begin{align}
- \nabla^2 u(\x) &= f(\x),\quad \x\mbox{ in } \Omega,
label{tut:poisson1}\\
u(\x) &= u_0(\x),\quad \x\mbox{ on } \partial \Omega\tp label{tut:poisson1:bc}
\end{align}
!et
Here, $u = u(\x)$ is the unknown function, $f = f(\x)$ is a
prescribed function, $\nabla^2$ is the Laplace operator (also
often written as $\Delta$), $\Omega$ is the spatial domain, and
$\partial\Omega$ is the boundary of $\Omega$. A stationary PDE like
this, together with a complete set of boundary conditions, constitute
a *boundary-value problem*, which must be precisely stated before
it makes sense to start solving it with FEniCS.

In two space dimensions with coordinates $x$ and $y$, we can write out
the Poisson equation as

!bt
\begin{equation}
- {\partial^2 u\over\partial x^2} -
{\partial^2 u\over\partial y^2} = f(x,y)\tp
\end{equation}
!et
The unknown $u$ is now a function of two variables, $u = u(x,y)$, defined
over a two-dimensional domain $\Omega$.

The Poisson equation arises in numerous physical contexts, including
heat conduction, electrostatics, diffusion of substances, twisting of
elastic rods, inviscid fluid flow, and water waves. Moreover, the
equation appears in numerical splitting strategies of more complicated
systems of PDEs, in particular the Navier--Stokes equations.

Solving a PDE such as the Poisson equation in FEniCS consists of the
following steps:

  o Identify the computational domain ($\Omega$), the PDE, its
    boundary conditions, and source terms ($f$).
  o Reformulate the PDE as a finite element variational problem.
  o Write a Python program which defines the computational domain,
    the variational problem, the boundary conditions, and source
    terms, using the corresponding FEniCS abstractions.
  o Call FEniCS to solve the PDE and, optionally, extend the program
    to compute derived quantities such as fluxes and averages, and
    visualize the results.

We shall now go through steps 2--4 in detail. The key feature of
FEniCS is that steps 3 and 4 result in fairly short code, while most
other software frameworks for PDEs require much more code and more
technically difficult programming.

===== Finite element variational formulation =====
label{tut:poisson1:varform}
idx{variational formulation}

FEniCS is based on the finite element method, which is a general and
efficient mathematical machinery for numerical solution of PDEs. The
starting point for the finite element methods is a PDE expressed in
*variational form*. Readers who are not familiar with variational
problems will get a brief introduction to the topic in this tutorial,
but getting and reading a proper book on the finite element method in
addition is encouraged. Section ref{tut:fembooks} contains a list of
some suitable books.

idx{test function}
idx{trial function}

The basic recipe for turning a PDE into a variational problem is to
multiply the PDE by a function $v$, integrate the resulting equation
over the domain $\Omega$, and perform integration by parts of terms
with second-order derivatives. The function $v$ which multiplies the
PDE is called a *test function*. The unknown function $u$ to be
approximated is referred to as a *trial function*. The terms test and
trial function are used in FEniCS programs too. Suitable function
spaces must be specified for the test and trial functions. For
standard PDEs arising in physics and mechanics such spaces are well
known.

In the present case, we first multiply the Poisson equation
by the test function $v$ and integrate over $\Omega$:

!bt
\begin{equation}
label{tut:poisson1:multbyv}
 -\int_\Omega (\nabla^2 u)v \dx = \int_\Omega fv \dx\tp \end{equation}
!et
We then apply integration by parts to the integrand with
second-order derivatives. We find that

!bt
\begin{equation}
label{tut:poisson1:eqbyparts}
 -\int_\Omega (\nabla^2 u)v \dx
= \int_\Omega\nabla u\cdot\nabla v \dx - \int_{\partial\Omega}{\partial u\over
\partial n}v \ds ,
\end{equation}
!et
where $\frac{\partial u}{\partial n} = \nabla u \cdot n$ is the
derivative of $u$ in the outward normal direction $n$ on the
boundary. The test function $v$ is required to vanish on the parts of
the boundary where the solution $u$ is known, which in the present
problem implies that $v=0$ on the whole boundary $\partial\Omega$.
The second term on the right-hand side of
(ref{tut:poisson1:eqbyparts}) therefore vanishes. From
(ref{tut:poisson1:multbyv}) and (ref{tut:poisson1:eqbyparts}) it
follows that

!bt
\begin{equation}
\int_\Omega\nabla u\cdot\nabla v \dx = \int_\Omega fv \dx\tp
label{tut:poisson1:weak1}
\end{equation}
!et
If we require that this equation holds for all test functions $v$ in
some suitable space $\hat V$, the so-called *test space*, we obtain a
well-defined mathematical problem that uniquely determines the
solution $u$ which lies in some (possibly different) function space
$V$, the so-called *trial space*.  We refer to
(ref{tut:poisson1:weak1}) as the *weak form* or *variational form* of
the original boundary-value problem
(ref{tut:poisson1})--(ref{tut:poisson1:bc}).

The proper statement of
our variational problem now goes as follows:
Find $u \in V$ such that

!bt
\begin{equation} label{tut:poisson1:var}
  \int_{\Omega} \nabla u \cdot \nabla v \dx =
  \int_{\Omega} fv \dx
  \quad \forall v \in \hat{V}.
\end{equation}
!et
The trial and test spaces $V$ and $\hat V$ are in the present
problem defined as

!bt
\begin{align*}
     V      &= \{v \in H^1(\Omega) : v = u_0 \mbox{ on } \partial\Omega\}, \\
    \hat{V} &= \{v \in H^1(\Omega) : v = 0 \mbox{ on } \partial\Omega\}\tp
\end{align*}
!et

In short, $H^1(\Omega)$ is the mathematically well-known Sobolev space
containing functions $v$ such that $v^2$ and $|\nabla v|^2$ have
finite integrals over $\Omega$ (essentially meaning that the functions
are continuos). The solution of the underlying PDE must lie in a
function space where also the derivatives are continuous, but the
Sobolev space $H^1(\Omega)$ allows functions with discontinuous
derivatives. This weaker continuity requirement of $u$ in the
variational statement (ref{tut:poisson1:var}), as a result of the
integration by parts, has great practical consequences when it comes
to constructing finite element function spaces. In particular, it
allows the use of piecewise polynomial function spaces; i.e., function
spaces constructed by stiching together polynomial functions on simple
domains such as intervals, triangles, or tetrahedrons.

The variational problem (ref{tut:poisson1:var}) is a *continuous
problem*: it defines the solution $u$ in the infinite-dimensional
function space $V$. The finite element method for the Poisson equation
finds an approximate solution of the variational problem
(ref{tut:poisson1:var}) by replacing the infinite-dimensional function
spaces $V$ and $\hat{V}$ by *discrete* (finite-dimensional) trial and
test spaces $V_h\subset{V}$ and $\hat{V}_h\subset\hat{V}$. The discrete variational problem reads: Find $u_h \in
V_h \subset V$ such that

!bt
\begin{equation} label{tut:poisson1:vard}
  \int_{\Omega} \nabla u_h \cdot \nabla v \dx =
  \int_{\Omega} fv \dx
  \quad \forall v \in \hat{V}_h \subset \hat{V}\tp
\end{equation}
!et
This variational problem, together with a suitable definition of the
function spaces $V_h$ and $\hat{V}_h$, uniquely defines our approximate
numerical solution of Poisson's equation (ref{tut:poisson1}). The
mathematical framework may seem complicated at first glance, but the
good news is the finite element variational problem
(ref{tut:poisson1:vard}) looks the same as the continuous variational
problem (ref{tut:poisson1:var}), and FEniCS can automatically solve
variational problems like (ref{tut:poisson1:vard})!

#The choice of $\hat{V}_h$ and $V_h$ follows directly from the kind of
#finite elements we want to apply in our problem. For example, choosing
#the well-known linear triangular element with three nodes implies that
#$\hat V_h$ and $V_h$ are the spaces of all piecewise linear functions
#over a mesh of triangles, where the functions in $\hat V_h$ are zero
#on the boundary and those in $V_h$ equal $u_0$ on the boundary.

!bwarning What we mean by the notation $u$ and $V$
The mathematics literature on variational problems writes $u_h$ for
the solution of the discrete problem and $u$ for the solution of the
continuous problem. To obtain (almost) a one-to-one relationship
between the mathematical formulation of a problem and the
corresponding FEniCS program, we shall drop the subscript $_h$ and use
$u$ for the solution of the discrete problem and $\uex$ for the exact
solution of the continuous problem, *if* we need to explicitly distinguish
between the two. Similarly, we will let $V$ denote the discrete finite
element function space in which we seek our solution.
!ewarning

===== Abstract finite element variational formulation =====
label{tut:poisson1:abstrat}
idx{abstract variational formulation}

It turns out to be convenient to introduce the following canonical
notation for variational problems:

!bt
\begin{equation}
a(u, v) = L(v)\tp
\end{equation}
!et
For the Poisson equation, we have:

!bt
\begin{align}
a(u, v) &= \int_{\Omega} \nabla u \cdot \nabla v \dx,
label{tut:poisson1:vard:a}\\
L(v) &= \int_{\Omega} fv \dx\tp  label{tut:poisson1:vard:L}
\end{align}
!et
From the mathematics literature, $a(u,v)$ is known as a *bilinear
form* and $L(v)$ as a *linear form*.  We shall in every linear problem
we solve identify the terms with the unknown $u$ and collect them in
$a(u,v)$, and similarly collect all terms with only known functions in
$L(v)$. The formulas for $a$ and $L$ are then coded directly in the
program.

FEniCS provies all the necessary mathematical notation needed to
express the variational problem $a(u, v) = L(v)$. To solve a linear
PDE in FEniCS, such as the Poisson equation, a user thus needs to
perform only two steps:

  * Express the PDE as a (discrete) variational problem: find $u\in V$
    such that $a(u,v) = L(v)$ for all $v\in \hat{V}$.
  * Choose the finite element spaces $V$ and $\hat V$ by specifying
    the domain (the mesh) and the type of function space (polynomial
    degree and type).

# Suggested: var coeff as early as possible!
# A basic Poisson solver
# Useful extensions/Useful stuff/: var coeff here
# Visualization: membrane, vtk, paraview, structured mesh
# Postprocessing computations: var coeff, functionals, conv rates
# Multiple domains and boundaries

!split
===== Choosing a test problem =====
label{tut:poisson1:testproblem}

The Poisson equation (ref{tut:poisson1}) has so far featured a general
domain $\Omega$ and general functions $u_0$ and $f$. For our first
implementation, we must decide on specific choices of $\Omega$, $u_0$,
and $f$.  It will be wise to construct a specific problem where we can
easily check that the computed solution is correct. Solutions that are
lower-order polynomials are primary candidates. Standard finite
element function spaces of degree $r$ will exactly reproduce
polynomials of degree $r$. And piecewise linear elements ($r=1$) are
able to exactly reproduce a quadratic polynomial on a uniformly
partitioned mesh. This important result can be used to verify our
implementation. We just manufacture some quadratic function in 2D as
the exact solution, say

!bt
\begin{equation}
\label{tut:poisson1:impl:uex}
\uex(x,y) = 1 +x^2 + 2y^2\tp
\end{equation}
!et
By inserting (ref{tut:poisson1:impl:uex}) into the Poisson equation
(ref{tut:poisson1}), we find that $\uex(x,y)$ is a solution if

!bt
\[ f(x,y) = -6,\quad u_0(x,y)=\uex(x,y)=1 + x^2 + 2y^2,\]
!et
regardless of the shape of the domain as long as $\uex$ is prescribed along
the boundary. We choose here, for simplicity,
the domain to be the unit square,

!bt
\[ \Omega = [0,1]\times [0,1] \tp\]
!et
This simple but very powerful method for constructing test problems
is called the *method of manufactured solutions*: pick a simple
expression for the exact solution, plug it into the equation to obtain
the right-hand side (source term $f$), then solve the equation with
this right-hand side and try to reproduce the exact solution.

!bnotice Tip: Try to verify your code with exact numerical solutions!
A common approach to testing the implementation of a numerical method
is to compare the numerical
solution with an exact analytical solution of the test problem and
conclude that the program works if the error is ``small enough''.
Unfortunately, it is impossible to tell if an error of size $10^{-5}$ on a
$20\times 20$ mesh of linear elements is the expected (in)accuracy of the
numerical approximation or if the error also contains the effect of a
bug in the code. All we usually know about the numerical error is its
*asymptotic properties*, for instance that it is proportional to $h^2$
if $h$ is the size of a cell in the mesh. Then we can compare the
error on meshes with different $h$ values to see if the asymptotic
behavior is correct. This is a very powerful verification technique
and is explained in detail in Section
ref{tut:poisson1:convrates}. However, if we have a test problem for which
we know that there should be no approximation errors, we know that
the analytical solution of the PDE problem should be reproduced to
machine precision by the program. That is why we emphasize this kind
of test problems throughout this tutorial. Typically, elements of
degree $r$ can reproduce polynomials of degree $r+1$ exactly, so this
is the starting point for constructing a solution without numerical
approximation errors.
!enotice

[AL: Unsure of this $r + 1$ property.]

!split
===== FEniCS implementation =====
label{tut:poisson1:impl}
label{tut:poisson1:impl:code}

A FEniCS program for solving our test problem for the Poisson equation
in 2D with the given choices of $u_0$, $f$, and $\Omega$ may look as
follows:

@@@CODE src/poisson_2d_flat.py fromto: from fenics import@

The complete code can be found in the file "`${prog['poisson_2d_flat']}.py`":
"${src_url}/${prog['poisson_2d_flat']}.py".

===== Running the program =====
label{tut:poisson1:impl:run}

The FEniCS program must be available in a plain text file, written with a
text editor such as Atom, Sublime Text, Emacs, Vim, or similar.

To run the program `${prog["poisson_2d_flat"]}.py`, open a terminal
window, move to the directory containing the program and type the
following command:

!bc sys
Terminal> python ${prog['poisson_2d_flat']}.py
!ec
Note that this command must be run in a FEniCS-enabled terminal. For
users of the FEniCS Docker containers, this means that you must type
this command after you have started a FEniCS session using
`fenicsproject run`.

When running the above command, FEniCS will run the program to compute
the approximate solution $u$. The approximate solution $u$ will be
compared to the exact solution $\uex$ and the error in the maximum
norm will be printed. Since we know that our approximate solution
should reproduced the exact solution to within machine precision, this
error should be small, something on the order of $10^{-15}$.

[AL: Add text here discussing what to expect in terms of plotting.
 Perhaps we have seamless notebook plotting working soon...]

#A plot window pops up showing how the solution $u$ looks like as a
#surface.  With the left mouse button you can tilt the figure. Click
#`m` to bring up the underlying mesh. Click `p` to save to a PNG file
#`dolfin_plot_0.png` and `P` to save to a PDF file
#`dolfin_plot_1.pdf`. To kill the plot window and terminate the
#application, click `Ctrl+q` (hold down the `Ctrl` key and press `q`).
#Figure ref{tut:poisson:2D:fig:ex1:u} displays the surface and the mesh
#below.  Since $u$ is a simple quadratic function, constructed for
#testing our solver, the surface looks quite boring.

FIGURE:[fig/ex1_u, width=600 frac=0.8] Plot of the solution in the first FEniCS example. label{tut:poisson:2D:fig:ex1:u}

===== Dissection of the program =====
label{tut:poisson1:impl:dissect}

We shall now dissect this FEniCS program in detail. The program is
written in the Python programming language. You may either take a
quick look at the "official Python tutorial":
"http://docs.python.org/tutorial/" to pick up the basics of Python if
you are unfamiliar with the language, or you may learn enough Python
as you go along with the examples in the present tutorial. The latter
strategy has proven to work for many newcomers to FEniCS. This is
because both the amount of abstract mathematical formalism and the
amount of Python expertise that is actually needed to be productive
with FEniCS is quite limited. And Python is an easy-to-learn language
that you will certainly come to love and use far beyond FEniCS
programming. Section ref{tut:pybooks} lists some relevant Python
books.

The listed FEniCS program defines a finite element mesh, a the finite
element function space $V$ on this mesh, boundary conditions for $u$
(the function $u_0$), and the bilinear and linear forms $a(u,v)$ and
$L(v)$.  Thereafter, the unknown trial function $u$ is computed. Then
we can compare the numerical and exact solution as well as visualize
the computed solution $u$.

=== The important first line ===

The first line in the program,

!bc pycod
from fenics import *
!ec
imports the key classes `UnitSquareMesh`, `FunctionSpace`, `Function`,
and so forth, from the FEniCS library.  All FEniCS programs for
solving PDEs by the finite element method normally start with this
line.

## NOTE: index entries *must* become before paragraph/subsubsection
## headings, otherwise sphinx output will be malformed

idx{`Mesh`}

=== Generating simple meshes ===

The statement

!bc pycod
mesh = UnitSquareMesh(8, 8)
!ec
defines a uniform finite element mesh over the unit square
$[0,1]\times [0,1]$. The mesh consists of *cells*, which in 2D are triangles
with straight sides. The parameters 8 and 8 specify that the square
should be divided into $8\times 8$ rectangles, each divided into a pair of
triangles. The total number of triangles (cells) thus becomes
128. The total number of vertices in the mesh is $9\cdot 9=81$.
In later chapters, you will learn how to generate more complex meshes.

idx{`FunctionSpace`}
idx{finite element specifications}
idx{CG finite element family}
idx{Lagrange finite element family}
idx{P1 element}

=== Defining the finite element function space ===

Having a mesh, we can define a finite element function space `V` over
this mesh:

!bc pycod
V = FunctionSpace(mesh, 'P', 1)
!ec

The second argument `'P`' specifies the type of element, while the third
argument is the degree of the basis functions of the element. The type
of element is here ``P'', implying the standard Lagrange family of
elements. You may also use `'Lagrange'` to specify this type of
element. FEniCS supports all simplex element families and the notation
defined in the "Periodic Table of the Finite Elements":
"http://femtable.org" cite{ArnoldLogg2014}.

idx{Periodic Table of the Finite Elements}

The third argument `1` specifies the degree of the finite element.  In
this case, the standard $\mathsf{P}_1$ linear Lagrange element, which
is a triangle with nodes at the three vertices. Some finite element
practitioners refer to this element as the ``linear triangle''. The
computed solution $u$ will be continuous and linearly varying in $x$
and $y$ over each cell in the mesh. Higher-degree polynomial
approximations over each cell are trivially obtained by increasing the
third parameter to `FunctionSpace`, which will then generate function
spaces of type $\mathsf{P}_2$, $\mathsf{P}_3$, and so forth.
Changing the second parameter to `'DP'` creates a function
space for discontinuous Galerkin methods.

idx{`TestFunction`} idx{`TrialFunction`}
idx{`DirichletBC`}
idx{Dirichlet boundary conditions}

=== Defining the trial and test functions ===

In mathematics, we distinguish between the trial and test spaces $V$
and $\hat{V}$. The only difference in the present problem is the
boundary conditions. In FEniCS we do not specify the boundary
conditions as part of the function space, so it is sufficient to work
with one common space `V` for the and trial and test functions in the
program:

!bc pycod
u = TrialFunction(V)
v = TestFunction(V)
!ec

idx{boundary specification (function)}

=== Defining the boundary and the boundary conditions ===

The next step is to specify the boundary condition: $u=u_0$ on
$\partial\Omega$. This is done by

!bc pycod
bc = DirichletBC(V, u0, u0_boundary)
!ec
where `u0` is an expression defining the solution values on the
boundary, and `u0_boundary` is a function (or object) defining
which points belong to the boundary.

Boundary conditions of the type $u=u_0$ are known as *Dirichlet
conditions*. For the present finite element method for the Poisson
problem, they are also called *essential boundary conditions*, as they
need to be imposed explicitly as part of the trial space (in contrast
to being defined implicitly as part of the variational formulation).
Naturally, the FEniCS class used to define Dirichlet boundary
conditions is named `DirichletBC`.

idx{`Expression`}

The variable `u0` refers to an `Expression` object, which is used to
represent a mathematical function. The typical construction is

!bc pycod
u0 = Expression(formula)
!ec
where `formula` is a string containing the mathematical expression.
This formula is written with C++ syntax. The expression is
automatically turned into an efficient, compiled C++ function.
The expression may depend on the variables `x[0]` and `x[1]`
corresponding to the $x$ and $y$ coordinates. In 3D, the expression
may also depend on the variable `x[2]` corresponding to the $z$
coordinate. With our choice of $u_0(x,y)=1 + x^2 + 2y^2$, the formula
string can be written as `1 + x[0]*x[0] + 2*x[1]*x[1]`:

!bc pycod
u0 = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
!ec

idx{C++ expression syntax}
idx{expression syntax (C++)}

!bnotice String expressions must have valid C++ syntax!
The string argument to an `Expression` object must obey C++ syntax.
Most Python syntax for mathematical expressions are also valid C++ syntax,
but power expressions make an exception: `p**a` must be written as
`pow(p,a)` in C++ (this is also an alternative Python syntax).
The following mathematical functions can be used directly
in C++
expressions when defining `Expression` objects:
`cos`, `sin`, `tan`, `acos`, `asin`,
`atan`, `atan2`, `cosh`, `sinh`, `tanh`, `exp`,
`frexp`, `ldexp`, `log`, `log10`, `modf`,
`pow`, `sqrt`, `ceil`, `fabs`, `floor`, and `fmod`.
Moreover, the number $\pi$ is available as the symbol `pi`.
All the listed functions are taken from the `cmath` C++ header file, and
one may hence
consult the documentation of `cmath` for more information on the
various functions.

If/else tests are possible using the C syntax for inline branching. The
function

!bt
\[ f(x,y) = \left\lbrace\begin{array}{ll} x^2, & x, y\geq 0\\
2, & \hbox{otherwise}\end{array}\right.\]
!et
is implemented as

!bc pycod
f = Expression('x[0] >= 0 && x[1] >= 0? pow(x[0], 2) : 2')
!ec

Parameters in expression strings are allowed, but
must be initialized via keyword
arguments when creating the `Expression` object. For example, the
function $f(x)=e^{-\kappa\pi^2t}\sin(\pi k x)$ can be coded as

!bc pycod
f = Expression('exp(-kappa*pow(pi,2)*t)*sin(pi*k*x[0])',
               kappa=1.0, t=0, k=4)
!ec
At any time, parameters can be updated:

!bc pycod
f.t += dt
f.k = 10
!ec
!enotice

idx{boundary specification (function)}

The function `u0_boundary` specifies which points that belong to the
part of the boundary where the boundary condition should be applied:

!bc pycod
def u0_boundary(x, on_boundary):
    return on_boundary
!ec
A function like `u0_boundary` for marking the boundary must return a
boolean value: `True` if the given point `x` lies on the Dirichlet
boundary and `False` otherwise.  The argument `on_boundary` is `True`
if `x` is on the physical boundary of the mesh, so in the present
case, where we are supposed to return `True` for all points on the
boundary, we can just return the supplied value of `on_boundary`. The
`u0_boundary` function will be called for every discrete point in the
mesh, which allows us to have boundaries where $u$ are known also
inside the domain, if desired.

One way to think about the specification of boundaries in FEniCS is
that FEniCS will ask you (or rather the function `u0_boundary` which
you have implemented) whether or not a specific point `x` is part of
the boundary. FEniCS already knows whether the point belongs to the
*actual* boundary (the mathematical boundary of the domain) and kindly
shares this information with you in the variable `on_boundary`. You
may choose to use this information (as we do here), or ignore it
completely.

The argument `on_boundary` may also be omitted, but in that case we need
to test on the value of the coordinates in `x`:

!bc pycod
def u0_boundary(x):
    return x[0] == 0 or x[1] == 0 or x[0] == 1 or x[1] == 1
!ec
Comparing floating-point values using an exact match test with
`==` is not good programming practice, because small round-off errors
in the computations of the `x` values could make a test `x[0] == 1`
become false even though `x` lies on the boundary.  A better test is
to check for equality with a tolerance. This can be done using the
`near` command in FEniCS:

!bc pycod
def u0_boundary(x):
    return near(x[0], 0) or near(x[1], 0) \
        or near(x[0], 1) or near(x[1], 1)
!ec

idx{UFL}

=== Defining the source term ===

Before defining the bilinear and linear forms $a(u,v)$ and $L(v)$ we
have to specify the source term $f$:

!bc pycod
f = Expression('-6')
!ec
When $f$ is constant over the domain, `f` can be
more efficiently represented as a `Constant`:

!bc pycod
f = Constant(-6)
!ec

=== Defining the variational problem ===

We now have all the ingredients we need to define the
variational problem:

!bc pycod
a = dot(grad(u), grad(v))*dx
L = f*v*dx
!ec
In essence, these two lines specify the PDE to be solved.  Note the
very close correspondence between the Python syntax and the
mathematical formulas $\nabla u\cdot\nabla v \dx$ and $fv \dx$.  This
is a key strength of FEniCS: the formulas in the variational
formulation translate directly to very similar Python code, a feature
that makes it easy to specify and solve complicated PDE problems.  The
language used to express weak forms is called UFL (Unified Form
Language) cite{UFL_2014,FEniCS}and is an integral part of FEniCS.

#Instead of `grad` we could also just have written `grad` in the
#examples in this tutorial. However, when taking gradients of vector
#fields, `grad` and `grad` differ. The latter is consistent with
#the tensor algebra commonly used to derive vector and tensor PDEs,
#where $\nabla$ (``nabla'') acts as a vector operator, and therefore
#this author prefers to always use `grad`.

=== Forming and solving the linear system ===

Having defined the finite element variational problem and boundary
condition, we can now ask FEniCS to compute the solution:

!bc pycod
u = Function(V)
solve(a == L, u, bc)
!ec
#Some prefer to replace `a` and `L` by an `equation`
#variable, which is accomplished by this equivalent code:

#!bc pycod
#equation = dot(grad(u), grad(v))*dx == f*v*dx
#u = Function(V)
#solve(equation, u, bc)
#!ec

Note that we first defined the variable `u` as a `TrialFunction` and
used it to represent the unknown in the form `a`. Thereafter, we
redefined `u` to be a `Function` object representing the solution;
i.e., the computed finite element function $u$. This redefinition of
the variable `u` is possible in Python and often done in FEniCS
applications for linear problem. The two types of objects that `u`
refers to are equal from a mathematical point of view, and hence it is
natural to use the same variable name for both objects.

idx{degrees of freedom}

[AL: I AM HERE]

=== Examining the values of the solution ===

The present test problem should produce a numerical solution that
equals the exact solution to machine precision. That is, there are
no approximation errors in our test problem. We can use this property
to ``prove'' that our implementation is correct, a necessary first step
before we try to apply our code to more complicated problems.
For such verification, we need
to compare the computed `u` function to `u0`.

A finite element function like $u$ is expressed as a linear combination
of basis functions $\phi_j$, spanning the space $V$:

!bt
\begin{equation}
u = \sum_{j=1}^N U_j \phi_j label{tut:poisson1:ufem}\tp
\end{equation}
!et
By writing `solve(a == L, u, bc)` in the program, a linear system
will be formed from $a$ and $L$, and this system is solved for the
$U_1,\ldots,U_N$ values. The $U_1,\ldots,U_N$ values are known
as *degrees of freedom* of $u$. For Lagrange elements (and many other
element types) $U_k$ is simply the value of $u$ at the node
with global number $k$.
The nodes and cell vertices coincide for linear Lagrange elements, while
for higher-order elements there are additional nodes at
the facets and maybe also in the interior of cells.

Having `u` represented as a `Function` object, we can either evaluate
`u(x)` at any point `x` in the mesh (expensive operation!),
or we can grab all the degrees of
freedom values $U_j$ directly by

!bc pycod
u_nodal_values = u.vector()
!ec
The result is a `Vector` object, which is basically an
encapsulation of the vector object used in the linear algebra package
that is used to solve the linear system arising from the
variational problem.
Since we program in Python it is convenient to convert the
`Vector` object to a standard `numpy` array for further
processing:

idx{degrees of freedom array}
idx{nodal values array}
idx{numbering!degrees of freedom}
idx{numbering!cell vertices}

!bc pycod
u_array = u_nodal_values.array()
!ec
With `numpy` arrays we can write MATLAB-like code to analyze
the data. Indexing is done with square brackets: `u_array[i]`,
where the index `i` always starts at `0`. However, `i` corresponds
to $u$ at some point in the mesh and the correspondence requires
knowledge of the numbering of degrees of freedom and the numbering of
vertices in elements in the mesh, see Section ref{tut:poisson1:verify1}
for details.

idx{`interpolate`}

For now, we want to check that the values in `u_array` are correct:
they should equal our `u0` function. The most natural approach is
to interpolate our `u0` expression onto our space
(i.e., the finite element mesh),

!bc pycod
u0_Function = interpolate(u0, V)
!ec
The `interpolate` function returns a `Function` object, whose degrees
of freedom values can be obtained by `.vector().array()`.  Our goal is
to show that the degrees of freedom arrays of `u` and `u0_Function`
are equal. One safe of doing this is to compute the maximum error,

!bc pycod
u0_array = u0_Function.vector().array()  # dof values
max_error = (u0_array - u.vector().array()).max()
print('max error:', max_error)
!ec

!bnotice How to check that the error vanishes?
With inexact arithmetics, as we always have on a computer,
this maximum error is not zero, but should be a small number.
The machine precision is about $10^{-16}$, but in finite element
calculations, rounding errors of this size may accumulate, so
the expected accuracy of `max_error` smaller. Experiments show
that increasing the number of elements and increasing the degree
of the finite element polynomials increase `max_error`.
For a mesh with $2(20\times 20)$ cubic Lagrange elements (degree 3)
`max_error` is about $2\cdot 10^{-12}$, while for 18 linear elements
the maximum error is about $2\cdot 10^{-15}$.
!enotice

=== Plotting the solution ===

The simplest way of quickly looking at `u` is to say

!bc pycod
plot(u, interactive=True)
# or
plot(u)
interactive()
!ec
Clicking on `Help` in the plot windows brings up a list of commands.
For example, typing `m` brings up the mesh.  With the left, middle,
and right mouse buttons you can rotate, translate, and zoom
(respectively) the plotted surface to better examine what the solution
looks like. You must click `Ctrl+q` to kill the plot window and
continue execution beyond the `plot(u, interactive=True)` command or
`interactive()`.  Figure ref{tut:poisson:2D:fig:ex1:u} displays the
resulting $u$ function.

Plotting both the solution and the mesh is accomplished by

!bc pycod
plot(u)
plot(mesh)
# Hold plot
interactive()
!ec
Type `Ctrl+w` to kill all plot windows and continue execution.

It is also possible to dump the computed solution to file, e.g., in the
VTK format:

!bc pycod
file = File('poisson.pvd')
file << u
!ec
The `poisson.pvd` file can now be loaded into any front-end to VTK,
say ParaView or VisIt. The `plot` function is intended for quick
examination of the solution during program development.  More in-depth
visual investigations of finite element solutions will normally
benefit from using highly professional tools such as ParaView and
VisIt.

===== Deflection of a membrane =====
label{ftut:poisson:membrane}

The previous problem and code targeted a simple test problem where we
can easily verify the implementation. Now we turn the attention to
a more physically relevant problem, in a non-trivial geometry, and
that results in solutions of somewhat more exciting shape.

We want to compute the deflection $w$ of a two-dimensional, circular membrane,
subject to a load $p$ over the membrane.
A scaled form of this problem
(see Section ref{tut:poisson:membrane} for mathematical details) has
the governing equation
$-\nabla^2 w = p$ over the unit circle, with $w=0$ on the boundary, and
the load given as

!bt
\[ p = - 4\exp{\left(-\beta^2(x^2 + (y-R_0)^2)\right)},\]
!et
where $\beta$ and $R_0$ are dimensionless numbers reflecting the
extent of the load and its location, respectively. Let us work with
a quite peak-shaped load, for which $\beta=8$ and $R_0=0.6$ are
relevant parameters.

Just a few modifications are necessary in our previous program to solve
this new problem.

=== Generating the mesh ===

A mesh over the unit circle can be created by the `mshr` tool in
FEniCS:

!bc pycod
from mshr import *
domain = Circle(Point(0.0, 0.0), 1.0)
mesh = generate_mesh(domain, n)
!ec
The `Circle` shape from `mshr` takes the center and radius of the circle
as the two first arguments, while `n` is the resolution, here the
suggested number of cells per radius.

=== The expression for the load ===

idx{`Expresion`}
idx{Expression with parameters}

The right-hand side pressure function
is represented by an `Expression` object. There
are two physical parameters in the formula for $f$ that enter the
expression string and these parameters must have their values set
by keyword arguments:

!bc pycod
p = Expression(
    '4*exp(-pow(beta,2)*(pow(x[0], 2) + pow(x[1]-R0, 2)))',
    beta=beta, R0=R0)
!ec
The coordinates in `Expression` objects *must* be a vector
with indices 0, 1, and 2, and with the name `x`. Otherwise
we are free to introduce names of parameters as long as these are
given default values by keyword arguments. All the parameters
initialized by keyword arguments can at any time have their
values modified. For example, we may set

!bc pycod
f.beta = 12
f.R0 = 0.3
!ec

idx{interpolation}

=== Variational form ===

We may introduce `w` instead of `u` as primary unknown and `p` instead
of `f` as right-hand side function:

!bc pycod
w = TrialFunction(V)
v = TestFunction(V)
a = dot(grad(w), grad(v))*dx
L = p*v*dx

w = Function(V)
solve(a == L, w, bc)
!ec

=== Visualization ===

It would be of interest to visualize $p$ along with $w$ so that we can
examine the pressure force and the membrane's response.  We must then transform
the formula (`Expression`) to a finite element function
(`Function`).  The most natural approach is to construct a finite
element function whose degrees of freedom are
calculated from $p$. That is, we interpolate $p$:

!bc pycod
p = interpolate(p, V)
!ec
Calling `plot(p)` will produce a plot of $p$. Note that the assignment
to `p` destroys the previous `Expression` object `p`, so if
it is of interest to still have access to this object, another name must be used
for the `Function` object returned by `interpolate`.

We can now plot `w` and `p` as well as dump the fields to file in VTK format:

!bc pycod
plot(w, title='Deflection')
plot(p, title='Load')

vtkfile = File('membrane.pvd')
vtkfile << w
vtkfile << p
!ec
Figure ref{ftut:poisson:membrane:fig} shows the result of the `plot`
commands.

FIGURE: [fig/membrane_fenics_viz, width=800 frac=1] Load (left) and resulting deflection (right) of a circular membrane. label{ftut:poisson:membrane:fig}


======= The time-dependent diffusion equation =======
label{tut:timedep}

The examples in Section ref{tut:poisson1:impl} illustrate that solving
linear, stationary PDE problems with the aid of FEniCS is easy and
requires little programming.  FEniCS clearly automates the spatial
discretization by the finite element method. One can use a separate,
one-dimensional finite element method in the domain as well, but very
often, it is easier to just use a finite difference method, or to
formulate the problem as an ODE system and leave the time-stepping to
an ODE solver.
#The solution of
#nonlinear problems, as we showed in Section
#ref{tut:poisson:nonlinear}, can also be automated (cf. Section
#ref{tut:nonlinear:Newton:auto}), but many scientists will prefer to
#code the solution strategy of the nonlinear problem themselves and
#experiment with various combinations of strategies in difficult
#problems. Time-dependent problems are somewhat similar in this
#respect: we have to add a time discretization scheme, which is often
#quite simple, making it natural to explicitly code the details of the
#scheme so that the programmer has full control.
#We shall explain how
#easily this is accomplished through examples.

[hpl: Should exemplify all three approaches? With emphasis on
simple finite differences?]

===== Variational formulation =====
label{tut:timedep:diffusion1}
idx{time-dependent PDEs}

Our time-dependent model problem for teaching purposes is naturally
the simplest extension of the Poisson problem into the time domain,
i.e., the diffusion problem

!bt
\begin{align}
{\partial u\over\partial t} &= \nabla^2 u + f\hbox{ in }\Omega,
label{tut:diffusion:pde1}\\
u &= u_0\hbox{ on } \partial \Omega,
label{tut:diffusion:pde1:bc}\\
u &= I \mbox{ at } t=0\tp
label{tut:diffusion:pde1:ic}
\end{align}
!et
Here, $u$ varies with space and time, e.g., $u=u(x,y,t)$ if the spatial
domain $\Omega$ is two-dimensional. The source function $f$ and the
boundary values $u_0$ may also vary with space and time.
The initial condition $I$ is a function of space only.

A straightforward approach to solving time-dependent PDEs by the
finite element method is to first discretize the time derivative by a
finite difference approximation, which yields a recursive set of
stationary problems, and then turn each stationary problem into a
variational formulation.

Let superscript $k$ denote a quantity at time $t_k$, where $k$ is an
integer counting time levels. For example, $u^k$ means $u$ at time
level $k$.  A finite difference discretization in time first consists
in sampling the PDE at some time level, say $k$:

!bt
\begin{equation} {\partial \over\partial t}u^k = \nabla^2 u^k + f^k\tp
label{tut:diffusion:pde1:tk}
\end{equation}
!et
The time-derivative can be approximated by a finite difference.
For simplicity and stability reasons we choose a
simple backward difference:

!bt
\begin{equation} {\partial \over\partial t}u^k\approx {u^k - u^{k-1}\over{\dt}},
label{tut:diffusion:BE}
\end{equation}
!et
where $\dt$ is the time discretization parameter.
Inserting (ref{tut:diffusion:BE}) in (ref{tut:diffusion:pde1:tk}) yields

!bt
\begin{equation}
{u^k - u^{k-1}\over{\dt}} = \nabla^2 u^k + f^k\tp
label{tut:diffusion:pde1:BE}
\end{equation}
!et
This is our time-discrete version of the diffusion PDE
(ref{tut:diffusion:pde1}).

We may reorder (ref{tut:diffusion:pde1:BE}) so
that the left-hand side contains the terms with the unknown $u^k$ and
the right-hand side contains computed terms only. The result
is a recursive set of spatial
(stationary) problems for $u^k$ (assuming $u^{k-1}$ is known from
computations at the previous time level):

!bt
\begin{align}
u^0 &= I, label{tut:diffusion:pde1:u0}\\
u^k - {\dt}\nabla^2 u^k &=  u^{k-1} + {\dt} f^k,\quad k=1,2,\ldots
label{tut:diffusion:pde1:uk}
\end{align}
!et
Given $I$, we can solve for $u^0$, $u^1$, $u^2$, and so on.

As an alternative to (ref{tut:diffusion:pde1:uk}), which can be
convenient in implementations, we may collect
all terms on one side of the equality sign:

!bt
\begin{equation}
u^k - {\dt}\nabla^2 u^k -  u^{k-1} - {\dt} f^k = ,\quad k=1,2,\ldots
label{tut:diffusion:pde1:uk2}
\end{equation}
!et

We use a finite element method to solve
(ref{tut:diffusion:pde1:u0}) and either of the equations
(ref{tut:diffusion:pde1:uk}) or (ref{tut:diffusion:pde1:uk2}).  This
requires turning the equations into weak forms.  As usual, we multiply
by a test function $v\in \hat V$ and integrate second-derivatives by
parts. Introducing the symbol $u$ for $u^k$ (which is natural in the
program), the resulting weak form can be conveniently written in
the standard notation:

!bt
\[ a_0(u,v)=L_0(v),\]
!et
for
(ref{tut:diffusion:pde1:u0}). The formulation (ref{tut:diffusion:pde1:uk})
gives rise to

!bt
\[ a(u,v)=L(v),\]
!et
where

!bt
\begin{align}
a_0(u,v) &= \int_\Omega uv \dx, label{tut:diffusion:pde1:a0}\\
L_0(v) &= \int_\Omega Iv \dx, label{tut:diffusion:pde1:L0}\\
a(u,v) &= \int_\Omega\left( uv + {\dt}
\nabla u\cdot \nabla v\right) \dx, label{tut:diffusion:pde1:a}\\
L(v) &= \int_\Omega \left(u^{k-1} + {\dt}  f^k\right)v \dx\tp
label{tut:diffusion:pde1:L}
\end{align}
!et
The alternative formulation (ref{tut:diffusion:pde1:uk2})
has a formulation

!bt
\[ F(u,v) = 0,\]
!et
where

!bt
\begin{equation}
F = \int_\Omega\left( uv + {\dt}
\nabla u\cdot \nabla v -
\left(u^{k-1} - {\dt}  f^k\right)v\right) \dx\tp
label{tut:diffusion:pde1:F}
\end{equation}
!et

The continuous variational problem is to find
$u^0\in V$ such that $a_0(u^0,v)=L_0(v)$ holds for all $v\in\hat V$,
and then find $u^k\in V$
such that $a(u^k,v)=L(v)$ for all $v\in\hat V$,
or alternatively, $F(u^k,v)=0$ for all $v\in\hat V$,
$k=1,2,\ldots$.

Approximate solutions in space are found by restricting the functional
spaces $V$ and $\hat V$ to finite-dimensional spaces, exactly as we
have done in the Poisson problems.  We shall use the symbol $u$ for
the finite element approximation at time $t_k$. In case we need to
distinguish this space-time discrete approximation from the exact
solution of the continuous diffusion problem, we use $\uex$ for the
latter.  By $u^{k-1}$ we mean the finite element approximation of the
solution at time $t_{k-1}$.

Instead of
solving (ref{tut:diffusion:pde1:u0}) by a finite element method, i.e.,
projecting $I$ onto $V$ via the problem $a_0(u,v)=L_0(v)$, we could
simply interpolate $u^0$ from $I$. That is, if $u^0=\sum_{j=1}^N
U^0_j\phi_j$, we simply set $U_j=I(x_j,y_j)$, where $(x_j,y_j)$ are
the coordinates of node number $j$. We refer to these two strategies
as computing the initial condition by either projecting $I$ or
interpolating $I$.  Both operations are easy to compute through one
statement, using either the `project` or `interpolate` function.

===== A simple implementation =====
label{tut:timedep:diffusion1:impl}

Our program needs to implement the time stepping explicitly, but can
rely on FEniCS to easily compute $a_0$, $L_0$, $F$, $a$, and $L$, and solve
the linear systems for the unknowns.

=== Test problem ===

Before starting the coding, we shall construct a problem where it is
easy to determine if the calculations are correct. The simple backward
time difference is exact for linear functions, so we decide to have
a linear variation in time. Combining a second-degree polynomial in space
with a linear term in time,

!bt
\begin{equation} u = 1 + x^2 + \alpha y^2 + \beta t,
label{tut:diffusion:pde1:u0test}
\end{equation}
!et
yields a function whose computed values at the nodes will be exact,
regardless of the size of the elements and $\dt$, as long as the mesh
is uniformly partitioned.  By inserting
(ref{tut:diffusion:pde1:u0test}) in the PDE problem
(ref{tut:diffusion:pde1}), it follows that $u_0$ must be given as
(ref{tut:diffusion:pde1:u0test}) and that $f(x,y,t)=\beta - 2 -
2\alpha$ and $I(x,y)=1+x^2+\alpha y^2$.

idx{`${prog["d2D_flat1"]}.py`}

=== The code ===

A new programming issue is how to deal with functions that vary in
space *and time*, such as the boundary condition $u_0$ given by
(ref{tut:diffusion:pde1:u0test}).  A natural solution is to apply an
`Expression` object with time $t$ as a parameter, in addition to the
parameters $\alpha$ and $\beta$
for `Expression` objects with parameters):

!bc pycod
alpha = 3; beta = 1.2
u0 = Expression('1 + x[0]*x[0] + alpha*x[1]*x[1] + beta*t',
                {'alpha': alpha, 'beta': beta})
u0.t = 0
!ec
This function expression has the components of `x` as independent
variables, while `alpha`, `beta`, and `t` are parameters.  The
parameters can either be set through a dictionary at construction
time, as demonstrated for `alpha` and `beta`, or anytime through
attributes in the function object, as shown for the `t` parameter.

The essential boundary conditions, along the whole boundary in this case,
are set in the usual way,

!bc pycod
def boundary(x, on_boundary):  # define the Dirichlet boundary
    return on_boundary

bc = DirichletBC(V, u0, boundary)
!ec

We shall use `u` for the unknown $u$ at the new time level and `u_1`
for $u$ at the previous time level.  The initial value of `u_1`,
implied by the initial condition on $u$, can be computed by either
projecting or interpolating $I$.  The $I(x,y)$ function is available
in the program through `u0`, as long as `u0.t` is zero.  We can then
do

!bc pycod
u_1 = interpolate(u0, V)
# or
u_1 = project(u0, V)
!ec
Note that we could, as an equivalent alternative to using `project`,
define $a_0$ and $L_0$ as we did in Section ref{tut:poisson:gradu} and
form the associated variational problem.

!bwarning Projecting versus interpolating the initial condition
To actually recover the
exact solution (ref{tut:diffusion:pde1:u0test}) to machine precision,
it is important not to compute the discrete initial condition by
projecting $I$, but by interpolating $I$ so that the nodal values are
exact at $t=0$ (projection results in approximative values at the
nodes).
!ewarning

We may either define $a$ or $L$ according to the formulas above, or
we may just define $F$ and ask FEniCS to figure out which terms that
go into the bilinear form $a$ and which that go into the linear form
$L$. The latter is convenient, especially in more complicated problems,
so we illustrate that construction:

!bc pycod
dt = 0.3      # time step

u = TrialFunction(V)
v = TestFunction(V)
f = Constant(beta - 2 - 2*alpha)

F = u*v*dx + dt*dot(grad(u), grad(v))*dx - (u_1 + dt*f)*v*dx
a, L = lhs(F), rhs(F)
!ec

Finally, we perform the time stepping in a loop:

!bc pycod
u = Function(V)   # the unknown at a new time level
T = 2             # total simulation time
t = dt

while t <= T:
    u0.t = t
    solve(a == L, u, bc)

    t += dt
    u_1.assign(u)
!ec

!bwarning Remember to update expression objects with the current time!
Inside the time loop,
observe that `u0.t` must be updated before the `solve` statement
to enforce computation of Dirichlet conditions at the
current time level. (The Dirichlet conditions look up the `u0` object
for values.)
!ewarning

The time loop above does not contain any comparison of the numerical
and the exact solution, which we must include in order to verify the
implementation.  As in many previous examples, we compute the
difference between the array of nodal values of `u` and the array of
the interpolated exact solution.  The following code is to be included
inside the loop, after `u` is found:

!bc pycod
u_e = interpolate(u0, V)
max_error = np.abs(u_e.vector().array() -
                   u.vector().array()).max()
print('max error, t=%.2f: %-10.3g' % (t, max_error))
!ec

The complete program code for this time-dependent case goes as follows:

@@@CODE src/d2D_flat1.py fromto: from fenics import@
The code is available in the
file "`${prog['d2D_flat1']}.py`": "${src_url}/d2D_flat1.py".


===== Diffusion of a Gaussian function =====

Add dumping to file and some plots.

======= A nonlinear Poisson equation =======


===== Variational formulation =====

Now we shall address how to solve nonlinear PDEs in FEniCS. Our
sample PDE for implementation is taken as a nonlinear Poisson equation:

!bt
\begin{equation}
-\nabla\cdot\left( q(u)\nabla u\right) = f,
\end{equation}
!et
in $\Omega$, with $u=u_0$ on the boundary $\partial\Omega$.
The coefficient $q(u)$ makes the equation nonlinear (unless $q(u)$
is constant in $u$).

The variational formulation of our model problem reads:
Find $u \in V$ such that

!bt
\begin{equation} label{tut:poisson:nonlinear1}
  F(u; v) = 0 \quad \forall v \in \hat{V},
\end{equation}
!et
where

!bt
\begin{equation}
label{tut:poisson:nonlinear2}
F(u; v) = \int_\Omega q(u)\nabla u\cdot \nabla v \dx,
\end{equation}
!et
and

!bt
\begin{align*}
    \hat{V} &= \{v \in H^1(\Omega) : v = 0 \mbox{ on } x_0=0\mbox{ and }x_0=1\}, \\
     V      &= \{v \in H^1(\Omega) : v = 0 \mbox{ on } x_0=0\mbox{ and } v = 1\mbox{ on }x_0=1\}\tp
\end{align*}
!et

The discrete problem arises as usual by restricting $V$ and $\hat V$ to a
pair of discrete spaces. As usual, we omit any subscript on discrete
spaces and simply say $V$ and $\hat V$ are chosen finite dimensional
according to some mesh with some element type.
Similarly, we let $u$ be the discrete solution and use $\uex$ for
the exact solution if it becomes necessary to distinguish between the two.

The discrete nonlinear problem is then written as: find $u\in V$ such that

!bt
\begin{equation}
  F(u; v) = 0 \quad \forall v \in \hat{V},
label{tut:poisson:nonlinear:d}
\end{equation}
!et
with $u = \sum_{j=1}^N U_j \phi_j$. Since $F$ is a nonlinear function
of $u$, the variational statement gives rise to a system of
nonlinear algebraic equations in the unknowns $U_1,\ldots,U_N$.


===== A simple implementation =====
label{tut:nonlinear:Newton:auto}

=== Overview ===

A working solver for the nonlinear Poisson equation is as easy to
implement as a solver for the corresponding linear problem.
All we need to do is the state the formula for $F$ and call
`solve(F == 0, u, bc)` instead of `solve(a == L, u, bc)` as we did
in the linear case. Here is a minimalistic code:

!bc pycod
from fenics import *

def q(u):
    """Nonlinear coefficient in the PDE."""
    return 1 + u**2

mesh = UnitSquareMesh(60, 40)
V = FunctionSpace(mesh, 'Lagrange', 1)
u0 = Expression(...)

def u0_boundary(x, on_boundary):
    return on_boundary

bc = DirichletBC(V, u0, u0_boundary)

# Define variational problem
u = Function(V)
v = TestFunction(V)
f = Expression(f_code)
F = dot(q(u)*grad(u), grad(v))*dx - f*v*dx

# Compute solution
solve(F == 0, u, bc)
!ec
The major difference from a linear problem is that the unknown function
`u` in the variational form is in the nonlinear case
a `Function`, not a `TrialFunction`.

The `solve` function takes the nonlinear equations and derives symbolically
the Jacobian matrix and runs a Newton method.

=== Constructing a test problem with SymPy ===

Let us do a specific computation. We then need choices for $f$ and $u_0$.
Previously, we have worked with manufactured solutions that can be
reproduced without approximation errors. This is more difficult in
nonlinear problems, and the algebra is more tedious. However, we may
utilize SymPy for symbolic computing and integrate such computations in the
FEniCS solver. This allows us to easily experiment with different
manufactured solutions. The forthcoming code with SymPy requires some
basic familiarity with this package (here, defining symbols, `diff` for
differentiation, `ccode` for C/C++ code generation).

We try out a two-dimensional
solution that is linear in the unknowns:

@@@CODE src/p2D_flat_nonlinear.py fromto: from fenics import *@u_code =

!bnotice Define symbolic coordinates as required in `Expression` objects
Note that we would normally write `x, y = sym.symbols('x y')`, but
if we want the resulting expressions to be have valid syntax for
`Expression` objects, and then $x$ reads `x[0]` and $y$ must be `x[1]`.
This is easily accomplished with `sympy` by defining the names of `x` and
`y` as `x[0]` and `x[1]`: `x, y = sym.symbols('x[0] x[1]')`.
!enotice

Turning the expressions for `u` and `f` into C or C++ syntax for
`Expression` objects needs two steps. First we ask for the C code of
the expressions,

!bc pycod
u_code = sym.printing.ccode(u)
f_code = sym.printing.ccode(f)
!ec
Sometimes we need some editing of the result to match the required syntax of
`Expression` objects, but not in this case. (The primary example is
that `M_PI` for $\pi$ in C/C++ must be replaced by `pi` for `Expression`
objects.) In our case here,
the output of `c_code` and `f_code` is

!bc ccod
x[0] + 2*x[1] + 1
-10*x[0] - 20*x[1] - 10
!ec
After having defined the mesh, the function space, and the boundary,
we define the boundary values, `u0`, as

!bc pycod
u0 = Expression(u_code)
!ec
Similarly, we define the right-hand side function as

!bc pycod
f = Expression(f_code)
!ec
The complete code is found in the file
`${prog["p2D_flat_nonlinear"]}.py`.

!bwarning Name clash between `fenics` and program variables
In a program like the one above, strange errors may occur due to
name clashes. If you define `sym`, `q`, and `f` prior to doing
`from fenics import *`, the latter statement will also import
variables with the names `sym`, `q`, and `f` and overwrite
the objects you had! This may lead to strange errors. The best
solution is to do `import fenics as fe` and prefix all FEniCS
object names by `fe`. The next best solution is to do the
`from fenics import *` first and then define our own variables
that overwrite those imported from `fenics`. This is acceptable
if we do not need `f`, `q`, and `sym` from `fenics`.
!ewarning

Running the code gives output that tells how the Newton iteration
progresses. With $2(6\times 4)$ cells we get convergence in 7
iterations with a tolerance of $10^{-9}$, and the error in the
numerical solution is about $10^{-11}$. Using more elements, e.g.,
$2(16\times 14)$, brings the error down to about $10^{-15}$,
which provides evidence for a correct implementation.

The current example shows how easy it is to solve a nonlinear problem
in FEniCS. However, experts on numerical solution of nonlinear PDEs
know very well that automated procedures may fail in nonlinear
problems, and that it is often necessary to have much more manual
control of the solution process than what we have in the current
case. Therefore, we return to this problem in Chapter
ref{tut:nonlinear} and show how we can implement our own solution
algorithms for nonlinear equations and also how we can steer the
parameters in the automated Newton method used above. You will then
realize how easy it is to implement tailored solution strategies for
nonlinear problems in FEniCS.


======= The equations of linear elasticity =======
label{tut:elast}

===== Variational formulation =====
label{tut:elast:varform}

Work with simple constant $\lambda$ and $\mu$ formulation, stationary,
with homogeneous Dirichlet or Neumann conditions, but include body force.
Case: Deflection of
a cantilever beam (could be lego box for the fun of it :-)
Then $x=0$ end is clamped with $u=0$ and the rest of the boundary can
be traction free (homogeneous Neumann condition).
Let gravity deform the shape.

The equations governing small elastic deformations of a body $\Omega$
are

!bt
\begin{align}
\nabla\cdot\sigma &= \varrho f\hbox{ in }\Omega,
label{tut:elast:varform:equilibrium}\\
\sigma &= \lambda\,\hbox{tr}\,\varepsilon I + 2\mu\varepsilon,
label{tut:elast:varform:stresstrain}\\
\varepsilon &= \frac{1}{2}\left(\nabla u + (nabla u)^T\right),
label{tut:elast:varform:strainu}
\end{align}
!et
where $u$ is the displacement vector field, $\sigma$ is the stress
tensor, $I$ is the identity tensor, $\varepsilon$ is the strain tensor,
and $\lambda$ and $\mu$ are Lame's elasticity coefficients for the material
in $\Omega$.
We shall combine (ref{tut:elast:varform:stresstrain}) and
(ref{tut:elast:varform:strainu}) to

!bt
\begin{equation}
\sigma = \lambda\nabla\cdot u I + \mu(\nabla u + (\nabla u)^T)\tp
label{tut:elast:varform:stressu}
\end{equation}
!et
Note that (ref{tut:elast:varform:equilibrium})-(ref{tut:elast:varform:strainu})
can easily be transformed to a vector PDE for $u$, which is the governing
PDE for the unknown $u$. In the derivation of the variational formulation,
however, the splitting of the equations as done above is convenient.

The variational formulation of
(ref{tut:elast:varform:equilibrium})-(ref{tut:elast:varform:strainu})
consists of forming the inner product of (ref{tut:elast:varform:equilibrium})
and a *vector* test function $v\in \hat{V}$, where $\hat{V}$
is a test vector function space,
and integrating over the domain $\Omega$:

!bt
\[ \int_\Omega (\nabla\cdot\sigma) \cdot v \dx =
\int_\Omega \varrho f\cdot v\dx\tp\]
!et
Since $\nabla\cdot\sigma$ contains second-order derivatives of the primary
unknown $u$, we integrate this term by parts:

!bt
\[ \int_\Omega (\nabla\cdot\sigma) \cdot \nabla v \dx
-\int_\Omega \sigma : \nabla v\dx + \int_{\partial\Omega} v\cdot sigma\cdot n \ds,\]
!et
where the colon operator is the inner product between tensors, and $n$
is the outward unit normal at the boundary. The quantity $\sigma\cdot n$
is known as the *traction* or stress vector at the boundary, and is often
prescribed as a boundary condition. We assume that it is prescribed
at a part $\partial\Omega_T$ of the boundary and set $T = \sigma\cdot n$.
We then have

!bt
\[
\int_\Omega (\sigma : \nabla v + \varrho f\cdot v) = \int_{\partial\Omega_T}
v\cdot T\ds\tp\]
!et
Inserting (ref{tut:elast:varform:stressu}) for $\sigma$ gives the
variational form with $u$ as unknown.

We can then summarize the variational formulation as find $u\in V$ such that

!bt
\begin{equation}
a(u,v) = L(v)\quad\forall v\in\hat{V},
\end{equation}
!et
where

!bt
\begin{align}
a(u,v) &= \int_\Omega\sigma :\nabla v \dx,\\
\sigma &= \lambda\nabla\cdot u I + \mu(\nabla u + (\nabla u)^T),\\
L(v) &= -\int_\Omega \varrho f\cdot v\dx + \int_{\partial\Omega_T}
v\cdot T\ds\tp\\
\end{align}
!et

One can show that the inner product of a symmetric tensor $A$ and a non-symmetric
tensor $B$ vanishes. If we express $\nabla v$ as a sum of its symmetric
and non-symmetric parts, only the symmetric part will survive in
the product $\sigma :\nabla v$ since $\sigma$ is a symmetric tensor. This
gives rise to the slightly different variational form

!bt
\begin{equation}
a(u,v) = \int_\Omega\sigma :\varepsilon(v) \dx,
\end{equation}
!et
and $\varepsilon(v)$ is the symmetric part of $v$:

!bt
\[ \varepsilon(v) = \frac{1}{2}(\nabla v + (\nabla v)^T)\tp\]
!et


===== A simple implementation =====

As test example, we may look at a cantilever beam deformed under its own weight.
Then $f=(0,0,-g)$ is the body force with $g$ as the acceleration
of gravity. If the beam is box-shaped, we set $u=(0,0,0)$ at the clamped end,
$x=0$. The rest of the boundaries are traction free.

======= The equations of hyperelasticity? =======

===== Variational formulation =====

===== A simple implementation =====

======= The Navier--Stokes equations =======

===== Variational formulation =====

===== A simple implementation =====
