

!split
======= Mathematical problem formulation =======

===== The Poisson equation =====
label{tut:poisson1:bvp}
idx{Poisson's equation}

Let us start with a ``Hello, World!'' program in the world of PDEs - it
must be a program that solves the Laplace or Poisson equation.
Our first example regards the following Poisson problem,

!bt
\begin{align}
- \nabla^2 u(\x) &= f(\x),\quad \x\mbox{ in } \Omega,
label{tut:poisson1}\\
u(\x) &= u_0(\x),\quad \x\mbox{ on } \partial \Omega\tp label{tut:poisson1:bc}
\end{align}
!et
Here, $u(\x)$ is the unknown function, $f(\x)$ is a
prescribed function, $\nabla^2$ is the Laplace operator (also
often written as $\Delta$), $\Omega$ is the spatial domain, and
$\partial\Omega$ is the boundary of $\Omega$. A stationary PDE like
this, together with a complete set of boundary conditions, constitute
a *boundary-value problem*, which must be precisely stated before
it makes sense to start solving it with FEniCS.

In two space dimensions with coordinates $x$ and $y$, we can write out
the Poisson equation as

!bt
\begin{equation}
- {\partial^2 u\over\partial x^2} -
{\partial^2 u\over\partial y^2} = f(x,y)\tp
\end{equation}
!et
The unknown $u$ is now a function of two variables, $u(x,y)$, defined
over a two-dimensional domain $\Omega$.

The Poisson equation arises in numerous physical contexts, including
heat conduction, electrostatics, diffusion of substances, twisting of
elastic rods, inviscid fluid flow, and water waves. Moreover, the
equation appears in numerical splitting strategies of more complicated
systems of PDEs, in particular the Navier-Stokes equations.


Solving a physical problem with FEniCS consists of the following steps:

  o Identify the PDE and its boundary conditions.
  o Reformulate the PDE problem as a variational problem.
  o Make a Python program where the formulas in the variational
    problem are coded, along with definitions of input data such as
    $f$, $u_0$, and a mesh for the spatial domain $\Omega$.
  o Add statements in the program for solving the variational
    problem, computing derived quantities such as $\nabla u$, and
    visualizing the results.

We shall now go through steps 2-4 in detail.  The key feature of
FEniCS is that steps 3 and 4 result in fairly short code, while most
other software frameworks for PDEs require much more code and more
technically difficult programming.


===== Variational formulation =====
label{tut:poisson1:varform}
idx{variational formulation}

FEniCS makes it easy to solve PDEs if finite elements are used for
discretization in space and the problem is expressed as a *variational
problem*. Readers who are not familiar with variational problems will
get a brief introduction to the topic in this tutorial, but getting
and reading a proper book on the finite element method in addition is
encouraged.  Section ref{tut:appendix:books} contains a list of some
suitable books.


idx{test function}
idx{trial function}

The core of the recipe for turning a PDE into a variational problem is
to multiply the PDE by a function $v$, integrate the resulting
equation over $\Omega$, and perform integration by parts of terms with
second-order derivatives. The function $v$ which multiplies the PDE is
in the mathematical finite element literature called a *test
function*. The unknown function $u$ to be approximated is referred to
as a *trial function*. The terms test and trial function are used in
FEniCS programs too.  Suitable function spaces must be specified for
the test and trial functions.  For standard PDEs arising in physics
and mechanics such spaces are well known.

In the present case, we first multiply the Poisson equation
by the test function $v$ and integrate,

!bt
\begin{equation}
label{tut:poisson1:multbyv}
 -\int_\Omega (\nabla^2 u)v \dx = \int_\Omega fv \dx\tp \end{equation}
!et
Then we apply integration by parts to the integrand with
second-order derivatives,

!bt
\begin{equation}
label{tut:poisson1:eqbyparts}
 -\int_\Omega (\nabla^2 u)v \dx
= \int_\Omega\nabla u\cdot\nabla v \dx - \int_{\partial\Omega}{\partial u\over
\partial n}v \ds ,
\end{equation}
!et
where $\frac{\partial u}{\partial n}$ is the derivative of $u$ in the
outward normal direction at the boundary.  The test function $v$ is
required to vanish on the parts of the boundary where $u$ is known,
which in the present problem implies that $v=0$ on the whole boundary
$\partial\Omega$.  The second term on the right-hand side of
(ref{tut:poisson1:eqbyparts}) therefore vanishes.  From
(ref{tut:poisson1:multbyv}) and (ref{tut:poisson1:eqbyparts}) it
follows that

!bt
\begin{equation}
\int_\Omega\nabla u\cdot\nabla v \dx = \int_\Omega fv \dx\tp
label{tut:poisson1:weak1}
\end{equation}
!et
This equation is supposed to hold for all $v$ in some function space
$\hat V$. The trial function $u$ lies in some (possibly different)
function space $V$.  We refer to (ref{tut:poisson1:weak1}) as the
*weak form* or *variational form* of the original boundary-value
problem (ref{tut:poisson1})-(ref{tut:poisson1:bc}).

The proper statement of
our variational problem now goes as follows:
Find $u \in V$ such that

!bt
\begin{equation} label{tut:poisson1:var}
  \int_{\Omega} \nabla u \cdot \nabla v \dx =
  \int_{\Omega} fv \dx
  \quad \forall v \in \hat{V}.
\end{equation}
!et
The test and trial spaces $\hat{V}$ and $V$ are in the present
problem defined as

!bt
\begin{align*}
    \hat{V} &= \{v \in H^1(\Omega) : v = 0 \mbox{ on } \partial\Omega\}, \\
     V      &= \{v \in H^1(\Omega) : v = u_0 \mbox{ on } \partial\Omega\}\tp
\end{align*}
!et
In short,
$H^1(\Omega)$ is the mathematically well-known Sobolev space containing
functions $v$ such that $v^2$ and $||\nabla v||^2$ have finite integrals over
$\Omega$. The solution of the underlying
PDE
must lie in a function space where also the derivatives are continuous,
but the Sobolev space $H^1(\Omega)$ allows functions with discontinuous
derivatives.
This weaker continuity requirement of $u$ in the variational
statement (ref{tut:poisson1:var}),
caused by the integration by parts, has
great practical consequences when it comes to constructing
finite elements.

To solve the Poisson equation numerically, we need to transform the
continuous variational problem
(ref{tut:poisson1:var})
to a discrete variational
problem. This is done by introducing *finite-dimensional* test and
trial spaces, often denoted as
$\hat{V}_h\subset\hat{V}$ and $V_h\subset{V}$. The
discrete variational problem reads:
Find $u_h \in V_h \subset V$ such that

!bt
\begin{equation} label{tut:poisson1:vard}
  \int_{\Omega} \nabla u_h \cdot \nabla v \dx =
  \int_{\Omega} fv \dx
  \quad \forall v \in \hat{V}_h \subset \hat{V}\tp
\end{equation}
!et
The choice of $\hat{V}_h$ and $V_h$ follows directly from the
kind of finite elements we want to apply in our problem. For example,
choosing the well-known linear triangular element with three nodes
implies that
$\hat V_h$ and $V_h$ are the spaces of all piecewise linear functions
over a mesh of triangles,
where the functions in $\hat V_h$
are zero on the boundary
and those in $V_h$ equal $u_0$ on the boundary.

!bwarning What we mean by the notation $u$ and $V$
The mathematics literature on variational problems writes $u_h$ for
the solution of the discrete problem and $u$ for the solution of the
continuous problem. To obtain (almost) a one-to-one relationship
between the mathematical formulation of a problem and the
corresponding FEniCS program, we shall use $u$ for the solution of
the discrete problem and $\uex$ for the exact solution of the
continuous problem, *if* we need to explicitly distinguish
between the two.

In most cases, we will introduce the PDE problem with
$u$ as unknown, derive a variational equation $a(u,v)=L(v)$ with $u\in
V$ and $v\in \hat V$, and then simply discretize the problem by saying
that we choose finite-dimensional spaces for $V$ and $\hat V$, without
adding any subscript to $V$ or $\hat V$. This
restriction of $V$ simply implies that $u$ becomes a discrete finite element
function.  In practice, this means that we turn our PDE problem into a
continuous variational problem, create a mesh and specify an element
type, and then let $V$ correspond to this mesh and element choice.
Depending upon whether $V$ is infinite- or finite-dimensional, $u$
will be the exact or approximate solution.
!ewarning

It turns out to be convenient to
introduce the following unified notation for linear weak forms:

!bt
\begin{equation}
a(u, v) = L(v)\tp
\end{equation}
!et
In the present problem we have that

!bt
\begin{align}
a(u, v) &= \int_{\Omega} \nabla u \cdot \nabla v \dx,
label{tut:poisson1:vard:a}\\
L(v) &= \int_{\Omega} fv \dx\tp  label{tut:poisson1:vard:L}
\end{align}
!et
From the mathematics literature,
$a(u,v)$ is known as a *bilinear form* and $L(v)$ as a
*linear form*.
We shall in every linear problem we solve identify the terms with the
unknown $u$ and collect them in $a(u,v)$, and similarly collect
all terms with only known functions in $L(v)$. The formulas for $a$ and
$L$ are then coded directly in the program.

To summarize, before making a FEniCS program for solving a PDE,
we must first perform two steps:

  * Turn the PDE problem into a discrete
    variational problem: find $u\in V$
    such that $a(u,v) = L(v)\quad\forall v\in \hat{V}$.
  * Specify the choice of spaces ($V$ and $\hat V$), which means
    specifying the mesh and type of finite elements.


# Suggested: var coeff as early as possible!
# A basic Poisson solver
# Useful extensions/Useful stuff/: var coeff here
# Visualization: membrane, vtk, paraview, structured mesh
# Postprocessing computations: var coeff, functionals, conv rates
# Multiple domains and boundaries

!split
======= A basic Poisson solver =======
label{tut:poisson1:impl}

The test problem so far has a general domain $\Omega$ and general functions
$u_0$ and $f$. For our first implementation we must decide on specific
choices of $\Omega$, $u_0$, and $f$.
It will be wise to construct a specific problem where we can easily
check that the computed solution is correct. Let us start with
specifying an exact solution $\uex(x,y)$:

!bt
\begin{equation}
\label{tut:poisson1:impl:uex}
\uex(x,y) = 1 +x^2 + 2y^2
\end{equation}
!et
on some 2D domain.  By inserting (ref{tut:poisson1:impl:uex}) in
our Poisson problem, we find that $\uex(x,y)$ is a solution if

!bt
\[ f(x,y) = -6,\quad u_0(x,y)=\uex(x,y)=1 + x^2 + 2y^2,\]
!et
regardless of the shape of the domain. We choose here, for simplicity,
the domain to be the unit square,

!bt
\[ \Omega = [0,1]\times [0,1] .\]
!et
The reason for specifying the solution (ref{tut:poisson1:impl:uex})
is that the finite element method, with a rectangular domain uniformly
partitioned into linear triangular elements, will exactly reproduce a
second-order polynomial at the vertices of the cells, regardless of
the size of the elements. This property allows us to verify the
implementation by comparing the computed solution ($u$) with the exact
solution ($\uex$). These quantities should be equal
to machine precision *at the nodes*.
Test problems with this property will be frequently constructed
throughout this tutorial.

===== A simple code =====
label{tut:poisson1:impl:code}

A FEniCS program for solving the Poisson equation in 2D with the given
choices of $u_0$, $f$, and $\Omega$ may look as follows:

@@@CODE ../../src/poisson/${prog['p2D_plain']}.py fromto: from dolfin import@

The complete code can be found in the file "`${prog['p2D_plain']}.py`":
"${src_url}/poisson/${prog['p2D_plain']}.py" in the
directory "`src/poisson`": "${src_url}/poisson".

===== Running the program =====
label{tut:poisson1:impl:run}

To run the program `${prog["p2D_plain"]}.py`, open a terminal window, move to
the directory containing the program and write

!bc sys
Terminal> python ${prog['p2D_plain']}.py
!ec
A plot window pops up showing how the solution $u$ looks like as a surface.
With the left mouse button you can tilt the figure. Click `m` to bring
up the underlying mesh. Click `p` to save to a PNG file `dolfin_plot_0.png`
and `P` to save to a PDF file `dolfin_plot_1.pdf`. To kill the
plot window and terminate the application, click `Ctrl+q` (hold down
the `Ctrl` key and press `q`).
Figure ref{tut:poisson:2D:fig:ex1:u} displays the surface and the mesh below.
Since $u$ is a simple quadratic function,
constructed for testing our solver, the
surface looks quite boring.

FIGURE:[fig/ex1_u, width=600 frac=0.8] Plot of the solution in the first FEniCS example. label{tut:poisson:2D:fig:ex1:u}


===== Dissection of the program =====
label{tut:poisson1:impl:dissect}

We shall now dissect this FEniCS program in detail. The program is
written in the Python programming language.  You may either take a
quick look at the "official Python tutorial":
"http://docs.python.org/tutorial/" to pick up the basics of Python if
you are unfamiliar with the language, or you may learn enough Python
as you go along with the examples in the present tutorial. The latter
strategy has proven to work for many newcomers to FEniCS. (The
requirement of using Python and an abstract mathematical formulation
of the finite element problem may seem difficult for those who are
unfamiliar with these topics.  However, the amount of mathematics and
Python that is really demanded to get you productive with FEniCS is
quite limited.  And Python is an easy-to-learn language that you
certainly will love and use far beyond FEniCS programming.)  Section
ref{tut:appendix:pybooks} lists some relevant Python books.

The listed FEniCS program defines a finite element mesh, the discrete
function spaces $V$ and $\hat{V}$ corresponding to this mesh and the
element type, boundary conditions for $u$ (the function $u_0$),
$a(u,v)$, and $L(v)$.  Thereafter, the unknown trial function $u$ is
computed. Then we can compare the numerical and exact solution
as well as investigate $u$ visually.

=== The key import line ===

The first line in the program,

!bc pycod
from dolfin import *
!ec
imports the key classes `UnitSquareMesh`, `FunctionSpace`, `Function`,
and so forth, from the DOLFIN library.  All FEniCS programs for
solving PDEs by the finite element method normally start with this
line. DOLFIN is a software library with efficient and convenient C++
classes for finite element computing, and `dolfin` is a Python package
providing access to this C++ library from Python programs.  You can
think of FEniCS as an umbrella, or project name, for a set of
computational components, where DOLFIN is one important component for
writing finite element programs. The `from dolfin import *` statement
imports other components too, but newcomers to FEniCS programming do
not need to care about this.

## NOTE: index entries *must* become before paragraph/subsubsection
## headings, otherwise sphinx output will be malformed

idx{`Mesh`}
idx{DOLFIN mesh}

=== Generating simple meshes ===

The statement

!bc pycod
mesh = UnitSquareMesh(6, 4)
!ec
defines a uniform finite element mesh over the unit square
$[0,1]\times [0,1]$. The mesh consists of *cells*, which are triangles
with straight sides. The parameters 6 and 4 tell that the square is
first divided into $6\times 4$ rectangles, and then each rectangle is
divided into two triangles. The total number of triangles then becomes
48. The total number of vertices in this mesh is $7\cdot 5=35$.
DOLFIN offers some classes for creating meshes over very simple
geometries. For domains of more complicated shape one needs to use a
separate *preprocessor* program to create the mesh.  The FEniCS
program will then read the mesh from file.

idx{`FunctionSpace`}
idx{finite element specifications}
idx{CG finite element family}
idx{Lagrange finite element family}
idx{P1 element}

=== Defining a function space corresponding to a mesh ===

Having a mesh, we can define a discrete function space `V` over this mesh:

!bc pycod
V = FunctionSpace(mesh, 'Lagrange', 1)
!ec
The second argument reflects the type of element, while the third
argument is the degree of the basis functions on the element.  The
type of element is here ``Lagrange'', implying the standard Lagrange
family of elements.  (Some FEniCS programs use `'CG'`, for Continuous
Galerkin, as a synonym for `'Lagrange'`.)  With degree 1, we simply
get the standard linear Lagrange element, which is a triangle with
nodes at the three vertices.  Some finite element practitioners refer
to this element as the ``linear triangle'' or the P1 element.  The
computed $u$ will be continuous and linearly varying in $x$ and $y$
over each cell in the mesh.  Higher-degree polynomial approximations
over each cell are trivially obtained by increasing the third
parameter in `FunctionSpace`, which will then generate P2, P3, and so
forth, type of elements. Changing the second parameter to `'DG'`
creates a function space for discontinuous Galerkin methods.

idx{`TestFunction`} idx{`TrialFunction`}
idx{`DirichletBC`}
idx{Dirichlet boundary conditions}

=== Defining test and trial functions ===

In mathematics, we distinguish between the trial and test spaces $V$
and $\hat{V}$. The only difference in the present problem is the
boundary conditions. In FEniCS we do not specify the boundary
conditions as part of the function space, so it is sufficient to work
with one common space `V` for the and trial and test functions in the
program:

!bc pycod
u = TrialFunction(V)
v = TestFunction(V)
!ec

idx{boundary specification (function)}

=== Specifying the boundary and boundary conditions ===

The next step is to specify the boundary condition: $u=u_0$ on
$\partial\Omega$. This is done by

!bc pycod
bc = DirichletBC(V, u0, u0_boundary)
!ec
where `u0` is an instance holding the $u_0$ values, and `u0_boundary`
is a function (or object) describing whether a point lies on the
boundary where $u$ is specified.

Boundary conditions of the type $u=u_0$ are known as *Dirichlet
conditions*, and also as *essential boundary conditions* in a finite
element context.  Naturally, the name of the DOLFIN class holding the
information about Dirichlet boundary conditions is `DirichletBC`.

idx{`Expression`}

The `u0` variable refers to an `Expression` object, which is used to
represent a mathematical function. The typical construction is

!bc pycod
u0 = Expression(formula)
!ec
where `formula` is a string containing the mathematical expression.
This formula is written with C++ syntax (the expression is
automatically turned into an efficient, compiled C++ function, see
Section ref{tut:app:cpp:functions} for details on the syntax). The
independent variables in the function expression are supposed to be
available as a point vector `x`, where the first element `x[0]`
corresponds to the $x$ coordinate, the second element `x[1]` to the
$y$ coordinate, and (in a three-dimensional problem) `x[2]` to the $z$
coordinate. With our choice of $u_0(x,y)=1 + x^2 + 2y^2$, the formula
string must be written as `1 + x[0]*x[0] + 2*x[1]*x[1]`:

!bc pycod
u0 = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
!ec

idx{boundary specification (function)}

The information about where to apply the `u0` function as boundary
condition is coded in a function `u0_boundary`:

!bc pycod
def u0_boundary(x, on_boundary):
    return on_boundary
!ec
A function like `u0_boundary` for marking the boundary must return a
boolean value: `True` if the given point `x` lies on the Dirichlet
boundary and `False` otherwise.  The argument `on_boundary` is `True`
if `x` is on the physical boundary of the mesh, so in the present
case, where we are supposed to return `True` for all points on the
boundary, we can just return the supplied value of `on_boundary`.  The
`u0_boundary` function will be called for every discrete point in the
mesh, which allows us to have boundaries where $u$ are known also
inside the domain, if desired.

One can also omit the `on_boundary` argument, but in that case we need
to test on the value of the coordinates in `x`:

!bc pycod
def u0_boundary(x):
    return x[0] == 0 or x[1] == 0 or x[0] == 1 or x[1] == 1
!ec
As for the formula in `Expression` objects, `x` in the `u0_boundary`
function represents a point in space with coordinates `x[0]`, `x[1]`,
etc. Comparing floating-point values using an exact match test with
`==` is not good programming practice, because small round-off errors
in the computations of the `x` values could make a test `x[0] == 1`
become false even though `x` lies on the boundary.  A better test is
to check for equality with a tolerance:

!bc pycod
def u0_boundary(x):
    tol = 1E-15
    return abs(x[0]) < tol or \
           abs(x[1]) < tol or \
           abs(x[0] - 1) < tol or \
           abs(x[1] - 1) < tol
!ec

idx{UFL}

=== Specifying the right-hand side function ===

Before defining $a(u,v)$ and $L(v)$ we have to specify the $f$ function:

!bc pycod
f = Expression('-6')
!ec
When $f$ is constant over the domain, `f` can be
more efficiently represented as a `Constant` object:

!bc pycod
f = Constant(-6.0)
!ec

=== Specifying the variational formulation ===

Now we have all the objects we need in order to specify this problem's
$a(u,v)$ and $L(v)$:

!bc pycod
a = inner(nabla_grad(u), nabla_grad(v))*dx
L = f*v*dx
!ec
In essence, these two lines specify the PDE to be solved.  Note the
very close correspondence between the Python syntax and the
mathematical formulas $\nabla u\cdot\nabla v \dx$ and $fv \dx$.  This
is a key strength of FEniCS: the formulas in the variational
formulation translate directly to very similar Python code, a feature
that makes it easy to specify PDE problems with lots of PDEs and
complicated terms in the equations.  The language used to express weak
forms is called UFL (Unified Form Language) and is an integral part of
FEniCS.

Instead of `nabla_grad` we could also just have written `grad` in the
examples in this tutorial. However, when taking gradients of vector
fields, `grad` and `nabla_grad` differ. The latter is consistent with
the tensor algebra commonly used to derive vector and tensor PDEs,
where $\nabla$ (``nabla'') acts as a vector operator, and therefore
this author prefers to always use `nabla_grad`.

=== Forming and solving the linear system ===

Having `a` and `L` defined, and information about essential
(Dirichlet) boundary conditions in `bc`, we can compute the solution,
a finite element function `u`, by

!bc pycod
u = Function(V)
solve(a == L, u, bc)
!ec
Some prefer to replace `a` and `L` by an `equation`
variable, which is accomplished by this equivalent code:

!bc pycod
equation = inner(nabla_grad(u), nabla_grad(v))*dx == f*v*dx
u = Function(V)
solve(equation, u, bc)
!ec

Note that we first defined the variable `u` as a `TrialFunction` and
used it to represent the unknown in the form `a`.  Thereafter, we
redefined `u` to be a `Function` object representing the solution,
i.e., the computed finite element function $u$.  This redefinition of
the variable `u` is possible in Python and often done in FEniCS
applications. The two types of objects that `u` refers to are equal
from a mathematical point of view, and hence it is natural to use the
same variable name for both objects. In a program, however,
`TrialFunction` objects must always be used for the unknowns in the
problem specification (the form `a`), while `Function` objects must be
used for quantities that are computed (known).

idx{degrees of freedom}

=== Examining the values of the solution ===

The present test problem should produce a numerical solution that
equals the exact solution to machine precision. That is, there are
no approximation errors in our test problem. We can use this property
to ``prove'' that our implementation is correct, a necessary first step
before we try to apply our code to more complicated problems.
For such verification, we need
to compare the computed `u` function to `u0`.

A finite element function like $u$ is expressed as a linear combination
of basis functions $\phi_j$, spanning the space $V$:

!bt
\begin{equation}
u = \sum_{j=1}^N U_j \phi_j label{tut:poisson1:ufem}\tp
\end{equation}
!et
By writing `solve(a == L, u, bc)` in the program, a linear system
will be formed from $a$ and $L$, and this system is solved for the
$U_1,\ldots,U_N$ values. The $U_1,\ldots,U_N$ values are known
as *degrees of freedom* of $u$. For Lagrange elements (and many other
element types) $U_k$ is simply the value of $u$ at the node
with global number $k$.
The nodes and cell vertices coincide for linear Lagrange elements, while
for higher-order elements there are additional nodes at
the facets and maybe also in the interior of cells.

Having `u` represented as a `Function` object, we can either evaluate
`u(x)` at any point `x` in the mesh (expensive operation!),
or we can grab all the degrees of
freedom values $U_j$ directly by

!bc pycod
u_nodal_values = u.vector()
!ec
The result is a DOLFIN `Vector` object, which is basically an
encapsulation of the vector object used in the linear algebra package
that is used to solve the linear system arising from the
variational problem.
Since we program in Python it is convenient to convert the
`Vector` object to a standard `numpy` array for further
processing:

idx{degrees of freedom array}
idx{nodal values array}
idx{numbering!degrees of freedom}
idx{numbering!cell vertices}

!bc pycod
u_array = u_nodal_values.array()
!ec
With `numpy` arrays we can write MATLAB-like code to analyze
the data. Indexing is done with square brackets: `u_array[i]`,
where the index `i` always starts at `0`. However, `i` corresponds
to $u$ at some point in the mesh and the correspondence requires
knowledge of the numbering of degrees of freedom and the numbering of
vertices in elements in the mesh, see Section ref{tut:poisson1:verify1}
for details.

idx{`interpolate`}

For now, we want to check that the values in `u_array` are correct:
they should equal our `u0` function. The most natural approach is
to interpolate our `u0` expression onto our space
(i.e., the finite element mesh),

!bc pycod
u0_Function = interpolate(u0, V)
!ec
The `interpolate` function returns a `Function` object, whose degrees
of freedom values can be obtained by `.vector().array()`.  Our goal is
to show that the degrees of freedom arrays of `u` and `u0_Function`
are equal. One safe of doing this is to compute the maximum error,

!bc pycod
u0_array = u0_Function.vector().array()  # dof values
max_error = (u0_array - u.vector().array()).max()
print('max error:', max_error)
!ec

!bnotice How to check that the error vanishes?
With inexact arithmetics, as we always have on a computer,
this maximum error is not zero, but should be a small number.
The machine precision is about $10^{-16}$, but in finite element
calculations, rounding errors of this size may accumulate, so
the expected accuracy of `max_error` smaller. Experiments show
that increasing the number of elements and increasing the degree
of the finite element polynomials increase `max_error`.
For a mesh with $2(20\times 20)$ cubic Lagrange elements (degree 3)
`max_error` is about $2\cdot 10^{-12}$, while for 18 linear elements
the maximum error is about $2\cdot 10^{-15}$.
!enotice

=== Plotting the solution ===

The simplest way of quickly looking at `u` is to say

!bc pycod
plot(u, interactive=True)
# or
plot(u)
interactive()
!ec
Clicking on `Help` in the plot windows brings up a list of commands.
For example, typing `m` brings up the mesh.  With the left, middle,
and right mouse buttons you can rotate, translate, and zoom
(respectively) the plotted surface to better examine what the solution
looks like. You must click `Ctrl+q` to kill the plot window and
continue execution beyond the `plot(u, interactive=True)` command or
`interactive()`.  Figure ref{tut:poisson:2D:fig:ex1:u} displays the
resulting $u$ function.

Plotting both the solution and the mesh is accomplished by

!bc pycod
plot(u)
plot(mesh)
# Hold plot
interactive()
!ec
Type `Ctrl+w` to kill all plot windows and continue execution.

It is also possible to dump the computed solution to file, e.g., in the
VTK format:

!bc pycod
file = File('poisson.pvd')
file << u
!ec
The `poisson.pvd` file can now be loaded into any front-end to VTK,
say ParaView or VisIt. The `plot` function is intended for quick
examination of the solution during program development.  More in-depth
visual investigations of finite element solutions will normally
benefit from using highly professional tools such as ParaView and
VisIt.


===== Refactored implementation =====
label{tut:poisson1:impl2}

Our initial program above is ``flat''. That is, it is not organized into
logical, reusable units in terms of Python functions. Such flat programs are
popular for quickly testing out some software, but not well suited for
serious problem solving. We shall therefore at once *refactor* the program,
meaning that we divide it into functions, but this is just a
reordering of the existing statements. During refactoring, we try
make functions as reusable as possible in other contexts, but
statements specific to a certain problem or task are also encapsulated
in (non-reusable) functions.
Being able to distinguish reusable code from specialized code is a key issue
when refactoring code, and this ability depends on a good mathematical
understanding of the problem at hand (``what is general, what is special?'').
In a flat program, general and specialized code (and mathematics)
is often mixed together.

=== A general solver function ===

Some of the code in the previous flat program are needed to solve any
Poisson problem $-\nabla^2 u=f$ on $[0,1]\times [0,1]$ with $u=u_0$ on
the boundary. Let us collect this code in a reusable function
`solver`.  Our special test problem will then just be an application
of `solver` with some additional statements.
We limit the `solver` function to just *compute the numerical
solution*. Plotting and comparing the solution with the exact solution
are considered to be problem-specific activities to be performed elsewhere.

We parameterize `solver` by $f$, $u_0$, and the
resolution of the mesh. Since it is so trivial to use higher-order
finite element functions by changing the third argument to
`FunctionSpace`, we let also the degree of the polynomials in the
finite element basis functions be an argument to `solver`.
[hpl: The refactoring extends functionality. Should we be strict and keep linear elements? The test is better when it tests the degree parameter as well...]

@@@CODE ../../src/poisson/${prog['p2D_func']}.py fromto: from dolfin import@def test_solver

=== Plotting for the test problem ===

The additional tasks we did in our initial program can be placed in
other functions. For example, plotting the solution in our particular
test problem is placed in an
`application_test` function:

@@@CODE ../../src/poisson/${prog['p2D_func']}.py fromto: def application_test@if __name

=== Make a module! ===

The refactored code is put in a file "`${prog['p2D_func']}.py`":
"${src_url}/poisson/${prog['p2D_func']}.py". We should make
sure that such a file can be imported (and hence reused) in other programs.
Then all statements in the main program should appear with a test
`if __name__ == '__main__':`. This test is true if the file is executed
as a program, but false if the file is imported.
If we want to run this file in the same way as we can
run `${prog['p2D_func']}.py`, the main program is simply a call to
`application_test()` followed by a call `interactive()` to hold the plot:

@@@CODE ../../src/poisson/${prog['p2D_func']}.py fromto: if __name@

idx{unit testing}

=== Verification ===

The remaining part of our first program is to compare the numerical and
the exact solution. Every time we edit the code we must rerun the test
and examine that `max_error` is sufficiently small so we know that the
code still works. To this end, we shall adopt *unit testing*, meaning
that we create a mathematical test and corresponding software that
can run all our tests automatically and check that all tests pass.
Python has several tools for unit testing. Two very popular ones are
pytest and nose. These are almost identical and very easy to use.
More classical unit testing with test classes is offered by the built-in
tool `unittest`, but here we are going to use pytest (or nose) since it demands
shorter and clearer code.

Mathematically, our unit test is that the finite element solution of
our problem when $f=-6$ equals the exact solution $u=u_0=1+x^2+2y^2$.
We have already created code that finds the maximum error in the
numerical solution. Because of rounding errors, we cannot demand this
maximum error to be zero, but we have to use a tolerance, which depends
to the number of elements and the degrees of the polynomials in the finite
element basis functions. In Section ref{tut:poisson1:impl:dissect} we
reported some experiments with the size of the maximum error. If we want
to test that `solver` works for meshes up to $2(20\times 20)$ elements
and cubic Lagrange elements, $10^{-11}$ is
an appropriate tolerance for testing that the maximum error vanishes.

Only three statements are necessary to carry out the unit test. However,
we shall embed these statements in software that the testing frameworks
pytest and nose can recognize. This means that each unit test
must be placed in a function that

 * has a name starting with `test_`
 * has no arguments
 * implements the test as `assert success, msg`

Regarding the last point, `success` is a boolean expression that is `False`
if the test fails, and in that case the string `msg` is written to the
screen. When the test fails, `assert` raises an `AssertionError` exception
in Python, otherwise the statement runs silently. The `msg` string is
optional, so `assert success` is the minimal test. In our case, we
will do `assert max_error < tol`, where `tol` is the tolerance ($10^{-11}$)
mentioned above.

A proper *test function* for implementing this unit test in the pytest
or nose testing frameworks has the following form. Note that we perform
the test for different mesh resolutions and degrees of finite elements.

@@@CODE ../../src/poisson/${prog['p2D_func']}.py fromto: def test_solver@def application_test
We can at any time run

!bc sys
Terminal> py.test -s -v ${prog['p2D_func']}.py
!ec
and the pytest tool will run all functions `test_*()` in the file and report
how the tests go.

We shall make it a habit in this book to encapsulate numerical test
problems in unit tests as done above, and we strongly encourage the
reader to create similar unit tests whenever a FEniCS solver is
implemented. We dare to assert that this is the only serious way
do reliable computational science with FEniCS.

!bnotice Tip: Print messages in test functions
The `assert` statement runs silently when the test passes so users may
become uncertain if all the statements in a test function are really
executed. A psychological help is to print out something before `assert`
(as we do in the example above) such that it is clear that the
test really takes place.
(Note that `py.test` needs the `-s` option to show printout
from the test functions.)
!enotice

The next three sections deal with some technicalities about specifying
the solution method for linear systems (so that you can solve large
problems) and examining array data from the computed solution (so that
you can check that the program is correct).  These technicalities are
scattered around in forthcoming programs. However, the impatient
reader who is more interested in seeing the previous program being
adapted to a real physical problem, and play around with some
interesting visualizations, can safely jump to Section
ref{tut:poisson:membrane}.  Information in the intermediate sections
can be studied on demand.

===== Exercise: Solve a Poisson problem =====

Solve the following problem

!bt
\begin{align}
\nabla^2 u &= 2e^{-2x}\sin(\pi y)((4-5\pi^2)\sin(2\pi x) - 8\pi\cos(2\pi x)),
\quad\hbox{ in }\Omega = [0,1]\times [0,1]\\
u &= 0\quad\hbox{ on }\partial\Omega
\end{align}
!et
The exact solution is given by

!bt
\[ \uex = 2e^{-2x}\sin(\pi x)\sin(\pi y)\tp\]
!et
Compute the maximum numerical approximation error in a mesh with
$2(N_x\times N_y)$ elements and in a mesh with double resolution:
$4(N_x\times N_y)$ elements. Show that the doubling the resolution
reduces the error by a factor 4 when using Lagrange elements of degree one.
(This is a good verification that the implementation is correct, but
note that the result requires sufficiently fine mesh - here
one may start with $N_x=N_y=20$.)
Make an illustrative plot of the solution too.

!bsubex
file=p2D_fsin_plain

Base your implementation on editing the program
`${prog["p2D_plain"]}.py`.

!bhint
In the string for an `Expression` object, `DOLFIN_PI` is the value of
$\pi$. Also note that $\pi^2$ must be expressed with syntax
`pow(DOLFIN_PI,2)` and not (the common Python syntax) `DOLFIN_PI**2`.

FEniCS will abort with a compilation error if you type the expressions
in a wrong way syntax-wise.  Search for `error:` in the
`/very/long/path/compile.log` file mentioned in the error message to
see what the C++ compiler reported as error in the expressions.
!ehint

!bsol
Looking at the `${prog["p2D_plain"]}.py` code, we realize that
the following edits are required:

 * Modify the `mesh` computation.
 * Modify `u0` and `f`.
 * Add expression for the exact solution.
 * Modify the computation of the numerical error.
 * Insert a loop to enable solving the problem twice.
 * Put the error reduction computation and the plot statements after the loop.

Here is the modified code:

@@@CODE exer/p2D_fsin_plain.py fromto: from dolfin import@

The number $\pi$ has the symbol `M_PI` in C and C++, but in FEniCS C++
expressions the symbol `DOLFIN_PI` must be used. Above, we introduce
the variable `pi` in the expression for `f`, since we find it more
readable, and then we define `pi` as `DOLFIN_PI` as an extra parameter
to `Expression`. The alternative of using `DOLFIN_PI` inside the
string `f` gives a more difficult-to-read expression.

FIGURE: [fig/p2D_fsin, width=500 frac=0.8]

!esol
!esubex

!bsubex
file=p2D_fsin_func

Base your implementation on a new file that imports functionality
from the module `${prog["p2D_func"]}.py`. Embed the check of the
reduction of the numerical approximation error in a unit test.

!bsol
Solving the two problems is a matter of calling `solver` with
different sets of arguments.
To compute the numerical error,
we need code that is close to what we have in `test_solver`.

@@@CODE exer/p2D_fsin_func.py fromto: from p2D_func import@
The unit test is embedded in a proper test function `test_solver`
for the pytest or
nose testing frameworks. Visualization of the solution is encapsulated
in the `application` function. Since we need `u_e`, `u0`, and `f`
in two functions, we place the definitions in a function `data` to
avoid copies of these expressions.

!esol
!esubex

!bremarks
This exercise demonstrates that changing a flat program to solve a new
problem requires careful editing of statements scattered around in the
file, while
the solution in b), based on the `solver` function, requires *no modifications*
of the `${prog["p2D_func"]}.py` file, just
*minimalistic additional new code* in a separate file. The Poisson solver
remains in one place (`${prog["p2D_func"]}.py`) while in a) we got two
Poisson solvers. If you decide to switch to an iterative solution method
for linear systems, you can do so in one place in b), and all applications
can take advantage of the extension.
!eremarks

!split
# Or Useful extensions and recipies?
======= Useful extensions =======

===== Controlling the solution process =====
label{tut:poisson1:solve:prm}

Sparse LU decomposition (Gaussian elimination) is used by default to
solve linear systems of equations in FEniCS programs.  This is a very
robust and recommended method for a few thousand unknowns in the
equation system, and may hence be the method of choice in many 2D and
smaller 3D problems. However, sparse LU decomposition becomes slow and
memory demanding in large problems.  This fact forces the use of
iterative methods, which are faster and require much less memory.
Consequently, we must tell you already now how you can take
advantage of state-of-the-art iterative solution methods in FEniCS.

=== Setting linear solver parameters ===

Preconditioned Krylov solvers is a type of popular iterative methods
that are easily accessible in FEniCS programs. The Poisson equation
results in a symmetric, positive definite coefficient matrix, for
which the optimal Krylov solver is the Conjugate Gradient (CG)
method. However, the CG method requires boundary conditions to be
implemented in a symmetric way. This is not the case by default, so
then a Krylov solver for non-symmetric system, such as GMRES, is a
better choice.  Incomplete LU factorization (ILU) is a popular and
robust all-round preconditioner, so let us try the GMRES-ILU pair:

!bc pycod
solve(a == L, u, bc)
      solver_parameters={'linear_solver': 'gmres',
                         'preconditioner': 'ilu'})
# Alternative syntax
solve(a == L, u, bc,
      solver_parameters=dict(linear_solver='gmres',
                             preconditioner='ilu'))
!ec
Section ref{tut:app:solver:prec} lists the most popular choices of
Krylov solvers and preconditioners available in FEniCS.

idx{linear algebra backend}
idx{PETSc} idx{Trilinos} idx{MTL4} idx{uBLAS}

=== Linear algebra backend ===

The actual GMRES and ILU implementations that are brought into action
depends on the choice of linear algebra package. FEniCS interfaces
several linear algebra packages, called *linear algebra backends* in
FEniCS terminology.  PETSc is the default choice if DOLFIN is compiled
with PETSc, otherwise uBLAS.  Epetra (Trilinos), Eigen, MTL4 are other
supported backends.  Which backend to apply can be controlled by
setting

!bc pycod
parameters['linear_algebra_backend'] = backendname
!ec
where `backendname` is a string, either `'Eigen'`, `'PETSc'`, `'uBLAS'`,
`'Epetra'`, or `'MTL4'`.  All these backends offer high-quality
implementations of both iterative and direct solvers for linear systems
of equations.

idx{UMFPACK}

A common platform for FEniCS users is Ubuntu Linux.  The FEniCS
distribution for Ubuntu contains PETSc, making this package the
default linear algebra backend.  The default solver is sparse LU
decomposition (`'lu'`), and the actual software that is called is then
the sparse LU solver from UMFPACK (which PETSc has an interface
to). The available linear algebra backends in a FEniCS installation is
listed by

!bc pycod
list_linear_algebra_backends()
!ec

idx{`parameters` database}
idx{`info` function}

=== The `parameters` database ===

We will normally like to control the tolerance in the stopping
criterion and the maximum number of iterations when running an
iterative method.  Such parameters can be set by accessing the *global
parameter database*, which is called `parameters` and which behaves as
a nested dictionary. Write

!bc pycod
info(parameters, verbose=True)
!ec
to list all parameters and their default values in the database.
The nesting of parameter sets is indicated through indentation in the
output from `info`.
According to this output, the relevant parameter set is
named `'krylov_solver'`, and the parameters are set like this:

!bc pycod
prm = parameters['krylov_solver']  # short form
prm['absolute_tolerance'] = 1E-10
prm['relative_tolerance'] = 1E-6
prm['maximum_iterations'] = 1000
!ec
Stopping criteria for Krylov solvers usually involve the norm of
the residual, which must be smaller than the absolute tolerance
parameter *or* smaller than the relative tolerance parameter times
the initial residual.

To get a printout of the number of actual iterations to reach the
stopping criterion, we can insert

!bc pycod
set_log_level(PROGRESS)
# or
set_log_level(DEBUG)
!ec
A message with the equation system size, solver type, and number of
iterations arises from specifying the argument `PROGRESS`, while
`DEBUG` results in more information, including CPU time spent in
the various parts of the matrix assembly and solve process.

We remark that default values for the global parameter database can be
defined in an XML file. To generate such a file from the current set
of parameters in a program, run

!bc pycod
File('dolfin_parameters.xml') << parameters
!ec
If a `dolfin_parameters.xml` file is found in the directory where a
FEniCS program is run, this file is read and used to initialize the
`parameters` object. Otherwise, the file
`.config/fenics/dolfin_parameters.xml` in the user's home directory is
read, if it exists.  Another alternative is to load the XML (with any
name) manually in the program:

!bc pycod
File('dolfin_parameters.xml') >> parameters
!ec
The XML file can also be in gzip'ed form with the extension `.xml.gz`.


idx{`${prog["p2D_iter"]}.py`}

=== An extended solver function ===

Let us extend the previous solver function from
`${prog["p2D_func"]}.py` such that it also offers the GMRES+ILU
preconditioned Krylov solver.

@@@CODE ../../src/poisson/${prog['p2D_iter']}.py fromto: from dolfin import@def test_solver
This new `solver` function, found in the file
`${prog["p2D_iter"]}.py`, replaces the one in `${prog["p2D_func"]}.py`:
it has all the functionality of the previous `solver` function,
but can also solve the linear system with
iterative methods and report the progress of such solvers.

=== Remark regarding unit tests ===

Regarding verification of the new `solver` function in terms of unit
tests, it turns out that unit testing in a problem where the
approximation error vanishes is gets more complicated when we use
iterative methods. The problem is to keep the error due to iterative
solution smaller than the tolerance used in the verification
tests. First of all this means that the tolerances used in the Krylov
solvers must be smaller than the tolerance used in the `assert` test,
but this is no guarantee to keep the linear solver error this small.
For linear elements and small meshes, a tolerance of $10^{-11}$ works
well in the case of Krylov solvers too (using a tolerance $10^{-12}$
in those solvers. However, as soon as we switch to P2 elements, it is
hard to force the linear solver error below $10^{-6}$. Consequently,
tolerances in tests depend on the numerical methods. The interested
reader is referred to the `test_solver` function in
`${prog["p2D_iter"]}.py` for details: this test function tests the
numerical solution for direct and iterative linear solvers, for
different meshes, and different degrees of the polynomials in the
finite element basis functions.


===== Linear variational problem and solver objects =====
label{tut:poisson1:solver:problem}
idx{LinearVariationalProblem}
idx{LinearVariationalSolver}

idx{`${prog["p2D_iter"]}.py`}

The `solve(a == L, u, bc)` call is just a compact syntax alternative to a
slightly more comprehensive specification of the variational equation
and the solution of the associated linear system.  This alternative
syntax is used in a lot of FEniCS applications and will also be
used later in this tutorial, so we show it already now:

!bc pycod
u = Function(V)
problem = LinearVariationalProblem(a, L, u, bc)
solver  = LinearVariationalSolver(problem)
solver.solve()
!ec

Many objects have an attribute `parameters` corresponding to
a parameter set in the global `parameters` database,
but local to the object. Here, `solver.parameters` play that
role. Setting the CG method with ILU preconditioning as solution
method and specifying solver-specific parameters can be done
like this:

!bc pycod
solver.parameters['linear_solver'] = 'gmres'
solver.parameters['preconditioner'] = 'ilu'
prm = solver.parameters['krylov_solver'] # short form
prm['absolute_tolerance'] = 1E-7
prm['relative_tolerance'] = 1E-4
prm['maximum_iterations'] = 1000
!ec
Settings in the global `parameters` database are
propagated to parameter sets in individual objects, with the
possibility of being overwritten as done above.

The linear variational problem and solver objects as outlined above
are incorporated in an alternative solver function, named
`solver_objects`, in
`${prog["p2D_iter"]}.py`. Otherwise, this function is parallel to the
previously shown `solver` function.


===== Writing out the discrete solution =====
label{tut:poisson1:verify1}

We have seen how to grab the degrees of freedom array from a
finite element function `u`:

!bc pycod
u_array = `u.vector().array()
!ec
The elements in `u_array` correspond to function values of `u` at nodes
in the mesh.  Now, a fundamental question is: What are the
coordinates of node `i` whose value is `u_array[i]`? To answer this
question, we need to understand how to get our hands on the
coordinates, and in particular, the numbering of degrees of freedom
and the numbering of vertices in the mesh. We start with P1 (1st order
Lagrange) elements where all the nodes are vertices in the mesh.

The function `mesh.coordinates()` returns the coordinates of the
vertices as a `numpy` array with shape $(M,d$), $M$ being the number
of vertices in the mesh and $d$ being the number of space dimensions:

!bc pyshell
>>> from dolfin import *
>>>
>>> mesh = UnitSquareMesh(2, 2)
>>> coor = mesh.coordinates()
>>> coor
array([[ 0. ,  0. ],
       [ 0.5,  0. ],
       [ 1. ,  0. ],
       [ 0. ,  0.5],
       [ 0.5,  0.5],
       [ 1. ,  0.5],
       [ 0. ,  1. ],
       [ 0.5,  1. ],
       [ 1. ,  1. ]])
!ec
We see from this output that vertices are first numbered along $y=0$
with increasing $x$ coordinate, then along $y=0.5$, and so on.

Next we compute a function `u` on this mesh, e.g., the $u=x+y$:

!bc pyshell
>>> V = FunctionSpace(mesh, 'Lagrange', 1)
>>> u = interpolate(Expression('x[0]+x[1]'), V)
>>> plot(u, interactive=True)
>>> u_array = u.vector().array()
>>> u_array
array([ 1. ,  0.5,  1.5,  0. ,  1. ,  2. ,  0.5,  1.5,  1. ])
!ec
We observe that `u_array[0]` is *not* the value of $x+y$ at vertex number 0,
since this vertex has coordinates $x=y=0$. The numbering of the
degrees of freedom $U_1,\ldots,U_{N}$ is obviously not the same as the
numbering of the vertices.

In the plot of `u`, type `w` to turn on wireframe instead of fully colored
surface, `m` to show the mesh, and then `v` to show the
numbering of the vertices.

<linebreak>
<linebreak>

FIGURE: [fig/vertex_numbering, width=500 frac=0.8]

<linebreak>
<linebreak>

idx{compute vertex values}
idx{vertex values}

The vertex values of a `Function` object can be extracted by
`u.compute_vertex_values()`, which returns an array where element `i`
is the value of `u` at vertex `i`:

!bc pyshell
>>> u_at_vertices = u.compute_vertex_values()
>>> for i, x in enumerate(coor):
...     print('vertex %d: u_at_vertices[%d]=%g\tu(%s)=%g' %
...           (i, i, u_at_vertices[i], x, u(x)))
vertex 0: u_at_vertices[0]=0	u([ 0.  0.])=8.46545e-16
vertex 1: u_at_vertices[1]=0.5	u([ 0.5  0. ])=0.5
vertex 2: u_at_vertices[2]=1	u([ 1.  0.])=1
vertex 3: u_at_vertices[3]=0.5	u([ 0.   0.5])=0.5
vertex 4: u_at_vertices[4]=1	u([ 0.5  0.5])=1
vertex 5: u_at_vertices[5]=1.5	u([ 1.   0.5])=1.5
vertex 6: u_at_vertices[6]=1	u([ 0.  1.])=1
vertex 7: u_at_vertices[7]=1.5	u([ 0.5  1. ])=1.5
vertex 8: u_at_vertices[8]=2	u([ 1.  1.])=2
!ec

idx{vertex to dof map}
idx{dof to vertex map}

Alternatively, we can ask for the mapping from vertex numbering to degrees
of freedom numbering in the space $V$:

!bc
v2d = vertex_to_dof_map(V)
!ec
Now, `u_array[v2d[i]]` will give us the value of the
degree of freedom in `u` corresponding
to vertex `i` (`v2d[i]`). In particular, `u_array[v2d]` is an array
with all the elements in the same (vertex numbered) order as `coor`.
The inverse map, from degrees of freedom
number to vertex number is given by `dof_to_vertex_map(V)`, so
`coor[dof_to_vertex_map(V)]` results in an array of all the
coordinates in the same order as the degrees of freedom.

For Lagrange elements of degree larger than 1, there are degrees of
freedom (nodes) that do not correspond to vertices.
[hpl: Anders, is the following true?] There is no simple way of getting the
coordinates associated with the non-vertex degrees of freedom, so
if we want to write out the values of a finite element solution,
the following code snippet does the task at the vertices, and this
will work for all kinds of Lagrange elements.

@@@CODE ../../src/poisson/${prog['p2D_iter']}.py fromto: def compare_exact@def normalize
As expected, the error is either identically zero or about $10^{-15}$ or
$10^{-16}$.

!bwarning Cheap vs expensive function evaluation
Given a `Function` object `u`, we can evaluate its values in various
ways:

 o `u(x)` for an arbitrary point `x`
 o `u.vector().array()[i]` for degree of freedom number `i`
 o `u.compute_vertex_values()[i]` at vertex number `i`

The first method, though very flexible, is in general very expensive
while the other two are very efficient (but limited to certain points).
!ewarning

To demonstrate the use of point evaluations of `Function` objects,
we write out the computed `u` at the center point
of the domain and compare it with the exact solution:

!bc pycod
center = (0.5, 0.5)
error = u0(center) - u(center)
print('numerical error at %s: %g' % (center, error)
!ec
Trying a $2(3\times 3)$ mesh, the output from the
previous snippet becomes

!bc dat
numerical error at (0.5, 0.5): -0.0833333
!ec
The discrepancy is due to the fact that the center point is not a node
in this particular mesh, but a point in the interior of a cell,
and `u` varies linearly over the cell while
`u0` is a quadratic function. When the center point is a node, as in
a $2(t\times 2)$ or $2(4\times 4)$ mesh, the error is of the order
$10^{-15}$.

We have seen how to extract the nodal values in a `numpy` array.
If desired, we can adjust the nodal values too. Say we want to
normalize the solution such that $\max_j U_j = 1$. Then we
must divide all $U_j$ values
by $\max_j U_j$. The following function performs the task:

@@@CODE ../../src/poisson/${prog['p2D_iter']}.py fromto: def normalize@def test_normalize
That is, we manipulate `u_array` as desired, and then we insert this
array into `u`'s `Vector` object.  The `/=` operator implies an
in-place modification of the object on the left-hand side: all
elements of the `u_array` are divided by the value `max_u`.
Alternatively, one could write `u_array = u_array/max_u`, which
implies creating a new array on the right-hand side and assigning this
array to the name `u_array`.

!bwarning Be careful when manipulating degrees of freedom
A call like `u.vector().array()` returns a *copy* of the data in
`u.vector()`. One must therefore never perform assignments like
`u.vector.array()[:] = ...`, but instead extract the `numpy` array
(i.e., a copy), manipulate it, and insert it back with `u.vector()[:]
= ` or `u.set_local(...)`.
!ewarning


All the code in this subsection can be found in the file `${prog["p2D_iter"]}.py`
in the `poisson` directory.


===== Parameterizing the number of space dimensions =====
label{tut:poisson:nD}
idx{dimension-independent code}

FEniCS makes it is easy to write a unified simulation code that can
operate in 1D, 2D, and 3D. We will conveniently make use of this
feature in forthcoming examples.  As an appetizer, go back to the
introductory programs `${prog["p2D_plain"]}.py` or
`${prog["p2D_func"]}.py` in the `poisson` directory and change the
mesh construction from `UnitSquareMesh(6, 4)` to `UnitCubeMesh(6, 4,
5)`. Now the domain is the unit cube partitioned into $6\times 4\times
5$|$6x4x5$ boxes, and each box is divided into six tetrahedra-shaped
finite elements for computations.  Run the program and observe that we
can solve a 3D problem without any other modifications (!). The
visualization allows you to rotate the cube and observe the function
values as colors on the boundary.


=== Generating a hypercube ===

The syntax for generating a unit interval, square, or box is different,
so we need to encapsulate this part of the code. Given a list or
tuple with the divisions into cells in the various spatial direction,
the following function returns the mesh in a $d$-dimensional problem:

!bc pycod
def unit_hypercube(divisions, degree):
    mesh_classes = [UnitIntervalMesh, UnitSquareMesh, UnitCubeMesh]
    d = len(divisions)
    mesh = mesh_classes[d-1](*divisions)
    V = FunctionSpace(mesh, 'Lagrange', degree)
    return V, mesh
!ec
The construction `mesh_class[d-1]` will pick the right name of the
object used to define the domain and generate the mesh.
Moreover, the argument `*divisions`
sends all the component of the list `divisions` as separate
arguments. For example, in a 2D problem where `divisions` has
two elements, the statement

!bc pycod
mesh = mesh_classes[d-1](*divisions)
!ec
is equivalent to

!bc pycod
mesh = UnitSquareMesh(divisions[0], divisions[1])
!ec

Replacing the `Nx` and `Ny` parameters by `divisions` and calling
`unit_hypercube` to create the mesh are the two modifications that
we need in any of the previously shown `solver` functions to turn
them into solvers for $d$-dimensional problems!


===== Computing derivatives =====
label{tut:poisson:gradu}

idx{projection}

In Poisson and many other problems, the gradient of the solution is
of interest. The computation is in principle simple:
since
$u = \sum_{j=1}^N U_j \phi_j$, we have that

!bt
\begin{equation*}
\nabla u = \sum_{j=1}^N U_j \nabla \phi_j\tp
\end{equation*}
!et
Given the solution variable `u` in the program, its gradient is
obtained by `grad(u)` or `nabla_grad(u)`.  However, the gradient of a
piecewise continuous finite element scalar field is a discontinuous
vector field since the $\phi_j$ has discontinuous derivatives at the
boundaries of the cells. For example, using Lagrange elements of
degree 1, $u$ is linear over each cell, and the numerical $\nabla u$
becomes a piecewise constant vector field. On the contrary, the exact
gradient is continuous.  For visualization and data analysis purposes
we often want the computed gradient to be a continuous vector
field. Typically, we want each component of $\nabla u$ to be
represented in the same way as $u$ itself. To this end, we can project
the components of $\nabla u$ onto the same function space as we used
for $u$.  This means that we solve $w = \nabla u$ approximately by a
finite element method, using the same elements for the components of
$w$ as we used for $u$. This process is known as *projection*.

idx{`project`} idx{projection}

Not surprisingly, projection is a so common operation in finite
element programs that FEniCS has a function for doing the task:
`project(q, W)`, which returns the projection of some `Function` or
`Expression` object named `q` onto the `FunctionSpace` (if `q` is
scalar) or `VectorFunctionSpace` (if `q` is vector-valued) named `W`.
Specifically, in our case where `u` is computed and we want to project
the vector-valued `grad(u)` onto the `VectorFunctionSpace` where each
component has the same `Function` space as `u`:

!bc pycod
V = u.function_space()
degree = u.ufl_element().degree()
W = VectorFunctionSpace(V.mesh(), 'Lagrange', degree)

grad_u = project(grad(u), W)
!ec
Figure ref{tut:poisson:2D:fig:ex1:gradu} shows
example of how such a smoothed `gradu(u)` vector field is visualized.

FIGURE:[fig/ex1_gradu, width=480] Example of visualizing the vector field $\nabla u$ by arrows at the nodes. label{tut:poisson:2D:fig:ex1:gradu}

The applications of projection are many, including turning discontinuous
gradient fields into continuous ones, comparing higher- and lower-order
function approximations, and transforming a higher-order finite element
solution down to a piecewise linear field, which is required by many
visualization packages.


The scalar component fields of the gradient
can be extracted as separate fields and, e.g., visualized:

!bc pycod
grad_u_x, grad_u_y = grad_u.split(deepcopy=True)
plot(grad_u_x, title='x-component of grad(u)')
plot(grad_u_y, title='y-component of grad(u)')
!ec
The `deepcopy=True` argument signifies a *deep copy*, which is
a general term in computer science implying that a copy of the data is
returned. (The opposite, `deepcopy=False`,
means a *shallow copy*, where
the returned objects are just pointers to the original data.)

idx{degrees of freedom array}
idx{nodal values array}
idx{degrees of freedom array (vector field)}

The `grad_u_x` and `grad_u_y` variables behave as
`Function` objects. In particular, we can extract the underlying
arrays of nodal values by

!bc pycod
grad_u_x_array = grad_u_x.vector().array()
grad_u_y_array = grad_u_y.vector().array()
!ec
The degrees of freedom of the `grad_u` vector field can also be
reached by

!bc pycod
grad_u_array = grad_u.vector().array()
!ec
but this is a flat `numpy` array where the degrees of freedom for the
$x$ component of the gradient is stored in the first part, then the
degrees of freedom of the $y$ component, and so on. This is less convenient
to work with.

idx{`${prog["p2D_iter"]}.py`}

The function `gradient(u)` in `${prog["p2D_iter"]}.py`
returns a projected (smoothed) $\nabla u$ vector field, given some
finite element function `u`:

@@@CODE ../../src/poisson/${prog['p2D_iter']}.py fromto: def gradient@def application_test_gradient

Examining the arrays with vertex values of `grad_u_x` and `grad_u_y`
quickly reveals that the computed `grad_u` field does not equal the
exact gradient $(2x, 4y)$ in this particular test problem where
$u=1+x^2+2y^2$.  There are inaccuracies at the boundaries, arising
from the approximation problem for $w$. Increasing the mesh resolution
shows, however, that the components of the gradient vary linearly as
$2x$ and $4y$ in the interior of the mesh (i.e., as soon as we are one
element away from the boundary).  The `application_test_gradient`
function in `${prog["p2D_iter"]}.py` performs some experiments.

!bnotice Detour: Manual projection.
Although you will always use `project` to project a finite element
function, it can be constructive this point in the tutorial to formulate the
projection mathematically and implement its steps manually in FEniCS.

Looking at the component $\partial u/\partial x$ of the gradient, we
project the (discrete) derivative $\sum_jU_j{\partial \phi_j/\partial
x}$ onto a function space with basis $\phi_1,\phi_2,\ldots$ such that
the derivative in this space is expressed by the standard sum
$\sum_j\bar U_j \phi_j$, for suitable (new) coefficients $\bar U_j$.

The variational problem for $w$ reads: find  $w\in \Vg$ such that

!bt
\begin{equation}
a(w, v) = L(v)\quad\forall v\in \hat{\Vg},
\end{equation}
!et
where

!bt
\begin{align}
a(w, v) &= \int_\Omega w\cdot v \dx,\\
L(v) &= \int_\Omega \nabla u\cdot v \dx\tp
\end{align}
!et
The function spaces $\Vg$ and $\hat{\Vg}$ (with the superscript g
denoting ``gradient'') are vector versions of the function space for
$u$, with boundary conditions removed (if $V$ is the space we used for
$u$, with no restrictions on boundary values, $\Vg = \hat{\Vg} =
[V]^d$, where $d$ is the number of space dimensions).  For example, if
we used piecewise linear functions on the mesh to approximate $u$, the
variational problem for $w$ corresponds to approximating each
component field of $w$ by piecewise linear functions.

The variational problem for the vector field
$w$, called `grad_u` in the code, is easy to solve in FEniCS:

!bc pycod
V_g = VectorFunctionSpace(mesh, 'Lagrange', 1)
w = TrialFunction(V_g)
v = TestFunction(V_g)

a = inner(w, v)*dx
L = inner(grad(u), v)*dx
grad_u = Function(V_g)
solve(a == L, grad_u)

plot(grad_u, title='grad(u)')
!ec
The boundary condition argument to `solve` is dropped since there are
no essential boundary conditions in this problem.
The new thing is basically that we work with a `VectorFunctionSpace`,
since the unknown is now a vector field, instead of the
`FunctionSpace` object for scalar fields.
!enotice


===== A variable-coefficient Poisson problem =====
label{tut:possion:2D:varcoeff}
idx{Poisson's equation with variable coefficient}
idx{`${prog["p2D_vc"]}.py`}

Suppose we have a variable coefficient $p(x,y)$ in the Laplace operator,
as in the boundary-value problem

!bt
\begin{equation} label{tut:poisson:2D:varcoeff}
  \begin{split}
    - \nabla\cdot \left\lbrack
p(x,y)\nabla u(x,y)\right\rbrack &= f(x,y) \quad \mbox{in } \Omega,
    \\
    u(x,y) &= u_0(x,y) \quad \mbox{on}\  \partial\Omega\tp
  \end{split}
\end{equation}
!et
We shall quickly demonstrate that this simple extension of our model
problem only requires an equally simple extension of the FEniCS program.

=== Test problem ===

Let us continue to use our favorite solution $u(x,y)=1+x^2+2y^2$ and
then prescribe $p(x,y)=x+y$. It follows that
$u_0(x,y) = 1 + x^2 + 2y^2$ and $f(x,y)=-8x-10y$.

=== Modifications of the PDE solver ===

What are the modifications we need to do in the previously shown codes
to incorporate the variable coefficient $p$?
from Section ref{tut:poisson1:verify1}?

  * `solver` must take `p` as argument,
  * `f` in our test problem
    must be an `Expression` since it is no longer a constant,
  * a new `Expression p` must be defined for the variable coefficient,
  * the formula for $a(u,v)$ in the variational problem is slightly changed.

First we address the modified variational problem. Multiplying
the PDE by a test function $v$ and
integrating by parts now results
in

!bt
\begin{equation*}
\int_\Omega p\nabla u\cdot\nabla v \dx -
\int_{\partial\Omega} p{\partial u\over
\partial n}v \ds = \int_\Omega fv \dx\tp
\end{equation*}
!et
The function spaces for $u$ and $v$ are the same as in
Section ref{tut:poisson1:varform}, implying that the boundary integral
vanishes since $v=0$ on $\partial\Omega$ where we have Dirichlet conditions.
The weak form $a(u,v)=L(v)$ then has

!bt
\begin{align}
a(u,v) &= \int_\Omega p\nabla u\cdot\nabla v \dx,\\
L(v) &= \int_\Omega fv \dx\tp
\end{align}
!et
In the code for solving $-\nabla^2u=f$ we must replace

!bc pycod
a = inner(nabla_grad(u), nabla_grad(v))*dx
!ec
by

!bc pycod
a = p*inner(nabla_grad(u), nabla_grad(v))*dx
!ec
to solve $-\nabla\cdot(p\nabla u)=f$. Moreover,
the definitions of `p` and `f` in the test problem read

!bc pycod
p = Expression('x[0] + x[1]')
f = Expression('-8*x[0] - 10*x[1]')
!ec
No additional modifications are necessary. The file
`${prog["p2D_vc"]}.py` (variable-coefficient Poisson problem in 2D)
is a copy of `${prog["p2D_iter"]}.py` with the mentioned changes
incorporated. Observe that $p=1$ recovers the original problem in
`${prog["p2D_iter"]}.py`.

You can run it and confirm
that it recovers the exact $u$ at the nodes.

=== Modifications of the flux computations ===

The flux $-p\nabla u$ may be of particular interest in
variable-coefficient Poisson problems as it often has an interesting
physical significance. As explained in Section ref{tut:poisson:gradu},
we normally want the piecewise discontinuous flux or gradient to be
approximated by a continuous vector field, using the same elements as
used for the numerical solution $u$. The approximation now consists of
solving $w = -p\nabla u$ by a finite element method: find $w\in \Vg$
such that

!bt
\begin{equation}
a(w, v) = L(v)\quad\forall v\in \hat{\Vg},
\end{equation}
!et
where

!bt
\begin{align}
a(w, v) &= \int_\Omega w\cdot v \dx,\\
L(v) &= \int_\Omega (-p \nabla u)\cdot v \dx\tp
\end{align}
!et
This problem is identical to the one in Section ref{tut:poisson:gradu},
except that $p$ enters the integral in $L$.

The relevant Python statement for computing the flux field take the form

!bc pycod
flux = project(-p*grad(u),
               VectorFunctionSpace(mesh, 'Lagrange', degreee))
!ec
An appropriate function for computing the flux based on `u` and `p` is

@@@CODE ../../src/poisson/${prog['p2D_vc']}.py fromto: def flux@def application_test_gradient


Plotting the flux vector field is naturally as easy as plotting
the gradient (see Section ref{tut:poisson:gradu}):

!bc pycod
plot(flux, title='flux field')

flux_x, flux_y = flux.split(deepcopy=True)  # extract components
plot(flux_x, title='x-component of flux (-p*grad(u))')
plot(flux_y, title='y-component of flux (-p*grad(u))')
!ec

For data analysis of the nodal values of the flux field we can
grab the underlying `numpy` arrays (demands a `deepcopy=True`
in the split of `flux`):

!bc pycod
flux_x_array = flux_x.vector().array()
flux_y_array = flux_y.vector().array()
!ec

[hpl: The following is not done properly in the revised version.]
The function `application_test_gradient` in the
program `${prog["p2D_vc"]}.py` contains in addition some plots,
including a curve plot
comparing `flux_x` and the exact counterpart along the line $y=1/2$.
The associated programming details related to this visualization
are explained in Section ref{tut:structviz}.

===== Creating the linear system explicitly =====
label{tut:poisson1:linalg}

Given $a(u,v)=L(v)$, the discrete solution $u$ is computed by
inserting $u=\sum_{j=1}^N U_j \phi_j$ into $a(u,v)$ and demanding
$a(u,v)=L(v)$ to be fulfilled for $N$ test functions
$\hat\phi_1,\ldots,\hat\phi_N$. This implies

!bt
\begin{equation*}
\sum_{j=1}^N a(\phi_j,\hat\phi_i) U_j = L(\hat\phi_i),\quad i=1,\ldots,N,
\end{equation*}
!et
which is nothing but a linear system,

!bt
\begin{equation*}
  AU = b,
\end{equation*}
!et
where the entries in $A$ and $b$ are given by

!bt
\begin{align*}
  A_{ij} &= a(\phi_j, \hat{\phi}_i), \\
  b_i &= L(\hat\phi_i)\tp
\end{align*}
!et

idx{`assemble`}
idx{linear systems (in FEniCS)}
idx{assembly of linear systems}

The examples so far have specified the left- and right-hand side of
the variational formulation and then asked FEniCS to assemble the
linear system and solve it.  An alternative is to explicitly call
functions for assembling the coefficient matrix $A$ and the right-side
vector $b$, and then solve the linear system $AU=b$ with respect to
the $U$ vector.  Instead of `solve(a == L, u, b)` we now write

!bc pycod
A = assemble(a)
b = assemble(L)
bc.apply(A, b)
u = Function(V)
U = u.vector()
solve(A, U, b)
!ec
The variables `a` and `L` are as before. That is, `a` refers to the
bilinear form involving a `TrialFunction` object (e.g., `u`)
and a `TestFunction` object (`v`), and `L` involves a
`TestFunction` object (`v`). From `a` and `L`,
the `assemble` function can
compute $A$ and $b$.

The matrix $A$ and vector $b$ are first assembled without incorporating
essential (Dirichlet) boundary conditions. Thereafter, the
call `bc.apply(A, b)` performs the necessary modifications of
the linear system such that `u` is guaranteed to equal the prescribed
boundary values.
When we have multiple Dirichlet conditions stored in a list `bcs`,
as explained in Section ref{tut:poisson:multiple:Dirichlet}, we must apply
each condition in `bcs` to the system:

!bc pycod
# bcs is a list of DirichletBC objects
for bc in bcs:
    bc.apply(A, b)
!ec

idx{`assemble_system`}

There is an alternative function `assemble_system`, which can
assemble the system and take boundary conditions into account in one call:

!bc pycod
A, b = assemble_system(a, L, bcs)
!ec
The `assemble_system` function incorporates the boundary conditions
in the element matrices and vectors, prior to assembly.
The conditions are also incorporated in a symmetric way to preserve
eventual symmetry of the coefficient matrix.
#That is, for each degree of freedom
#that is known, the corresponding row and column is zero'ed out and 1
#is placed on the main diagonal, and the right-hand side `b` is
#modified by subtracting the column in `A` times the value of the
#degree of, and then the corresponding entry in `b` is replaced by the
#known value of the degree of freedom.
With `bc.apply(A, b)` the
matrix `A` is modified in an nonsymmetric way.
#: The row is zero'ed out
#and 1 is placed on the main diagonal, and the degree of freedom value
#is inserted in `b`.

Note that the solution `u` is, as before, a `Function` object.
The degrees of freedom, $U=A^{-1}b$, are filled
into `u`'s `Vector` object (`u.vector()`)
by the `solve` function.

The object `A` is of type `Matrix`, while `b` and
`u.vector()` are of type `Vector`. We may convert the
matrix and vector data to `numpy` arrays by calling the
`array()` method as shown before. If you wonder how essential
boundary conditions are incorporated in the linear system, you can
print out `A` and `b` before and after the
`bc.apply(A, b)` call:

!bc pycod
A = assemble(a)
b = assemble(L)
if mesh.num_cells() < 16:  # print for small meshes only
    print(A.array())
    print(b.array())
bc.apply(A, b)
if mesh.num_cells() < 16:
    print(A.array())
    print(b.array())
!ec


With access to the elements in `A` through a `numpy` array we can easily
perform computations on this matrix, such as computing the eigenvalues
(using the `eig` function in `numpy.linalg`). We can alternatively dump
`A.array()` and `b.array()` to file in MATLAB format and invoke
MATLAB or Octave to analyze the linear system.
Dumping the arrays to MATLAB format is done by

!bc pycod
import scipy.io
scipy.io.savemat('Ab.mat', {'A': A.array(), 'b': b.array()})
!ec
Writing `load Ab.mat` in MATLAB or Octave will then make
the array variables `A` and `b` available for computations.

idx{SLEPc}

Matrix processing in Python or MATLAB/Octave is only feasible for
small PDE problems since the `numpy` arrays or matrices in MATLAB
file format are dense matrices. DOLFIN also has an interface to the
eigensolver package SLEPc, which is a preferred tool for computing the
eigenvalues of large, sparse matrices of the type encountered in PDE
problems (see `demo/la/eigenvalue` in the DOLFIN source code tree
for a demo).


#A complete code where the linear system $AU=b$ is explicitly assembled and
#solved is found in the file `${prog["dn3_p2D"]}.py` in the directory
#`poisson`. This code solves the same problem as in
#`${prog["dn2_p2D"]}.py`
#(Section ref{tut:poisson:multiple:Dirichlet}).  For small
#linear systems, the program writes out `A` and `b` before and
#after incorporation of essential boundary conditions and illustrates
#the difference between `assemble` and `assemble_system`.
#The reader is encouraged to run the code for a $2\times 1$
#mesh (`UnitSquareMesh(2, 1)` and study the output of `A`.

By default, `solve(A, U, b)` applies sparse LU decomposition
as solver. Specification of an iterative solver and preconditioner
is done through two optional arguments:

!bc pycod
solve(A, U, b, 'cg', 'ilu')
!ec
Appropriate names of solvers and preconditioners are found in
Section ref{tut:app:solver:prec}.

idx{KrylovSolver}

To control tolerances in the stopping criterion and the maximum
number of iterations, one can explicitly form a `KrylovSolver` object
and set items in its `parameters` attribute
(see also Section ref{tut:poisson1:solver:problem}):

!bc pycod
solver = KrylovSolver('cg', 'ilu')
prm = solver.parameters
prm['absolute_tolerance'] = 1E-7
prm['relative_tolerance'] = 1E-4
prm['maximum_iterations'] = 1000
u = Function(V)
U = u.vector()
set_log_level(DEBUG)
solver.solve(A, U, b)
!ec
The function `solver_linalg` in the
program file `${prog["p2D_vc"]}.py` implements a solver function where
the user can choose between different types of assembly: the variational
(`solve(a == L, u, bc)`), assembling the matrix and right-hand side separately, and assembling the system such that the coefficient matrix preserves
symmetry.
The function `application_linalg` runs a test problem on sequence of
meshes and solves the problem with symmetric and non-symmetric modification
of the coefficient matrix. One can monitor the number of Krylov
method iteration and realize that with a symmetric coefficient matrix,
the Conjugate Gradient method requires slightly fewer iterations than
GMRES in the non-symmetric case. Taking into account that the Conjugate
Gradient method has less work per iteration, there is some efficiency to
be gained by using `assemble_system`.

[hpl: Running `application_linalg`, the results are strange: Why does
the `solve(a==L,...)` method need many more iterations than `solve(A,
U, b, ...)` when we use the same Krylov parameter settings? Something
wrong with the settings?]

idx{random start vector (linear systems)}

The choice of start vector for the iterations in a linear solver is often
important. With the `solver.solve(A, U, b)` call the default start vector
is the zero vector. A start vector
with random numbers in the interval $[-100,100]$ can be computed as

!bc pycod
n = u.vector().array().size
U = u.vector()
U[:] = numpy.random.uniform(-100, 100, n)
solver.parameters['nonzero_initial_guess'] = True
solver.solve(A, U, b)
!ec
Note that we must turn off the default behavior of setting the start
vector (``initial guess'') to zero.

Creating the linear system explicitly in a program can have some
advantages in more advanced problem settings. For example, $A$ may
be constant throughout a time-dependent simulation, so we can avoid
recalculating $A$ at every time level and save a significant amount
of simulation time.  Sections ref{tut:timedep:diffusion1:impl}
and ref{tut:timedep:diffusion1:noassemble} deal with this topic
in detail.


# In other problems, we may divide the variational
# problem and linear system into different terms, say $A=M + {\dt} K$,
# where $M$ is a matrix arising from a term like $\partial u/\partial t$,
# $K$ is a term corresponding to a Laplace operator, and $\dt$ is
# a time discretization parameter. When $\dt$ is changed in time,
# we can efficiently recompute $A = M + {\dt} K$ without
# reassembling the constant matrices $M$ and $K$. This strategy may
# speed up simulations significantly.


!split
======= Visualization =======

===== Deflection of a circular membrane =====
label{tut:poisson:membrane}

Perhaps you are not particularly amazed by viewing the simple surface
of $u$ in the test problem used in the previous sections.
However, solving a real physical problem
with a more interesting and amazing solution on the screen is only a
matter of specifying a more exciting domain, boundary condition,
and/or right-hand side $f$.

=== The problem ===

One possible physical problem regards the deflection $D(x,y)$ of an
elastic circular membrane with radius $R$, subject to a localized
perpendicular pressure force, modeled as a Gaussian function.  The
appropriate PDE model is

!bt
\begin{equation}
-T\nabla^2 D = p(x,y)\quad\hbox{in }\Omega = \{ (x,y)\,|\, x^2+y^2\leq R\},
\end{equation}
!et
with

!bt
\begin{equation}
p(x,y) = {A\over 2\pi\sigma}\exp{\left(
- {1\over2}\left( {x-x_0\over\sigma}\right)^2
- {1\over2}\left( {y-y_0\over\sigma}\right)^2
\right)}\, .
\end{equation}
!et
Here, $T$ is the tension in the membrane (constant), $p$ is the external
pressure load,
$A$ the amplitude of the pressure, $(x_0,y_0)$ the localization of
the Gaussian pressure function, and $\sigma$ the ``width'' of this
function. The boundary of the membrane has no
deflection, implying $D=0$ as boundary condition.

#For scaling and verification it is convenient to simplify the problem
#to find an analytical solution. In the limit $\sigma\rightarrow\infty$,
#$p\rightarrow A/(2\pi\sigma)$ (constant pressure throughout $\Omega$),
#and we can easily find an analytical solution
#of the problem by integrating the Poisson equation in the
#radial coordinate: $r\in [0,R]$. The result becomes
#$D(r)=(r^2-R^2)A/(8\pi\sigma T)$.

=== Scaling ===

The localization of the pressure, $(x_0,y_0)$, is for simplicity
set to $(0, R_0)$.
There are many physical parameters in this problem, and we can benefit
from grouping them by means of scaling. Let us introduce dimensionless
coordinates $\bar x = x/R$, $\bar y = y/R$, and a dimensionless
deflection $w=D/D_c$, where $D_c$ is a characteristic size of the
deflection. Introducing $\bar R_0=R_0/R$, we get

!bt
\[ \frac{\partial^2 w}{\partial\bar x^2} +
\frac{\partial^2 w}{\partial\bar y^2}= \alpha
\exp{\left(
- \beta^2(\bar x^2
+ (\bar y-\bar R_0)^2)\right)}\hbox{ for } \bar x^2 + \bar y^2 < 1,\]
!et
where

!bt
\[ \alpha = \frac{R^2A}{2\pi T D_c\sigma},\quad\beta = \frac{R}{\sqrt{2}\sigma}\tp\]
!et
With an appropriate scaling, $\bar w$ and its derivatives are of size
unity, so the left-hand side of the scaled PDE is about unity in size,
while the right-hand side has $\alpha$ as its characteristic size.
This suggest choosing $\alpha$ to be unity, or around unit.
We shall in particular choose $\alpha=4$. With this value,
the solution is $w(\bar x,\bar y) = 1-\bar x^2 - \bar y^2$.
(One can also find the analytical solution in scaled coordinates and show
that the maximum deflection $D(0,0)$ is $D_c$ if we choose $\alpha=4$
to determine $D_c$.)
With $D_c=AR^2/(8\pi\sigma T)$
and dropping the bars we get the scaled problem

!bt
\begin{equation}
\nabla^2w = 4\exp{\left(
- \beta^2(x^2
+ (y-R_0)^2)\right)},
label{tut:poisson1:membrane:scaled:eq}
\end{equation}
!et
to be solved over the unit circle with $w=0$ on the boundary.
Now there are only two parameters to vary: the dimensionless extent
of the pressure, $\beta$, and the localization of the pressure peak, $R_0\in [0,1]$.
As $\beta\rightarrow 0$, we
have a special case with solution $w=1-x^2-y^2$.

Given a computed $w$, the physical deflection is given by

!bt
\[ D = \frac{AR^2}{8\pi\sigma T}w\tp\]
!et

=== Implementation ===

Very few modifications of the software in
`${prog["p2D_iter"]}.py` are required. Actually, the `solver` function
can be reused, except that the domain is now a circle and not a
square. We change the `solver` function by letting the mesh be
an argument `mesh` (instead of `Nx` and `Ny`):

!bc pycod
def solver(
    f, u0, mesh, degree=1,
    linear_solver='Krylov', # Alt: 'direct'
    ...):
    V = FunctionSpace(mesh, 'Lagrange', degree)
    ...
!ec

A mesh over the unit circle can be created by the `mshr` tool in
FEniCS:

!bc pycod
from mshr import *
domain = Circle(Point(0.0, 0.0), 1.0)
mesh = generate_mesh(domain, n)
!ec
The `Circle` shape from `mshr` takes the center and radius of the circle
as the two first arguments, while `n` is the resolution, here the
suggested number of cells per radius.

idx{`Expresion`}
idx{Expression with parameters}

The right-hand side pressure function
is represented by an `Expression` object. There
are two physical parameters in the formula for $f$ that enter the
expression string and these parameters must have their values set
by keyword arguments:

!bc pycod
p = Expression(
    '4*exp(-pow(beta,2)*(pow(x[0], 2) + pow(x[1]-R0, 2)))',
    beta=beta, R0=R0)
!ec
The coordinates in `Expression` objects *must* be a vector
with indices 0, 1, and 2, and with the name `x`. Otherwise
we are free to introduce names of parameters as long as these are
given default values by keyword arguments. All the parameters
initialized by keyword arguments can at any time have their
values modified. For example, we may set

!bc pycod
f.beta = 12
f.R0 = 0.3
!ec

idx{interpolation}

It would be of interest to visualize $p$ along with $w$ so that we can
examine the pressure force and the membrane's response.  We must then transform
the formula (`Expression`) to a finite element function
(`Function`).  The most natural approach is to construct a finite
element function whose degrees of freedom are
calculated from $p$. That is, we interpolate $p$:

!bc pycod
p = interpolate(p, V)
!ec
Calling `plot(p)` will produce a plot of $p$. Note that the assignment
to `p` destroys the previous `Expression` object `p`, so if
it is of interest to still have access to this object, another name must be used
for the `Function` object returned by `interpolate`.

We need some evidence that the program works, and to this end we may
use the analytical solution listed above for the case $\beta =0$.

The final program is found in the file `${prog["membrane"]}.py`, located
in the `poisson` directory. The key function to simulate
membrane deflection is named `application`.

@@@CODE ../../src/poisson/${prog["membrane"]}.py fromto: from dolfin import@def test_membrane

Choosing a very peak-formed pressure with large $\beta$ (e.g., $\beta
\geq 20$) and a location $R_0$ toward the circular boundary (e.g.,
$R_0=0.5$), may produce an exciting visual demonstrations of the very
smoothed elastic response to a peak force (or mathematically, the
smoothing properties of the inverse of the Laplace operator).  One
needs to experiment with the mesh resolution to get a smooth visual
representation of $p$.  You are strongly encouraged to play around
with the plots and different mesh resolutions:

!bc sys
Terminal> python -c 'import membrane as m; m.application()' \
          membrane.py
!ec


===== Quick visualization with VTK =====
label{tut:quickviz}
idx{visualization} idx{plotting} idx{VTK}

As we go along with examples it is fun to play around with
`plot` commands and visualize what is computed. This section explains
some useful visualization features.

The `plot` command applies the VTK package to visualize finite element
functions in a very quick and simple way.  The command is ideal for
debugging, teaching, and initial scientific investigations.  The
visualization can be interactive, or you can steer and automate it
through program statements.  More advanced and professional
visualizations are usually better created with advanced tools like
Mayavi, ParaView, or VisIt.

idx{`membranev.p`}

We have made a program `${prog["membrane"]}.py` for the membrane deflection
problem in Section ref{tut:poisson:membrane} and added various
demonstrations of plotting capabilities. You are encouraged to play around with
`${prog["membrane"]}.py` and modify the code as you read about various features.

idx{`plot`}

The `plot` function can take additional arguments, such as
a title of the plot, or a specification of a wireframe plot (elevated mesh)
instead of a colored surface plot:

!bc pycod
plot(mesh, title='Finite element mesh')
plot(w, wireframe=True, title='Solution')
!ec
Axes can be turned on by the `axes=True` argument, while
`interactive=True` makes the program hang at the plot command - you have
to type `q` in the plot window to terminate the plot and continue execution.

The left mouse button is used to rotate the surface, while the right
button can zoom the image in and out.
Point the mouse to the `Help` text down in the lower left corner to
get a list of all the keyboard commands that are available.
For example,

 * pressing `m` turns visualization of the mesh on and off,
 * pressing `b` turns on and off a bounding box,
 * pressing `p` dumps the plot to a PNG file,
 * pressing `P` dumps the plot to a PDF file,
 * pressing `Ctrl +' stretches the surface in the $z$ direction,
 * pressing `Ctrl -' shrinks++ the surface in the $z$ direction,
 * pressing `Ctrl w' closes the plot window,
 * pressing `Ctrl q' closes all plot windows.

The plots created by pressing `p` or `P` are stored in files with
names `dolfin_plot_X.png` or `dolfin_plot_X.pdf`,
where `X` is an integer that is increase by one from the last plot
that was made. The file stem `dolfin_plot_` can be set to something
more suitable through the `hardcopy_prefix` keyword argument to the
`plot` function,
for instance, `plot(f, hardcopy_prefix='pressure')`.

idx{rotate PDF plots}
idx{`pdftk`}

Plots stored in PDF format need to be rotated 90 degrees before
inclusion in documents. This can be done by the `convert -rotate 90`
command (from the ImageMagick utility), but the resulting file has
then no more high-resolution PDF vector graphics. A better solution
is therefore to use `pdftk` to preserve the vector graphics:

!bc sys
Terminal> pdftk dolfin_plot_1.pdf cat 1-endnorth output out.pdf
!ec

For making plots in batch, we can do the following:

!bc pycod
viz_w = plot(w, interactive=False)
viz_w.elevate(-10)  # adjust (lift) camera from the default view
viz_w.plot(w)       # bring new settings into action
viz_w.write_png('deflection')  # make deflection.png
viz_w.write_pdf('deflection')  # make deflection.pdf
# Rotate pdf file (right) from landscape to portrait
import os
os.system('pdftk deflection.pdf cat 1-endnorth output w.pdf')
!ec
The commands above appear in the `application2`
function in the `${prog["membrane"]}.py` file.

FIGURE:[fig/membrane_deflection, width=480 frac=0.7] Plot of the deflection of a membrane. label{tut:poisson:2D:fig1}

===== Paraview =====

===== Taking advantage of structured mesh data =====
label{tut:structviz}
idx{structured mesh}
idx{visualization, structured mesh}
idx{`scitools`}

When finite element computations are done on a structured rectangular
mesh, maybe with uniform partitioning, VTK-based tools for completely
unstructured 2D/3D meshes are not required.  Instead we can use
visualization and data analysis tools for *structured data*.
Such data typically appear in finite difference simulations and
image analysis.  Analysis and visualization of structured data are faster
and easier than doing the same with data on unstructured meshes, and
the collection of tools to choose among is much larger.  We shall
demonstrate the potential of such tools and how they allow for
tailored and flexible visualization and data analysis.

idx{`BoxField`}

A necessary first step is to transform our `mesh` object to an object
representing a rectangle with equally-shaped *rectangular* cells.
The second step is to
transform the one-dimensional array of nodal values to a
two-dimensional array holding the values at the corners of the cells
in the structured mesh. We want to access a value by
its $i$ and $j$ indices, $i$ counting cells in the $x$ direction, and
$j$ counting cells in the $y$ direction.  This transformation is in
principle straightforward, yet it frequently leads to obscure indexing
errors, so using software tools to ease the work is advantageous.

In the directory `src/modules`, associated with this booklet,
we have included a Python module `BoxField` that can take a finite
element function `u` computed by a FEniCS software and represent
it on a structured box-shaped mesh and assign or extract values by
multi-dimensional indexing: `[i]` in 1D, `[i,j]` in 2D, and
`[i,j,k]` in 3D. Given a finite element function `u`,
the following function returns a `BoxField` object that represents
`u` on a structured mesh:

@@@CODE ../../src/poisson/${prog['p2D_vc']}.py fromto: def structured_mesh@def application_structured_mesh
Note that we can only turn functions on meshes with P1 elements into
`BoxField` objects, so if `u` is based on another element type, we first
interpolate the scalar field onto a mesh with P1 elements. Also note
that to use the
function, we need to know the divisions into cells in the various
spatial directions (`divisions`).

The `u_box` object contains several useful data structures:

 * `u_box.grid`: object for the structured mesh
 * `u_box.grid.coor[X]`: grid coordinates in `X=0` direction
 * `u_box.grid.coor[Y]`: grid coordinates in `Y=1` direction
 * `u_box.grid.coor[Z]`: grid coordinates in `Z=2` direction
 * `u_box.grid.coorv[X]`: vectorized version of `u_box.grid.coor[X]`
   (for vectorized computations or surface plotting)
 * `u_box.grid.coorv[Y]`: vectorized version of `u_box.grid.coor[Y]`
 * `u_box.grid.coorv[Z]`: vectorized version of `u_box.grid.coor[Z]`
 * `u_box.values`: `numpy` array holding the `u` values;
   `u_box.values[i,j]` holds `u` at the mesh point with coordinates <linebreak>
   `(u_box.grid.coor[X], u_box.grid.coor[Y])`

=== Iterating over points and values ===

Let us go back to the `solver` function in the
`${prog["p2D_vc"]}.py` code from
Section ref{tut:possion:2D:varcoeff}, compute `u`, map it onto a
`BoxField` object for a structured mesh representation, and
write out the coordinates and function values at all mesh points:

!bc pycod
u = solver(p, f, u0, nx, ny, 1, linear_solver='direct')
u_box = structured_mesh(u, (nx, ny))
u_ = u_box.values       # numpy array
X = 0;  Y = 1           # for indexing in x and y direction

# Iterate over 2D mesh points (i,j)
print('u_ is defined on a structured mesh with %s points' %
      str(u_.shape))
for j in range(u_.shape[1]):
    for i in range(u_.shape[0]):
        print('u[%d,%d]=u(%g,%g)=%g' %
              (i, j,
               u_box.grid.coor[X][i], u_box.grid.coor[X][j],
               u_[i,j]))
!ec

=== Finite difference approximations ===

Note that with `u_`, we can easily express finite difference approximation
of derivatives:

!bc pycod
x = u_box.grid.coor[X]
dx = x[1] - x[0]
u_xx = (u_[i-1,j] - 2*u_[i,j] + u_[i+1,j])/dx**2
!ec

idx{surface plot (structured mesh)}

=== Surface plot ===

The ability to access a finite element field in the way one can access
a finite difference-type of field is handy in many occasions, including
visualization and data analysis.
With Matplotlib we can create a surface plot, see
Figure ref{tut:structviz:fig1} (upper left):

!bc pycod
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
fig = plt.figure()
ax = fig.gca(projection='3d')
cv = u_box.grid.coorv  # vectorized mesh coordinates
ax.plot_surface(cv[X], cv[Y], u_, cmap=cm.coolwarm,
                rstride=1, cstride=1)
plt.title('Surface plot of solution')
!ec
The key issue is to know that the coordinates needed for the surface
plot is in `u_box.grid.coorv` and that the values are in `u_`.

FIGURE: [fig/p2D_vc_structmesh2, width=800 frac=1] Various plots of the solution on a structured mesh. label{tut:structviz:fig1}


idx{contour plot}

=== Contour plot ===

A contour plot can also be made by Matplotlib:

!bc pycod
fig = plt.figure()
ax = fig.gca()
levels = [1.5, 2.0, 2.5, 3.5]
cs = ax.contour(cv[X], cv[Y], u_, levels=levels)
plt.clabel(cs)  # add labels to contour lines
plt.axis('equal')
plt.title('Contour plot of solution')
!ec
The result appears in Figure ref{tut:structviz:fig1} (upper right).


=== Curve plot through the mesh ===

A handy feature of `BoxField` objects is the ability to give a start
point in the grid and a direction, and then extract the field and
corresponding coordinates along the nearest line of mesh points. In 3D fields
one can also extract data in a plane.  Say we want to plot $u$ along
the line $y=0.4$. The mesh points, `x`, and the $u$ values
along this line, `u_val`, are extracted by

!bc pycod
start = (0, 0.4)
X = 0
x, u_val, y_fixed, snapped = u_box.gridline(start, direction=X)
!ec
The variable `snapped` is true if the line had to be snapped onto a
gridline and in that case `y_fixed` holds the snapped
(altered) $y$ value. To avoid interpolation in the structured mesh,
`snapped` is in fact *always* true.

A comparison of the numerical and exact solution along the line
$y=0.5$ (snapped from $y=0.4$) is made by the following code:

!bc pycod
start = (0, 0.4)
x, u_val, y_fixed, snapped = u_box.gridline(start, direction=X)
u_e_val = [u0((x_, y_fixed)) for x_ in x]

plt.figure()
plt.plot(x, u_val, 'r-')
plt.plot(x, u_e_val, 'bo')
plt.legend(['P1 elements', 'exact'], loc='upper left')
plt.title('Solution along line y=%g' % y_fixed)
plt.xlabel('x');  plt.ylabel('u')
!ec
See Figure ref{tut:structviz:fig1} (lower left) for the resulting curve plot.

=== Curve plot of the flux ===

Let us also compare the numerical and
exact flux $-p\partial u/\partial x$ along the same line as above:

!bc pycod
flux_u = flux(u, p)
flux_u_x, flux_u_y = flux_u.split(deepcopy=True)

# Plot the numerical and exact flux along the same line
flux2_x = flux_u_x if flux_u_x.ufl_element().degree() == 1 \
          else interpolate(flux_x,
               FunctionSpace(u.function_space().mesh(),
                             'Lagrange', 1))
flux_u_x_box = structured_mesh(flux_u_x, (nx,ny))
x, flux_u_val, y_fixed, snapped = \
   flux_u_x_box.gridline(start, direction=X)
y = y_fixed

plt.figure()
plt.plot(x, flux_u_val, 'r-')
plt.plot(x, flux_u_x_exact(x, y_fixed), 'bo')
plt.legend(['P1 elements', 'exact'], loc='upper right')
plt.title('Flux along line y=%g' % y_fixed)
plt.xlabel('x');  plt.ylabel('u')
!ec
The second `plt.plot` command
requires a Python function `flux_u_x_exact(x,y)` to be
available for the exact flux expression.

Note that Matplotlib is one choice of plotting package. With the unified
interface in the "SciTools package": "https://github.com/hplgit/scitools" one
can access Matplotlib, Gnuplot, MATLAB, OpenDX, VisIt, and other plotting
engines through the same API.

idx{`sympy`}

=== Test problem ===

The graphics referred to in Figure ref{tut:structviz:fig1} correspond to
a test problem with prescribed solution $\uex = H(x)H(y)$, where

!bt
\[ H(x) = e^{-16(x-\frac{1}{2})^2}\sin(3\pi x)\tp\]
!et
We just fit a function $f(x,y)$ in the PDE (can choose $p=1$),
and notice that $u=0$ along the
boundary of the unit square. Although it is easy to carry out the
differentiation of $f$ by hand and hardcode the resulting expressions
in an `Expression` object, a more reliable habit is to use Python's
symbolic computing engine, `sympy`, to perform mathematics and
automatically turn formulas into C++ syntax for `Expression` objects.
The following text assumes some familiarity with `sympy` and illustrates
how FEniCS programmers may take advantage of symbolic computing.

We start out with defining the exact solution in `sympy`:

!bc pycod
from sympy import exp, sin, pi  # for use in math formulas
import sympy as sym
H = lambda x: exp(-16*(x-0.5)**2)*sin(3*pi*x)
x, y = sym.symbols('x[0], x[1]')
u = H(x)*H(y)
!ec

!bnotice Define symbolic coordinates as required in `Expression` objects
Note that we would normally write `x, y = sym.symbols('x y')`, but
if we want the resulting expressions to be have valid syntax for
`Expression` objects, and then $x$ reads `x[0]` and $y$ must be `x[1]`.
This is easily accomplished with `sympy` by defining the names of `x` and
`y` as `x[0]` and `x[1]`: `x, y = sym.symbols('x[0] x[1]')`.
!enotice

Turning the expression for `u` into C or C++ syntax for `Expression` objects
needs two steps. First we ask for the C code of the expression,

!bc pycod
u_c = sym.printing.ccode(u)
!ec
Then we do some editing of `u_c` to match the required syntax of
`Expression` objects. Printing `u_c` gives (here manually broken up as
two lines)

!bc
-exp(-16*pow(x[0] - 0.5, 2) - 16*pow(x[1] - 0.5, 2))*
sin(3*M_PI*x[0])*sin(3*M_PI*x[1])
!ec
The necessary syntax adjustment is replacing
the symbol `M_PI` for $\pi$ in C/C++ by `DOLFIN_PI`:

!bc pycod
u_c = u_c.replace('M_PI', 'DOLFIN_PI')
u0 = Expression(u_c)
!ec

Thereafter, we can progress with the computation of $f = -\nabla\cdot(p\nabla u)$:

!bc pycod
p = 1
f = sym.diff(-p*sym.diff(u, x), x) + sym.diff(-p*sym.diff(u, y), y)
f = sym.simplify(f)
f_c = sym.printing.ccode(f)
f_c = f_c.replace('M_PI', 'DOLFIN_PI')
f = Expression(f_c)
!ec
We also need a Python function for the exact flux $-p\partial u/\partial x$:

!bc pycod
flux_u_x_exact = sym.lambdify([x, y], -p*sym.diff(u, x),
                              modules='numpy')
!ec
It remains to define `p = Constant(1)` and set `nx` and `ny` before calling
`solver` to compute the finite element solution of this problem.


#FIGURE: [fig/p2D_vc_structmesh, width=800 frac=1] Various plots of the solution on a structured mesh. label{tut:structviz:fig1a}


# #ifdef EXTRA
It should be easy with the information above to transform a finite
element field over a uniform rectangular or box-shaped mesh to the
corresponding `BoxField` object and perform MATLAB-style
visualizations of the whole field or the field over planes or along
lines through the domain.  By the transformation to a regular grid we
have some more flexibility than what the `plot` command in DOLFIN
offers. However, we remark
that comprehensive tools like VisIt, MayaVi2, or ParaView also have
the possibility for plotting fields along lines and extracting planes
in 3D geometries, though usually with less degree of control compared
to Gnuplot, MATLAB, and Matplotlib.  For example, in investigations of
numerical accuracy or numerical artifacts one is often interested in
studying curve plots where only the nodal values sampled. This is
straightforward with a structured mesh data structure, but more
difficult in visualization packages utilizing unstructured grids, as
hitting exactly then nodes when sampling a function along a line
through the grid might be non-trivial.
# #endif

!split
======= Postprocessing computations =======

===== Computing functionals =====
label{tut:poisson1:functionals}
idx{functionals}

After the solution $u$ of a PDE is computed, we occasionally want to compute
functionals of $u$, for example,

!bt
\begin{equation}
{1\over2}||\nabla u||^2 \equiv {1\over2}\int_\Omega \nabla u\cdot \nabla u \dx,
label{tut:poisson1:functionals:energy}
\end{equation}
!et
which often reflects some energy quantity.
Another frequently occurring functional is the error

!bt
\begin{equation}
||\uex-u|| = \left(\int_\Omega (\uex-u)^2 \dx\right)^{1/2},
label{tut:poisson1:functionals:error}
\end{equation}
!et
where $\uex$ is the exact solution. The error
is of particular interest when studying convergence properties.
Sometimes the interest concerns the flux out of a part $\Gamma$ of
the boundary $\partial\Omega$,

!bt
\begin{equation}
F = -\int_\Gamma p\nabla u\cdot\normalvec \ds,
label{tut:poisson1:functionals:flux}
\end{equation}
!et
where $\normalvec$ is an outward unit normal at $\Gamma$ and $p$ is a
coefficient (see the problem in Section ref{tut:possion:2D:varcoeff}
for a specific example).
All these functionals are easy to compute with FEniCS, and this section
describes how it can be done.

idx{energy functional}

=== Energy functional ===

The integrand of the
energy functional
(ref{tut:poisson1:functionals:energy})
is described in the UFL language in the same manner as we describe
weak forms:

!bc pycod
energy = 0.5*inner(grad(u), grad(u))*dx
E = assemble(energy)
!ec
The `assemble` call performs the integration.
It is possible to restrict the integration to subdomains, or parts
of the boundary, by using
a mesh function to mark the subdomains as explained in
Section ref{tut:poisson:mat:neumann}.

# #ifdef EXTRA
The function `energy` in `${prog["membrane"]}.py` carries out the computation of
the elastic energy

idx{`${prog["membrane"]}.py`}

[hpl: Things are right wrt scaling so far. The PDE is valid for $\beta=0$ so use this case to check scaled energy expressions. Energy is stress from a dimensional point of view: $\int \sigma(\epsilon)d\epsilon = \int E\epsilon d\epsilon \sim E$. The $\beta=0$ case corresponds to $A/(2\pi\sigma)$ constant on the right-hand side in non-scaled coordinates. Must be something with
$\beta\rightarrow 0$, norm of $\nabla w$ goes to zero, no...not from the
exact solution from $w$.]

!bt
\begin{equation*}
{1\over2}||T\nabla D||^2 = {1\over2}\left(\frac{TD_c}{R}\right)^2R^2
||\bar\nabla w||^2 =
{1\over2}\left({AR^2\over 8\pi\sigma}\right)^2
||\nabla w||^2 = \hbox{ no beta! }
\left(\frac{A}{8\pi}\right)^2\beta^2||\nabla w||^2
\end{equation*}
!et
in the membrane problem from Section ref{tut:poisson:membrane}.
# #endif

idx{error functional}

=== Error functional ===

Computation of (ref{tut:poisson1:functionals:error}) is typically done
by

!bc pycod
error = (u - u_exact)**2*dx
E = sqrt(abs(assemble(error)))
!ec
The exact solution $\uex$ is here in a `Function` or
`Expression` object `u_exact`, while `u` is the
finite element approximation.
(Sometimes, for very small error values, the result of
`assemble(error)` can be a (very small) negative number, so we have
used `abs` in the expression for `E` above to ensure a positive value
for the `sqrt` function.)

As will be explained and demonstrate in Section
ref{tut:poisson1:convrates}, the integration of `(u - u_exact)**2*dx`
can result in too optimistic convergence rates unless one is careful
how `u_exact` is transferred onto a mesh. The general recommendation
for reliable error computation is to use the `errornorm` function
(see `pydoc dolfin.errornorm` and Section ref{tut:poisson1:convrates}
for more information):

!bc pycod
E = errornorm(u_exact, u)
!ec


idx{flux functional}

=== Flux Functionals ===

To compute flux integrals like $F = -\int_\Gamma p\nabla
u\cdot\normalvec \ds$ we need to define the $\normalvec$ vector,
referred to as *facet normal* in FEniCS. If the surface domain
$\Gamma$ in the flux integral is the complete
boundary we can perform the flux computation by

!bc pycod
n = FacetNormal(mesh)
flux = -p*dot(nabla_grad(u), n)*ds
total_flux = assemble(flux)
!ec
Although `nabla_grad(u)` and `grad(u)` are interchangeable
in the above expression when `u` is a scalar function, we have
chosen to write `nabla_grad(u)` because this is
the right expression if we generalize the underlying equation
to a vector Laplace/Poisson PDE. With `grad(u)` we must in that
case write `dot(n, grad(u))`.

It is possible to restrict the integration to a part of the boundary
using a mesh function to mark the relevant part, as
explained in Section ref{tut:poisson:mat:neumann}. Assuming that the
part corresponds to subdomain number `i`, the relevant syntax for
the variational formulation of the
flux is `-p*inner(grad(u), n)*ds(i)`.


===== Computing convergence rates =====
label{tut:poisson1:convrates}

To illustrate error computations and convergence of finite element
solutions, we have included a function `convergence_rate` in
the `${prog["p2D_vc"]}.py` program. This is a tool that is very
handy when verifying finite element codes and will therefore be explained in
detail here.


The $L^2$ norm of the error in a finite element approximation $u$,
$\uex$ being the exact solution, is given by

=== Various ways of computing the error ===

!bt
\[ E = \left(\int_\Omega (u_e-u)^2 \dx\right)^{1/2},\]
!et
and implemented in FEniCS by

!bc pycod
error = (u - u_e)**2*dx
E = sqrt(abs(assemble(error)))
!ec
Sometimes, for very small error values, the result of
`assemble(error)` can be a (very small) negative number, so we have
used `abs` in the expression for `E` above to ensure a positive value
for the `sqrt` function.

We remark that `u_e` will, in the expression
above, be interpolated onto the function space `V` before `assemble`
can perform the integration over the domain. This implies that the
exact solution used in the integral will vary linearly over the cells,
and not as a sine function, if `V` corresponds to linear Lagrange
elements.  This situation may yield a smaller error `u - u_e` than
what is actually true.  More accurate representation of the exact
solution is easily achieved by interpolating the formula onto a space
defined by higher-order elements, say of third degree:

!bc pycod
Ve = FunctionSpace(mesh, 'Lagrange', degree=3)
u_e_Ve = interpolate(u_e, Ve)
error = (u - u_e_Ve)**2*dx
E = sqrt(assemble(error))
!ec
To achieve complete mathematical control of which function space the
computations are carried out in, we can explicitly interpolate `u` to
the same space:

!bc pycod
u_Ve = interpolate(u, Ve)
error = (u_Ve - u_e_Ve)**2*dx
!ec

The square in the expression for `error` will be expanded and lead to
a lot of terms that almost cancel when the error is small, with the
potential of introducing significant rounding errors.  The function
`errornorm` is available for avoiding this effect by first
interpolating `u` and `u_exact` to a space with higher-order elements,
then subtracting the degrees of freedom, and then performing the
integration of the error field. The usage is simple:

!bc pycod
E = errornorm(u_exact, u, normtype='L2', degree=3)
!ec
It is illustrative to look at the short implementation of `errornorm`:

!bc pycod
def errornorm(u_exact, u, Ve):
    u_Ve = interpolate(u, Ve)
    u_e_Ve = interpolate(u_exact, Ve)
    e_Ve = Function(Ve)
    # Subtract degrees of freedom for the error field
    e_Ve.vector()[:] = u_e_Ve.vector().array() - \
                       u_Ve.vector().array()
    error = e_Ve**2*dx
    return sqrt(assemble(error))
!ec
The `errornorm` procedure turns out to be identical to computing
the expression `(u_e - u)**2*dx` directly in
the present test case.

Sometimes it is of interest to compute the error of the
gradient field: $||\nabla (u-\uex)||$
(often referred to as the $H^1$ seminorm of the error).
Given the error field `e_Ve` above, we simply write

!bc pycod
H1seminorm = sqrt(assemble(inner(grad(e_Ve), grad(e_Ve))*dx))
!ec

All the various types of error computations here are placed in a
function `compute_errors` in `${prog["p2D_vc"]}.py`:
[hpl: Necessary to repeat code? New info is essentiall the return dict.]
[hpl: Anders, I (in 2010...) ran into problems with `dolfin.errornorm`,
see comments in the code below, and made the version below. We should
check out these problems again and adjust `dolfin.errornorm` if
necessary.]

@@@CODE ../../src/poisson/${prog['p2D_vc']}.py fromto: def compute_errors@def convergence_rate

=== Computing convergence rates empirically ===

Calling the `solver` function for finer and finer meshes enables us to
study the convergence rate. Define the element size $h=1/n$, where $n$
is the number of cell divisions in $x$ and $y$ direction (`n=Nx=Ny` in
the code). We perform experiments with $h_0>h_1>h_2\cdots$ and compute
the corresponding errors $E_0, E_1, E_3$ and so forth.  Assuming
$E_i=Ch_i^r$ for unknown constants $C$ and $r$, we can compare two
consecutive experiments, $E_i=Ch_i^r$ and $E_{i-1}=Ch_{i-1}^r$, and
solve for $r$:

!bt
\begin{equation*}
r = {\ln(E_i/E_{i-1})\over\ln (h_i/h_{i-1})}\tp
\end{equation*}
!et
The $r$ values should approach the expected convergence
rate `degree+1` as $i$ increases.

The procedure above can easily be turned into Python code. Here
we run through a different types of elements (P1, P2, P3, and P4),
perform experiments over a series of refined meshes, and for
each experiment report the six error types as returned by `compute_errors`:

@@@CODE ../../src/poisson/${prog['p2D_vc']}.py fromto: def convergence_rate@def structured_mesh
Note how make a complete general function `convergence_rate`, aimed at
any 2D Poisson problem in the class we now can solve, and then call
this general function in `convergence_rate_sin` for a special test
case.

=== Test problem ===

Section ref{tut:poisson:gradu} and specify a more complicated solution,

!bt
\begin{equation*}
u(x,y) = \sin(\omega\pi x)\sin(\omega\pi y)
\end{equation*}
!et
on the unit square.
This choice implies $f(x,y)=2\omega^2\pi^2 u(x,y)$.
With $\omega$ restricted to an integer
it follows that $u_0=0$.

We need to define the
appropriate boundary conditions, the exact solution, and the $f$ function
in the code:

!bc pycod
def boundary(x, on_boundary):
    return on_boundary

bc = DirichletBC(V, Constant(0.0), boundary)

omega = 1.0
u_e = Expression('sin(omega*pi*x[0])*sin(omega*pi*x[1])',
                 omega=omega)

f = 2*pi**2*omega**2*u_e
!ec

=== Experiments ===

Calling `convergence_rate_sin()` gives some interesting results.
Using the error measure `E5` based on the infinity norm of the
difference of the degrees of freedom, we have

|---c---------c---------c---------c---------c---------c-----|
| element | $n=8$   | $n=16$  | $n=32$  | $n=64$  | $n=128$ |
|---l---------r---------r---------r---------r---------r-----|
| P1      | 1.99    | 1.97    | 1.99    | 2.0     | 2.0     |
| P2      | 3.99    | 3.96    | 3.99    | 4.0     | 3.99    |
| P3      | 3.96    | 3.89    | 3.96    | 3.99    | 4.0     |
| P4      | 3.75    | 4.99    | 5.0     | 5.0     |         |
|-----------------------------------------------------------|

The computations with P4 elements on a $128\times 128$ with a
direct solver (UMFPACK) on a small laptop broke down.
Otherwise we achieve expected results: the error goes like
$h^{d+1}$ for elements of degree $d$. Also $L^2$ norms based
on the `errornorm` gives the expected $h^{d+1}$ rate for
$u$ and $h^d$ for $\nabla u$.

However, using `(u - u_exact)**2` for the error computation, which implies
interpolating `u_exact` onto the same space as `u`, results in $h^4$
convergence for P2 elements.

|---c---------c---------c---------c---------c---------c-----|
| element | $n=8$   | $n=16$  | $n=32$  | $n=64$  | $n=128$ |
|---l---------r---------r---------r---------r---------r-----|
| P1      | 1.98    | 1.94    | 1.98    | 2.0     | 2.0     |
| P2      | 3.98    | 3.95    | 3.99    | 3.99    | 3.99    |
| P3      | 3.69    | 4.03    | 4.01    | 3.95    | 2.77    |
|-----------------------------------------------------------|

This is an example where it is important to interpolate `u_exact` to a
higher-order space (polynomials of degree 3 are sufficient here) to
avoid computing a too optimistic convergence rate.

# Problems with interpolate(u,Ve) - interpolate(u_exact,Ve) for
# high degree and large meshes. Rounding errors? errornorm is the
# remedy?
# interpolate(u,Ve) - interpolate(u_exact,Ve)
# P1: 1.98, 1.96, 1.99, 2.0, 2.0
# P2: 3.01, 3.03, 3.01, 3.0, 3.02
# P3: 2.7, 4.02, 4.0, 2.63, 0.17
# P4: 1.54, 5.11, 0.91, 0.15, -0.01


Checking convergence rates is the next best method for verifying PDE codes
(the best being a numerical solution without approximation errors
as in Section ref{tut:poisson1:verify1} and many other places in this tutorial).

!split
======= Multiple domain and boundaries =======

===== Combining Dirichlet and Neumann conditions =====
label{tut:poisson1:DN}

Let us make a slight extension of our two-dimensional Poisson problem
from Section ref{tut:poisson1:bvp} and add a Neumann boundary
condition. The domain is still the unit square, but now we set the
Dirichlet condition $u=u_0$ at the left and right sides, $x=0$ and
$x=1$, while the Neumann condition

!bt
\begin{equation*}
-{\partial u\over\partial n}=g
\end{equation*}
!et
is applied to the remaining
sides $y=0$ and $y=1$.
The Neumann condition is also known as a *natural boundary condition*
(in contrast to an essential boundary condition).

idx{Neumann boundary conditions}

=== PDE problem ===

Let $\Gamma_D$ and $\Gamma_N$ denote the parts of $\partial\Omega$
where the Dirichlet and Neumann conditions apply, respectively.  The
complete boundary-value problem can be written as

!bt
\begin{align}
    - \nabla^2 u &= f \mbox{ in } \Omega,  \\
    u &= u_0 \mbox{ on } \Gamma_D,       \\
    - {\partial u\over\partial n} &= g \mbox{ on } \Gamma_N  \tp
\end{align}
!et
Again we choose $u=1+x^2 + 2y^2$ as the exact solution and adjust $f$, $g$, and
$u_0$ accordingly:

!bt
\begin{align*}
f &= -6,\\
g &= \left\lbrace\begin{array}{ll}
-4, & y=1\\
0,  & y=0
\end{array}\right.\\
u_0 &= 1 + x^2 + 2y^2\tp
\end{align*}
!et
For ease of programming we may introduce a $g$ function defined over the whole
of $\Omega$ such that $g$ takes on the right values at $y=0$ and
$y=1$. One possible extension is

!bt
\begin{equation*}
g(x,y) = -4y\tp
\end{equation*}
!et

=== Variational formulation ===

The first task is to derive the variational problem. This time we cannot
omit the boundary term arising from the integration by parts, because
$v$ is only zero on $\Gamma_D$. We have

!bt
\begin{equation*}
 -\int_\Omega (\nabla^2 u)v \dx
= \int_\Omega\nabla u\cdot\nabla v \dx - \int_{\partial\Omega}{\partial u\over
\partial n}v \ds,
\end{equation*}
!et
and since $v=0$ on $\Gamma_D$,

!bt
\begin{equation*}
- \int_{\partial\Omega}{\partial u\over
\partial n}v \ds
=
- \int_{\Gamma_N}{\partial u\over
\partial n}v \ds
= \int_{\Gamma_N}gv \ds,
\end{equation*}
!et
by applying the boundary condition on $\Gamma_N$.
The resulting weak form reads

!bt
\begin{equation}
\int_{\Omega} \nabla u \cdot \nabla v \dx +
\int_{\Gamma_N} gv \ds
= \int_{\Omega} fv \dx\tp
label{tut:poisson:2D:DN:weak}
\end{equation}
!et
Expressing this equation
in the standard notation $a(u,v)=L(v)$ is straightforward with

!bt
\begin{align}
a(u, v) &= \int_{\Omega} \nabla u \cdot \nabla v \dx,
label{tut:poisson2:vard:a}\\
L(v) &= \int_{\Omega} fv \dx -
\int_{\Gamma_N} gv \ds\tp  label{tut:poisson2:vard:L}
\end{align}
!et

=== Implementation ===

How does the Neumann condition impact the implementation?
Let us go back to the very simplest file,
`${prog["p2D_plain"]}.py`, from
Section ref{tut:poisson1:impl:code},
we realize that the statements remain almost the same.
Only two adjustments are necessary:

  * The function describing the boundary where Dirichlet conditions
    apply must be modified.
  * The new boundary term must be added to the expression in `L`.

The first adjustment can be coded as

!bc pycod
def Dirichlet_boundary(x, on_boundary):
    if on_boundary:
        if x[0] == 0 or x[0] == 1:
            return True
        else:
            return False
    else:
        return False
!ec
A more compact implementation reads

!bc pycod
def Dirichlet_boundary(x, on_boundary):
    return on_boundary and (x[0] == 0 or x[0] == 1)
!ec

!bwarning Never use `==` for comparing real numbers!
A list like `x[0] == 1` should never be used if `x[0]` is a real number,
because rounding errors in `x[0]` may make the test fail even when it is
mathematically correct. Consider

!bc pycod
>>> 0.1 + 0.2 == 0.3
False
>>> 0.1 + 0.2
0.30000000000000004
!ec

Comparison of real numbers need to use tolerances! The values of the
tolerances depend on the size of the numbers involved in arithmetic
operations:

!bc pycod
>>> abs(0.1+0.2 - 0.3)
5.551115123125783e-17
>>> abs(1.1+1.2 - 2.3)
0.0
>>> abs(10.1+10.2 - 20.3)
3.552713678800501e-15
>>> abs(100.1+100.2 - 200.3)
0.0
>>> abs(1000.1+1000.2 - 2000.3)
2.2737367544323206e-13
>>> abs(10000.1+10000.2 - 20000.3)
3.637978807091713e-12
!ec
For numbers around unity, tolerances as low as $3\cdot 10^{-16}$ can be used
(in fact, this tolerance is known as `DOLFIN_EPS` in the `dolfin` package),
otherwise an appropriate tolerance must be found.

Testing for `x[0] == 1` should therefore be implemented as

!bc pycod
tol = 1E-14
if abs(x[0] - 1) < tol:
    ...
!ec
!ewarning

Here is a new boundary function using tolerances in the test:

!bc pycod
def Dirichlet_boundary(x, on_boundary):
    tol = 1E-14   # tolerance for coordinate comparisons
    return on_boundary and \
           (abs(x[0]) < tol or abs(x[0] - 1) < tol)
!ec

The second adjustment of our program concerns the definition of `L`,
where we have to add a boundary integral and a definition of the $g$
function to be integrated:

!bc pycod
g = Expression('-4*x[1]')
L = f*v*dx - g*v*ds
!ec
The `ds` variable implies a boundary integral, while `dx`
implies an integral over the domain $\Omega$.
No more modifications are necessary.


===== Multiple Dirichlet conditions =====
label{tut:poisson:multiple:Dirichlet}

The PDE problem from the previous section applies a function $u_0(x,y)$
for setting Dirichlet conditions at two parts of the boundary.
Having a single function to set multiple Dirichlet conditions is
seldom possible. The more general case is to have $m$ functions for
setting Dirichlet conditions on $m$ parts of the boundary.
The purpose of this section is to explain how such multiple conditions
are treated in FEniCS programs.

Let us return to the case from Section ref{tut:poisson1:DN} and define
two separate functions for the two Dirichlet conditions:

!bt
\begin{align*}
    - \nabla^2 u &= -6 \mbox{ in } \Omega, \\
    u &= u_L \mbox{ on } \Gamma_0, \\
    u &= u_R \mbox{ on } \Gamma_1, \\
    - {\partial u\over\partial n} &= g \mbox{ on } \Gamma_N \tp
\end{align*}
!et
Here, $\Gamma_0$ is the boundary $x=0$, while $\Gamma_1$ corresponds
to the boundary $x=1$.  We have that $u_L = 1 + 2y^2$, $u_R = 2 +
2y^2$, and $g=-4y$.

=== Functions for marking Dirichlet boundaries ===

For the left boundary $\Gamma_0$ we define the
usual triple of a function for the boundary value, a function for
defining the boundary of interest, and a `DirichletBC` object:

!bc pycod
u_L = Expression('1 + 2*x[1]*x[1]')

def left_boundary(x, on_boundary):
    tol = 1E-14   # tolerance for coordinate comparisons
    return on_boundary and abs(x[0]) < tol

Gamma_0 = DirichletBC(V, u_L, left_boundary)
!ec
For the boundary $x=1$ we write a similar code snippet:

!bc pycod
u_R = Expression('2 + 2*x[1]*x[1]')

def right_boundary(x, on_boundary):
    tol = 1E-14   # tolerance for coordinate comparisons
    return on_boundary and abs(x[0] - 1) < tol

Gamma_1 = DirichletBC(V, u_R, right_boundary)
!ec
The various essential conditions are then collected in a list
and used in the solution process:

!bc pycod
bcs = [Gamma_0, Gamma_1]
...
solve(a == L, u, bcs)
# or
problem = LinearVariationalProblem(a, L, u, bcs)
solver  = LinearVariationalSolver(problem)
solver.solve()
!ec

In other problems, where the $u$ values are constant at a part of the
boundary, we may use a simple `Constant` object instead of an
`Expression` object.

=== Classes for marking Dirichlet boundaries ===

Instead of using a function like `left_boundary(x, on_boundary)` to
mark a boundary, we can alternatively use a class, which allows
for more flexibility in more complicated problems. The class for marking
a boundary is derived from class `SubDomain` and has a method `inside(self, x, on_boundary)` for the code that returns whether the `point` is on the
boundary in question or not. Our previous `left_boundary` function
takes this form in its class version:

!bc pycod
class LeftBoundary(SubDomain):
    def inside(self, x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[0]) < tol

left_boundary = LeftBoundary()
Gamma_0 = DirichletBC(V, u_L, left_boundary)
!ec


=== Debugging Dirichlet conditions ===

Debugging of PDE solvers very often faces the question of whether the
boundary conditions are set correctly or not. To check which Dirichlet
conditions that are actually set in the present problem, we can call
the `get_boundary_values` method in the `DirichletBC` objects. This
method returns a dictionary with degrees of freedom as keys and
corresponding essential conditions as values. In the present problem
we can write

!bc pycod
coor = mesh.coordinates()
d2v = dof_to_vertex_map(V)
for bc in bcs:
    bc_dict = bc.get_boundary_values()
    for dof in bc_dict:
        print('dof %2d: u=%g\t at point %s' %
              (dof, bc_dict[dof],
	      str(tuple(coor[d2v[dof]].tolist()))))
!ec
The printing of coordinates for each degree of freedom (node here)
is only appropriate when degrees of freedom coincide with function
values at the vertices of the mesh, which is the case for linear
Lagrange elements only. One should therefore make somewhat
more robust code that prints out the coordinates (for convenience
when checking boundary values) only in the case of first-order
Lagrange elements:

!bc pycod
Lagrange_1st_order = V.ufl_element().degree() == 1
if Lagrange_1st_order:
    coor = mesh.coordinates()
    d2v = dof_to_vertex_map(V)
    for bc in bcs:
        bc_dict = bc.get_boundary_values()
        for dof in bc_dict:
            print('dof %2d: u=%g' % (dof, bc_dict[dof])),
            print('\t at point %s' %
                  (str(tuple(coor[d2v[dof]].tolist()))))
!ec
The output for a mesh made by `UnitSquareMesh(3, 2)` becomes
!bc dat
dof  0: u=1 	 at point (0.0, 0.0)
dof  8: u=3 	 at point (0.0, 1.0)
dof  4: u=1.5 	 at point (0.0, 0.5)
dof  3: u=2 	 at point (1.0, 0.0)
dof 11: u=4 	 at point (1.0, 1.0)
dof  7: u=2.5 	 at point (1.0, 0.5)
!ec

#The file `${prog["dn2_p2D"]}.py` contains a complete program which
#demonstrates the constructions above.
An extended example with multiple Neumann conditions would have
been quite natural now, but this requires marking various parts
of the boundary using the *mesh function* concept and is therefore
left to Section ref{tut:poisson:mat:neumann}.

===== Working with two subdomains =====
label{tut:possion:2D:2mat:problem}

idx{heterogeneous media}
idx{multi-material domain}


Solving PDEs in domains made up of different materials is a frequently
encountered task. In FEniCS, these kind of problems are handled by
defining subdomains inside the domain. The subdomains may represent the
various materials. We can thereafter define material properties through
functions, known in FEniCS as *mesh functions*,
that are piecewise constant in each subdomain.
A simple example with
two materials (subdomains) in 2D will
demonstrate the basic steps in the process.
# Later, a multi-material
# problem in $d$ space dimensions is addressed.

FIGURE: [fig/layered_medium_2, width=400 frac=0.5] Medium with discontinuous material properties. label{tut:possion:2D:2mat:fig1}

=== Mathematical problem ===

Suppose we want to solve

!bt
\begin{equation} label{tut:poisson:2D:2mat:varcoeff2}
    \nabla\cdot \left\lbrack k(x,y)\nabla u(x,y)\right\rbrack = 0,
\end{equation}
!et
in a domain $\Omega$ consisting of two subdomains where $k$ takes on
a different value in each subdomain.
For simplicity, yet without loss of generality, we choose for the current
implementation
the domain $\Omega = [0,1]\times [0,1]$ and divide it into two equal
subdomains,
as depicted in Figure ref{tut:possion:2D:2mat:fig1},

!bt
\begin{equation*}
\Omega_0 = [0, 1]\times [0,1/2],\quad
\Omega_1 = [0, 1]\times (1/2,1]\tp
\end{equation*}
!et
We define $k(x,y)=k_0$ in $\Omega_0$ and $k(x,y)=k_1$ in $\Omega_1$,
where $k_0>0$ and $k_1>0$ are given constants.
As boundary conditions, we choose $u=0$ at $y=0$, $u=1$ at $y=1$,
and $\partial u/\partial n=0$ at $x=0$ and $x=1$.
One can show that the exact solution is now given by

!bt
\begin{equation}
u(x, y) = \left\lbrace\begin{array}{ll}
{2yk_1\over k_0+k_1}, & y \leq 1/2\\
{(2y-1)k_0 + k_1\over k_0+k_1}, & y \geq 1/2
\end{array}\right.
\end{equation}
!et
As long as the element boundaries coincide with the internal boundary
$y=1/2$, this piecewise linear solution should be exactly recovered
by Lagrange elements of any degree. We use this property to verify
the implementation.

Physically, the present problem may correspond to heat conduction, where
the heat conduction in $\Omega_1$ is ten times more efficient than
in $\Omega_0$. An alternative interpretation is flow in porous media
with two geological layers, where the layers' ability to transport
the fluid differs by a factor of 10.

idx{boundary specification (class)}
idx{`${prog["mat2_p2D"]}.py`}

=== Implementation ===
label{tut:possion:2D:2mat:impl}

The new functionality in this subsection regards how to define the
subdomains $\Omega_0$ and $\Omega_1$. For this purpose we need to use
subclasses of class `SubDomain`, not only plain functions as we have
used so far for specifying boundaries. Consider the boundary function

!bc pycod
def boundary(x, on_boundary):
    tol = 1E-14
    return on_boundary and abs(x[0]) < tol
!ec
for defining the boundary $x=0$. Instead of using such a stand-alone
function, we can create an instance (or object)
of a subclass of `SubDomain`,
which implements the `inside` method as an alternative to the
`boundary` function:

!bc pycod
class Boundary(SubDomain):
    def inside(self, x, on_boundary):
        tol = 1E-14
        return on_boundary and abs(x[0]) < tol

boundary = Boundary()
bc = DirichletBC(V, Constant(0), boundary)
!ec
A word about computer science terminology may be used here:
The term *instance*
means a Python object of a particular type (such as `SubDomain`,
`Function`
`FunctionSpace`, etc.).
Many use *instance* and *object*
as interchangeable terms. In other computer programming languages one may
also use the term *variable* for the same thing.
We mostly use the well-known  term *object* in this text.

A subclass of `SubDomain` with an `inside` method offers
functionality for marking parts of the domain or
the boundary. Now we need to define one class for the
subdomain $\Omega_0$
where $y\leq 1/2$ and another for the subdomain $\Omega_1$ where $y\geq 1/2$:

!bc pycod
class Omega0(SubDomain):
    def inside(self, x, on_boundary):
        return True if x[1] <= 0.5 else False

class Omega1(SubDomain):
    def inside(self, x, on_boundary):
        return True if x[1] >= 0.5 else False
!ec
Notice the use of `<=` and `>=` in both tests. For a cell to
belong to, e.g., $\Omega_1$, the `inside` method must return
`True` for all the vertices `x` of the cell. So to make the
cells at the internal boundary $y=1/2$ belong to $\Omega_1$, we need
the test `x[1] >= 0.5`.

The next task is to use a `MeshFunction` to mark all
cells in $\Omega_0$ with the subdomain number 0 and all cells in $\Omega_1$
with the subdomain number 1.
Our convention is to number subdomains as $0,1,2,\ldots$.

A `MeshFunction` is a discrete function that can be evaluated at a set
of so-called *mesh entities*. Examples of mesh entities are
cells, facets, and vertices. A `MeshFunction` over cells is suitable to
represent subdomains (materials), while a `MeshFunction` over
facets is used to represent pieces of external or internal boundaries.
Mesh functions over vertices can be used to describe continuous fields.

Since we need to define subdomains of $\Omega$
in the present example, we must make use
of a `MeshFunction` over cells. The
`MeshFunction` constructor is fed with three arguments: 1) the type
of value: `'int'` for integers, `'uint'` for positive
(unsigned) integers, `'double'` for real numbers, and
`'bool'` for logical values; 2) a `Mesh` object, and 3)
the topological dimension of the mesh entity in question: cells
have topological dimension equal to the number of space dimensions in
the PDE problem, and facets have one dimension lower.
Alternatively, the constructor can take just a filename
and initialize the `MeshFunction` from data in a file.
#  #ifdef BOOK
We shall
demonstrate this functionality in the next multi-material problem
in Section ref{tut:possion:nD:nmat}.
#  #endif

We start with creating a `MeshFunction` whose
values are non-negative integers (`'uint'`)
for numbering the subdomains.
The mesh entities of interest are the cells, which have dimension 2
in a two-dimensional problem (1 in 1D, 3 in 3D). The appropriate code for
defining the `MeshFunction` for two subdomains then reads

!bc pycod
subdomains = MeshFunction('uint', mesh, 2)
# Mark subdomains with numbers 0 and 1
subdomain0 = Omega0()
subdomain0.mark(subdomains, 0)
subdomain1 = Omega1()
subdomain1.mark(subdomains, 1)
!ec

Calling `subdomains.array()` returns a `numpy` array of the
subdomain values. That is, `subdomain.array()[i]` is
the subdomain value of cell number `i`. This array is used to
look up the subdomain or material number of a specific element.

We need a function `k` that is constant in
each subdomain $\Omega_0$ and $\Omega_1$. Since we want `k`
to be a finite element function, it is natural to choose
a space of functions that are constant over each element.
The family of discontinuous Galerkin methods, in FEniCS
denoted by `'DG'`, is suitable for this purpose. Since we
want functions that are piecewise constant, the value of
the degree parameter is zero:

!bc pycod
V0 = FunctionSpace(mesh, 'DG', 0)
k  = Function(V0)
!ec
To fill `k` with the right values in each element, we loop over
all cells (i.e., indices in `subdomain.array()`),
extract the corresponding subdomain number of a cell,
and assign the corresponding $k$ value to the `k.vector()` array:

!bc pycod
k_values = [1.5, 50]  # values of k in the two subdomains
for cell_no in range(len(subdomains.array())):
    subdomain_no = subdomains.array()[cell_no]
    k.vector()[cell_no] = k_values[subdomain_no]
!ec

Long loops in Python are known to be slow, so for large meshes
it is preferable to avoid such loops and instead use *vectorized code*.
Normally this implies that the loop must be replaced by
calls to functions from the `numpy` library that operate on complete
arrays (in efficient C code). The functionality we want in the present
case is to compute an array of the same size as
`subdomain.array()`, but where the value `i` of an entry
in `subdomain.array()` is replaced by `k_values[i]`.
Such an operation is carried out by the `numpy` function `choose`:

!bc pycod
help = numpy.asarray(subdomains.array(), dtype=numpy.int32)
k.vector()[:] = numpy.choose(help, k_values)
!ec
The `help` array is required since `choose` cannot work with
`subdomain.array()` because this array has elements of
type `uint32`. We must therefore transform this array to an array
`help` with standard `int32` integers.

Having the `k` function ready for finite element computations, we
can proceed in the normal manner with defining essential boundary
conditions, as in Section ref{tut:poisson:multiple:Dirichlet},
and the $a(u,v)$ and $L(v)$ forms, as in
Section ref{tut:possion:2D:varcoeff}.
All the details can be found in the file `${prog["mat2_p2D"]}.py`.


===== Multiple Neumann, Robin, and Dirichlet condition =====
label{tut:poisson:mat:neumann}
idx{Dirichlet boundary conditions}
idx{Neumann boundary conditions}
idx{Robin boundary conditions}
idx{boundary conditions}

Let us go back to the model problem from
Section ref{tut:poisson:multiple:Dirichlet}
where we had both Dirichlet and Neumann conditions.
The term `v*g*ds` in the expression for `L` implies a
boundary integral over the complete boundary, or in FEniCS terms,
an integral over all exterior facets.
However, the contributions from the parts of the boundary where we have
Dirichlet conditions are erased when the linear system is modified by
the Dirichlet conditions.
We would like, from an efficiency point of view, to integrate `v*g*ds`
only over the parts of the boundary where we actually have Neumann conditions.
And more importantly,
in other problems one may have different Neumann conditions or
other conditions like the Robin type condition.
With the mesh function concept we can mark
different parts of the boundary and integrate over specific parts.
The same concept can also be used to treat multiple Dirichlet conditions.
The forthcoming text illustrates how this is done.

Essentially, we still stick to the model problem from
Section ref{tut:poisson:multiple:Dirichlet}, but replace the
Neumann condition at $y=0$ by a *Robin condition*:

!bt
\begin{equation*}
-{\partial u\over\partial n} = p(u-q),
\end{equation*}
!et
where $p$ and $q$ are specified functions.
The Robin condition is
most often used to model heat transfer to the surroundings and arise
naturally from Newton's cooling law.

Since we have prescribed a simple solution in our model problem,
$u=1+x^2+2y^2$, we adjust $p$ and $q$ such that the condition holds
at $y=0$. This implies that $q=1+x^2+2y^2$ and $p$ can be arbitrary
(the normal derivative at $y=0$: $\partial u/\partial n = -\partial u/\partial y = -4y=0$).

Now we have four parts of the boundary: $\Gamma_N$ which corresponds to
the upper side $y=1$, $\Gamma_R$ which corresponds to the lower part
$y=0$, $\Gamma_0$ which corresponds to the left part $x=0$, and
$\Gamma_1$ which corresponds to the right part $x=1$. The
complete boundary-value problem reads

!bt
\begin{align}
    - \nabla^2 u &= -6 \mbox{ in } \Omega, label{tut:poisson:2D:DN3}\\
    u &= u_L \mbox{ on } \Gamma_0, label{tut:poisson:2D:DN3:bc1}\\
    u &= u_R \mbox{ on } \Gamma_1, label{tut:poisson:2D:DN3:bc2}\\
    - {\partial u\over\partial n} &= p(u-q) \mbox{ on } \Gamma_R,
    label{tut:poisson:2D:DN3:bc3}\\
    - {\partial u\over\partial n} &= g \mbox{ on } \Gamma_N\tp
    label{tut:poisson:2D:DN3:bc4}
\end{align}
!et
The involved prescribed functions are $u_L= 1 + 2y^2$,
$u_R = 2 + 2y^2$, $q=1+x^2+2y^2$, $p$ is arbitrary, and $g=-4y$.

Integration by parts of $-\int_\Omega v\nabla^2 u \dx$ becomes
as usual

!bt
\begin{equation*}
 -\int_\Omega v\nabla^2 u \dx
= \int_\Omega\nabla u\cdot \nabla v \dx - \int_{\partial\Omega}{\partial u\over
\partial n}v \ds\tp
\end{equation*}
!et
The boundary integral vanishes on $\Gamma_0\cup\Gamma_1$, and
we split the parts over $\Gamma_N$ and $\Gamma_R$ since we have
different conditions at those parts:

!bt
\begin{equation*}
- \int_{\partial\Omega}v{\partial u\over\partial n} \ds
=
-\int_{\Gamma_N}v{\partial u\over\partial n} \ds -
\int_{\Gamma_R}v{\partial u\over\partial n} \ds
= \int_{\Gamma_N}vg \ds +
\int_{\Gamma_R}vp(u-q) \ds\tp
\end{equation*}
!et
The weak form then becomes

!bt
\begin{equation*}
\int_{\Omega} \nabla u\cdot \nabla v \dx +
\int_{\Gamma_N} gv \ds + \int_{\Gamma_R}p(u-q)v \ds
= \int_{\Omega} fv \dx,
\end{equation*}
!et
We want to write this weak form in the standard
notation $a(u,v)=L(v)$, which
requires that we identify all integrals with *both* $u$ and $v$,
and collect these in $a(u,v)$, while the remaining integrals with
$v$ and not $u$ go
into $L(v)$.
The integral from the Robin condition must of this reason be split in two
parts:

!bt
\begin{equation*} \int_{\Gamma_R}p(u-q)v \ds
= \int_{\Gamma_R}puv \ds - \int_{\Gamma_R}pqv \ds\tp
\end{equation*}
!et
We then have

!bt
\begin{align}
a(u, v) &= \int_{\Omega} \nabla u\cdot \nabla v \dx
+ \int_{\Gamma_R}puv \ds,
label{tut:poisson:2D:DN3:var:a}\\
L(v) &= \int_{\Omega} fv \dx -
\int_{\Gamma_N} g v \ds + \int_{\Gamma_R}pqv \ds\tp
label{tut:poisson:2D:DN3:var:L}
\end{align}
!et

idx{`${prog["dnr_p2D"]}.py`}

## /usr/share/dolfin/demo/documented/subdomains/python/demo_subdomains.py
## contains a good example, followed up in stokes solvers

A natural starting point for implementation is the `${prog["dn2_p2D"]}.py`
program in the directory `poisson`. The new aspects are

  o definition of a mesh function over the boundary,
  o marking each side as a subdomain, using the mesh function,
  o splitting a boundary integral into parts.

Task 1 makes use of the `MeshFunction` object, but contrary to
Section ref{tut:possion:2D:2mat:impl}, this is not a function over
cells, but a function over cell facets. The topological dimension of
cell facets is one lower than the cell interiors, so in a two-dimensional
problem the dimension
becomes 1. In general, the facet dimension
is given as `mesh.topology().dim()-1`,
which we use in the code for ease of direct reuse in other problems.
The construction of a `MeshFunction` object to mark boundary parts
now reads

!bc pycod
boundary_parts = \
  MeshFunction('size_t', mesh, mesh.topology().dim()-1)
!ec
As in Section ref{tut:possion:2D:2mat:impl} we
use a subclass of `SubDomain` to identify the various parts
of the mesh function. Problems with domains of more complicated geometries may
set the mesh function for marking boundaries as part of the mesh
generation.
In our case, the $y=0$ boundary can be marked by

!bc pycod
class LowerRobinBoundary(SubDomain):
    def inside(self, x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[1]) < tol

Gamma_R = LowerRobinBoundary()
Gamma_R.mark(boundary_parts, 0)
!ec
The code for the $y=1$ boundary is similar and is seen in
`${prog["dnr_p2D"]}.py`.

The Dirichlet boundaries are marked similarly, using subdomain number 2 for $\Gamma_0$ and 3 for $\Gamma_1$:

!bc pycod
class LeftBoundary(SubDomain):
    def inside(self, x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[0]) < tol

Gamma_0 = LeftBoundary()
Gamma_0.mark(boundary_parts, 2)

class RightBoundary(SubDomain):
    def inside(self, x, on_boundary):
        tol = 1E-14   # tolerance for coordinate comparisons
        return on_boundary and abs(x[0] - 1) < tol

Gamma_1 = RightBoundary()
Gamma_1.mark(boundary_parts, 3)
!ec
Specifying the `DirichletBC` objects may now make use of
the mesh function (instead of a `SubDomain` subclass object)
and an indicator for which subdomain each condition
should be applied to:

!bc pycod
u_L = Expression('1 + 2*x[1]*x[1]')
u_R = Expression('2 + 2*x[1]*x[1]')
bcs = [DirichletBC(V, u_L, boundary_parts, 2),
       DirichletBC(V, u_R, boundary_parts, 3)]
!ec

Some functions need to be defined before we can go on with the
`a` and `L` of the variational problem:

!bc pycod
g = Expression('-4*x[1]')
q = Expression('1 + x[0]*x[0] + 2*x[1]*x[1]')
p = Constant(100)  # arbitrary function can go here
u = TrialFunction(V)
v = TestFunction(V)
f = Constant(-6.0)
!ec

The new aspect of the variational problem is the two distinct
boundary integrals.
Having a mesh function over exterior cell facets (our
`boundary_parts` object), where subdomains (boundary parts) are
numbered as $0,1,2,\ldots$, the special symbol `ds(0)`
implies integration over subdomain (part) 0, `ds(1)` denotes
integration over subdomain (part) 1, and so on.
The idea of multiple `ds`-type objects generalizes to volume
integrals too: `dx(0)`, `dx(1)`, etc., are used to
integrate over subdomain 0, 1, etc.,  inside $\Omega$.

The variational problem can be defined as

!bc pycod
a = inner(nabla_grad(u), nabla_grad(v))*dx + p*u*v*ds(0)
L = f*v*dx - g*v*ds(1) + p*q*v*ds(0)
!ec
For the `ds(0)` and `ds(1)` symbols to work we must obviously
connect them (or `a` and `L`) to the mesh function marking
parts of the boundary. This is done by a certain keyword argument
to the `assemble` function:

!bwarning
The old code looked like

!bc pycod
A = assemble(a, exterior_facet_domains=boundary_parts)
b = assemble(L, exterior_facet_domains=boundary_parts)
!ec
but the `exterior_facet_domain` argument is no longer legal.
The text must be updated! The associated code gives wrong results.
!ewarning

!bc pycod
A = assemble(a)
b = assemble(L)
!ec
Then essential boundary conditions are enforced, and the system can
be solved in the usual way:

!bc pycod
for bc in bcs:
    bc.apply(A, b)
u = Function(V)
U = u.vector()
solve(A, U, b)
!ec
The complete code is in the `${prog["dnr_p2D"]}.py` file in the
`poisson` directory.

===== Handy methods in key FEniCS objects =====

idx{`pydoc`}
In general,
`pydoc dolfin.X` shows the documentation of any DOLFIN name `X`
and lists all the methods (i.e.g, functions in the class) that
can be called. Below, we list just a few, but very useful, methods
in the most central FEniCS classes.

=== Mesh ===

Let `mesh` be a `Mesh` object.

  * `mesh.coordinates()` returns an array of the coordinates of
     the vertices in the mesh.
  * `mesh.num_cells()` returns the number of cells (triangles)
    in the mesh,
  * `mesh.num_vertices()` returns the number of vertices in
    the mesh (with our choice of linear Lagrange elements this equals the
    number of nodes, `len(u_array)`, or dimension of the space `V.dim()`),
  * `mesh.cells()` returns the vertex numbers of the vertices in
    each cell as a `numpy` array with shape
    (*number of cells*, *number of vertices in a cell*),
  * `mesh.hmin()` returns the minimum cell diameter (``smallest cell''),
  * `mesh.hmax()` returns the maximum cell diameter (``largest cell'').

Writing `print(mesh)` dumps a short, pretty-print description
of the mesh (`print(mesh)` actually displays the result of `str(mesh)`,
which defines the pretty print):

!bc dat
<Mesh of topological dimension 2 (triangles) with
16 vertices and 18 cells, ordered>
!ec

=== Function space ===

Let `V` be a `FunctionSpace` object.

 * `V.mesh()` returns the associated mesh.
 * `V.dim()` returns the dimension (number of degrees of freedom).
 * `V.ufl_element()` returns the associated finite element.

=== Function ===

Let `u` be a `Function` object.

 * `u.function_space()` returns the associated function space.
 * `u.vector()` returns the DOLFIN vector of degrees of freedom.
 * `u.vector().array()` returns a copy of the degrees of freedom
   in a `numpy` array.
